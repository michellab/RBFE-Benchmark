{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# analysis per system\n",
    "\n",
    "# import libraries\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as _stats\n",
    "from scipy.interpolate import griddata\n",
    "from functools import reduce\n",
    "from pipeline.analysis import *\n",
    "from pipeline.utils import *\n",
    "from pipeline import *\n",
    "import logging\n",
    "import networkx as nx\n",
    "import glob\n",
    "from scipy.stats import sem as sem\n",
    "from matplotlib import colormaps\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "# warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from cinnabar import wrangle as _wrangle\n",
    "\n",
    "\n",
    "print(BSS.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normal_dist(values):\n",
    "    # check normally dist\n",
    "    if len(values) < 50:\n",
    "        stat, p = _stats.shapiro(values)\n",
    "    else:\n",
    "        stat, p = _stats.kstest(values)\n",
    "    if p < 0.05:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def flatten_comprehension(matrix):\n",
    "    return [item for row in matrix for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the analysis method to use\n",
    "ana_dicts = {\n",
    "    \"plain\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": False,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"subsampling\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": True,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"1ns\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": False,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 25,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"2ns\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": False,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 50,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"3ns\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": False,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 75,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"autoeq\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": True,\n",
    "        \"statistical inefficiency\": True,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    # \"TI\": {\n",
    "    # \"estimator\": \"TI\",\n",
    "    # \"method\": \"alchemlyb\",\n",
    "    # \"check overlap\": True,\n",
    "    # \"try pickle\": True,\n",
    "    # \"save pickle\": True,\n",
    "    # \"auto equilibration\": False,\n",
    "    # \"statistical inefficiency\": False,\n",
    "    # \"truncate lower\": 0,\n",
    "    # \"truncate upper\": 100,\n",
    "    # \"name\": None,\n",
    "    # },\n",
    "    #     \"single_0\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    #     \"single_1\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    #     \"single_2\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_dict_name = {\n",
    "    \"tyk2\": \"TYK2\",\n",
    "    \"mcl1\": \"MCL1\",\n",
    "    \"p38\": \"P38Î±\",\n",
    "    \"syk\": \"SYK\",\n",
    "    \"hif2a\": \"HIF2A\",\n",
    "    \"cmet\": \"CMET\",\n",
    "}\n",
    "eng_dict_name = {\n",
    "    \"AMBER\": \"AMBER22\",\n",
    "    \"SOMD\": \"SOMD1\",\n",
    "    \"GROMACS\": \"GROMACS23\",\n",
    "    \"hahn\": \"Hahn et al.\",\n",
    "    \"openfe\": \"OpenFE\",\n",
    "    \"fepplus\": \"FEP+\",\n",
    "}\n",
    "\n",
    "set_cols = pipeline.analysis.set_colours(\n",
    "    other_results_names=[\"hahn\", \"openfe\", \"fepplus\"]\n",
    ")\n",
    "col_dict = {}\n",
    "for eng in eng_dict_name:\n",
    "    col_dict[eng_dict_name[eng]] = set_cols[eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = \"tyk2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dict = {}\n",
    "\n",
    "#\n",
    "# , \"combined\", \"lomap\", \"rbfenn\", \"flare\", \"lomap-a-optimal\", \"lomap-d-optimal\", \"rbfenn-a-optimal\", \"rbfenn-d-optimal\"\n",
    "for network in [\"combined\", \"lomap\", \"rbfenn\", \"flare\"]:\n",
    "    # all the options\n",
    "    ana_obj_dict = {}\n",
    "\n",
    "    for ana_dict in ana_dicts.items():\n",
    "        ana_prot = analysis_protocol(ana_dict[1])\n",
    "\n",
    "        bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "        # main_dir = f\"{bench_folder}/reruns/{protein}\"\n",
    "        main_dir = f\"/backup/{protein}\"\n",
    "\n",
    "        # # if need size of protein\n",
    "        # try:\n",
    "        #     prot = BSS.IO.readMolecules(\n",
    "        #         [\n",
    "        #             f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.gro\",\n",
    "        #             f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.top\",\n",
    "        #         ]\n",
    "        #     )[0]\n",
    "        # except:\n",
    "        #     prot = BSS.IO.readMolecules(\n",
    "        #         [\n",
    "        #             f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.prm7\",\n",
    "        #             f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.rst7\",\n",
    "        #         ]\n",
    "        #     )[0]\n",
    "\n",
    "        # print(f\"no of residues in the protein: {prot.nResidues()}\")\n",
    "\n",
    "        # choose location for the files\n",
    "        if protein == \"syk\" or protein == \"cmet\" or protein == \"hif2a\":\n",
    "            # the lomap network\n",
    "            if network == \"lomap\":\n",
    "                net_file = f\"{main_dir}/execution_model/network_lomap.dat\"\n",
    "            else:\n",
    "                ana_obj_dict[protein][ana_dict[0]] = None\n",
    "                continue\n",
    "        elif protein == \"p38\":\n",
    "            if (\n",
    "                network == \"lomap-a-optimal\"\n",
    "                or network == \"lomap-d-optimal\"\n",
    "                or network == \"rbfenn-a-optimal\"\n",
    "                or network == \"rbfenn-d-optimal\"\n",
    "            ):\n",
    "                ana_obj_dict[protein][ana_dict[0]] = None\n",
    "                continue\n",
    "            else:\n",
    "                net_file = f\"{main_dir}/execution_model/network_{network}.dat\"\n",
    "\n",
    "        else:\n",
    "            net_file = f\"{main_dir}/execution_model/network_{network}.dat\"\n",
    "\n",
    "        exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "        output_folder = f\"{main_dir}/outputs_extracted\"\n",
    "\n",
    "        # prot_file = f\"{main_dir}/execution_model/protocol.dat\" # no protocol used , name added after if needed\n",
    "        pipeline_prot = pipeline_protocol(auto_validate=True)\n",
    "        # pipeline_prot.name(\"\")\n",
    "\n",
    "        # initialise the network object\n",
    "        all_analysis_object = analysis_network(\n",
    "            output_folder,\n",
    "            exp_file=exp_file,\n",
    "            net_file=net_file,\n",
    "            analysis_prot=ana_prot,\n",
    "            # method=pipeline_prot.name(),  # if the protocol had a name\n",
    "            # engines=pipeline_prot.engines(),\n",
    "        )\n",
    "\n",
    "        # compute\n",
    "        try:\n",
    "            all_analysis_object.compute_results()\n",
    "        except:\n",
    "            print(\"failed analysis\")\n",
    "\n",
    "        # add ligands folder\n",
    "        all_analysis_object.add_ligands_folder(\n",
    "            f\"{bench_folder}/inputs/reruns/{protein}/ligands_intermediates\"\n",
    "        )\n",
    "\n",
    "        ana_obj_dict[ana_dict[0]] = all_analysis_object\n",
    "\n",
    "    network_dict[network] = ana_obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# set the network for the pertubation analysis\n",
    "network = \"combined\"\n",
    "ana_obj = network_dict[network][\"plain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify any outliers and plot again if needed above\n",
    "failed_perts_dict_percen = {}\n",
    "failed_perts_dict = {}\n",
    "\n",
    "failed_perts_dict_percen = {}\n",
    "failed_perts_dict = {}\n",
    "\n",
    "for eng in ana_obj.engines:  # ana_obj.engines\n",
    "    failed_perts_dict_percen[eng] = 100 - ana_obj.successful_perturbations(eng)[1]\n",
    "    failed_perts_dict[eng] = ana_obj.failed_perturbations(eng)\n",
    "    print(\n",
    "        f\"failed percentage for {eng}: {100 - ana_obj.successful_perturbations(eng)[1]} ({len(ana_obj.perturbations) - len(ana_obj.successful_perturbations(eng)[2])} / {len(ana_obj.perturbations)})\"\n",
    "    )\n",
    "    print(f\"{eng} failed perturbations: {ana_obj.failed_perturbations(engine=eng)}\")\n",
    "    print(f\"{eng} disconnected ligands: {ana_obj.disconnected_ligands(engine=eng)}\")\n",
    "    print(f\"outliers 10 {eng}: {ana_obj.get_outliers(threshold=10, name=eng)}\")\n",
    "    print(f\"outliers 5 {eng}: {ana_obj.get_outliers(threshold=5, name=eng)}\")\n",
    "\n",
    "    # ana_obj.remove_outliers(threshold=5, name=eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of the perturbation analysis methods\n",
    "\n",
    "mae_dict = {}\n",
    "\n",
    "sem_dict = {}\n",
    "sem_dict_name = {}\n",
    "\n",
    "for name in ana_dicts:\n",
    "    sem_list_name = []\n",
    "    sem_dict[name] = {}\n",
    "\n",
    "    sem_dict[name][protein] = {}\n",
    "\n",
    "    ana_obj = network_dict[network][name]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        # print(name, eng)\n",
    "        sem_dict[name][protein][eng] = {}\n",
    "\n",
    "        sem_list = []\n",
    "        sems = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "        sem_list.append(sems)\n",
    "        sem_list_name.append(sems)\n",
    "\n",
    "        sem_list = reduce(lambda xs, ys: xs + ys, sem_list)\n",
    "        sem_list = [x for x in sem_list if str(x) != \"nan\"]\n",
    "\n",
    "        # if not check_normal_dist(sem_list):\n",
    "        #     print(f\"{prot} {name} not normally dist\")\n",
    "\n",
    "        mean = np.mean(sem_list)\n",
    "        lower_ci, upper_ci = _stats.norm.interval(\n",
    "            confidence=0.95, loc=np.mean(sem_list), scale=_stats.sem(sem_list)\n",
    "        )\n",
    "        # print(protein, name, eng, mean, lower_ci, upper_ci)\n",
    "        sem_dict[name][protein][eng] = (\n",
    "            mean,\n",
    "            _stats.tstd(sem_list),\n",
    "            (lower_ci, upper_ci),\n",
    "            sem_list,\n",
    "        )\n",
    "\n",
    "    sem_list_name = reduce(lambda xs, ys: xs + ys, sem_list_name)\n",
    "    sem_list_name = [x for x in sem_list_name if str(x) != \"nan\"]\n",
    "    mean = np.mean(sem_list_name)\n",
    "    lower_ci, upper_ci = _stats.norm.interval(\n",
    "        confidence=0.95, loc=np.mean(sem_list_name), scale=_stats.sem(sem_list_name)\n",
    "    )\n",
    "    # print(name, mean, lower_ci, upper_ci)\n",
    "    sem_dict_name[name] = (\n",
    "        mean,\n",
    "        _stats.tstd(sem_list_name),\n",
    "        (lower_ci, upper_ci),\n",
    "        sem_list_name,\n",
    "    )\n",
    "\n",
    "    mae_dict[name] = {}\n",
    "\n",
    "    mae_dict[name][protein] = {}\n",
    "\n",
    "    ana_obj = network_dict[network][name]\n",
    "\n",
    "    stats_string_all = \"\"\n",
    "    try:\n",
    "        mae = ana_obj.calc_mae_engines(pert_val=\"pert\", recalculate=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        stats_string = \"\"\n",
    "        try:\n",
    "            mae_dict[name][protein][eng] = (\n",
    "                mae[0][eng][\"experimental\"],\n",
    "                mae[1][eng][\"experimental\"],\n",
    "                mae[2][eng][\"experimental\"],\n",
    "            )\n",
    "            stats_string += f\"{eng} MAE: {mae[0][eng]['experimental']:.2f} +/- {mae[1][eng]['experimental']:.2f} kcal/mol, \"\n",
    "\n",
    "            if sem_dict[name][protein][eng][0]:\n",
    "                stats_string += f\"SEM: {sem_dict[name][protein][eng][0]:.2f} +/- {sem_dict[name][protein][eng][1]:.2f} kcal/mol\\n\"\n",
    "            elif name == \"single\":\n",
    "                errors = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "                stats_string += f\"error: {np.mean(errors):.2f} +/- {_stats.tstd(errors):.2f} kcal/mol\\n\"\n",
    "\n",
    "            # print(stats_string)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"could not compute for {protein} {name} {eng}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs based on engine\n",
    "plotting_dict = sem_dict  # mae_dict or sem_dict\n",
    "stats_name = \"ÎÎG SEM\"  # MAE or SEM\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(20, 20), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "for engine, pos in zip(ana_obj.engines, [axes[0], axes[1], axes[2]]):\n",
    "    df_list = []\n",
    "    df_err_list = []\n",
    "    for name in ana_dicts:\n",
    "        df = (\n",
    "            pd.DataFrame(plotting_dict[name])\n",
    "            .applymap(lambda x: x[0])\n",
    "            .rename(prot_dict_name, axis=1)\n",
    "            .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "            .rename({engine: name}, axis=1)\n",
    "            .rename(\n",
    "                {\n",
    "                    \"plain\": \"Full data\",\n",
    "                    \"subsampling\": \"Subsampling\",\n",
    "                    \"autoeq\": \"Auto-equilibration\",\n",
    "                    \"1ns\": \"1 ns sampling\",\n",
    "                    \"2ns\": \"2 ns sampling\",\n",
    "                    \"3ns\": \"3 ns sampling\",\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        df_err = (\n",
    "            pd.DataFrame(plotting_dict[name])\n",
    "            .applymap(lambda x: x[1])\n",
    "            .rename(prot_dict_name, axis=1)\n",
    "            .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "            .rename({engine: name}, axis=1)\n",
    "            .rename(\n",
    "                {\n",
    "                    \"plain\": \"Full data\",\n",
    "                    \"subsampling\": \"Subsampling\",\n",
    "                    \"autoeq\": \"Auto-equilibration\",\n",
    "                    \"1ns\": \"1 ns sampling\",\n",
    "                    \"2ns\": \"2 ns sampling\",\n",
    "                    \"3ns\": \"3 ns sampling\",\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # df_lower = df_err.applymap(lambda x: x[0])\n",
    "        # df_upper = df_err.applymap(lambda x: x[1])\n",
    "        # df_err = (df_upper - df_lower) / 2\n",
    "\n",
    "        df_list.append(df)\n",
    "        df_err_list.append(df_err)\n",
    "\n",
    "    df = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        df_list,\n",
    "    )\n",
    "    df_err = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        df_err_list,\n",
    "    )\n",
    "\n",
    "    print(df)\n",
    "    print(engine)\n",
    "    print(df.mean())\n",
    "    print(df.sem())\n",
    "    print(df_err)\n",
    "\n",
    "    # engine colours\n",
    "    col_dict = {\n",
    "        \"AMBER\": plt.get_cmap(\"autumn\"),\n",
    "        \"SOMD\": plt.get_cmap(\"cool\"),\n",
    "        \"GROMACS\": plt.get_cmap(\"viridis\"),\n",
    "    }\n",
    "\n",
    "    # scale data for compatibility with cmap\n",
    "    data = [i for i in range(1, len(df.columns) + 1)]\n",
    "    den = max(data) - min(data)\n",
    "    scaled_data = [(datum - min(data)) / den for datum in data]\n",
    "\n",
    "    # get colors corresponding to data\n",
    "    colors = []\n",
    "    my_cmap = plt.get_cmap(\"plasma\")  # col_dict[engine]\n",
    "\n",
    "    for decimal in scaled_data:\n",
    "        colors.append(my_cmap(decimal))\n",
    "\n",
    "    df.plot(\n",
    "        kind=\"bar\",\n",
    "        color=colors,\n",
    "        yerr=df_err,\n",
    "        title=eng_dict_name[engine],\n",
    "        ax=pos,\n",
    "        xlabel=\"Protein System\",\n",
    "        ylabel=f\"{stats_name} (kcal/mol)\",\n",
    "    )\n",
    "# fig.suptitle(f'{stats_name} perturbations for LOMAP/RBFENN-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the network for the pertubation analysis\n",
    "network = \"combined\"\n",
    "ana_obj = network_dict[network][\"plain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the statistical significance and make a violin plot\n",
    "\n",
    "stats_name = \"SEM\"\n",
    "\n",
    "# checking for significance\n",
    "eng1 = \"AMBER\"\n",
    "eng2 = \"SOMD\"\n",
    "eng3 = \"GROMACS\"\n",
    "first_err_vals = []\n",
    "second_err_vals = []\n",
    "third_err_vals = []\n",
    "\n",
    "if stats_name == \"MAE\":\n",
    "    # MAE\n",
    "    f_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng1][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "        for key in ana_obj.calc_pert_dict[eng1]\n",
    "        if not \"Intermediate\" in key\n",
    "    ]\n",
    "    s_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng2][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "        for key in ana_obj.calc_pert_dict[eng2]\n",
    "        if not \"Intermediate\" in key\n",
    "    ]\n",
    "    t_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng3][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "        for key in ana_obj.calc_pert_dict[eng3]\n",
    "        if not \"Intermediate\" in key\n",
    "    ]\n",
    "elif stats_name == \"SEM\":\n",
    "    # SEM\n",
    "    f_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng1][key][1])\n",
    "        for key in ana_obj.calc_pert_dict[eng1]\n",
    "    ]\n",
    "    s_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng2][key][1])\n",
    "        for key in ana_obj.calc_pert_dict[eng2]\n",
    "    ]\n",
    "    t_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng3][key][1])\n",
    "        for key in ana_obj.calc_pert_dict[eng3]\n",
    "    ]\n",
    "else:\n",
    "    print(\"wrong name\")\n",
    "\n",
    "first_err_vals.append(f_err_vals)\n",
    "second_err_vals.append(s_err_vals)\n",
    "third_err_vals.append(t_err_vals)\n",
    "\n",
    "first_err_vals = flatten_comprehension(first_err_vals)\n",
    "second_err_vals = flatten_comprehension(second_err_vals)\n",
    "third_err_vals = flatten_comprehension(third_err_vals)\n",
    "\n",
    "# filtered_data = [t for t in zip(first_err_vals, second_err_vals, third_err_vals) if not any(np.isnan(x) for x in t)]\n",
    "# first_err_vals, second_err_vals, third_err_val = map(list, zip(*filtered_data))\n",
    "valid_indices = [\n",
    "    i\n",
    "    for i in range(len(first_err_vals))\n",
    "    if not (\n",
    "        np.isnan(first_err_vals[i])\n",
    "        or np.isnan(second_err_vals[i])\n",
    "        or np.isnan(third_err_vals[i])\n",
    "    )\n",
    "]\n",
    "first_err_vals = [first_err_vals[i] for i in valid_indices]\n",
    "second_err_vals = [second_err_vals[i] for i in valid_indices]\n",
    "third_err_vals = [third_err_vals[i] for i in valid_indices]\n",
    "\n",
    "assert len(first_err_vals) == len(second_err_vals)\n",
    "assert len(first_err_vals) == len(third_err_vals)\n",
    "assert len(second_err_vals) == len(third_err_vals)\n",
    "\n",
    "eng_list_dict = {}\n",
    "eng_list_dict[eng1] = first_err_vals\n",
    "eng_list_dict[eng2] = second_err_vals\n",
    "eng_list_dict[eng3] = third_err_vals\n",
    "\n",
    "stats_test_dict = {}\n",
    "\n",
    "for enga in [eng1, eng2, eng3]:\n",
    "    stats_test_dict[enga] = {}\n",
    "    for engb in [eng1, eng2, eng3]:\n",
    "        if enga == engb:\n",
    "            stats_test_dict[enga][engb] = 100\n",
    "        else:\n",
    "            # check normally distributed\n",
    "            if (\n",
    "                _stats.shapiro(\n",
    "                    abs(np.array(eng_list_dict[enga] - np.array(eng_list_dict[engb])))\n",
    "                )[1]\n",
    "                > 0.05\n",
    "            ):\n",
    "                print(\"data is normally distributed !!\")\n",
    "            else:\n",
    "                t, p = _stats.wilcoxon(\n",
    "                    eng_list_dict[enga], eng_list_dict[engb]\n",
    "                )  # absolute error  # ttest_rel\n",
    "                stats_test_dict[enga][engb] = p\n",
    "        # print(enga, engb, t, p)\n",
    "\n",
    "df = pd.DataFrame(stats_test_dict).applymap(lambda x: float(x))\n",
    "print(\n",
    "    f\"statistical significance for the {stats_name} for the perturbations between engines\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD between engines\n",
    "\n",
    "filtered_keys = [\n",
    "    key\n",
    "    for key in ana_obj.calc_pert_dict[eng1]\n",
    "    if key in ana_obj.calc_pert_dict[eng2]\n",
    "    and key in ana_obj.calc_pert_dict[eng3]\n",
    "    and not (\n",
    "        np.isnan(ana_obj.calc_pert_dict[eng1][key]).any()\n",
    "        or np.isnan(ana_obj.calc_pert_dict[eng2][key]).any()\n",
    "        or np.isnan(ana_obj.calc_pert_dict[eng3][key]).any()\n",
    "    )\n",
    "]\n",
    "\n",
    "# statistical sig\n",
    "\n",
    "# only for the same perturabtions\n",
    "eng_list_dict = {}\n",
    "eng_list_dict[eng1] = [ana_obj.calc_pert_dict[eng1][key][0] for key in filtered_keys]\n",
    "eng_list_dict[eng2] = [ana_obj.calc_pert_dict[eng2][key][0] for key in filtered_keys]\n",
    "eng_list_dict[eng3] = [ana_obj.calc_pert_dict[eng3][key][0] for key in filtered_keys]\n",
    "\n",
    "stats_test_dict = {}\n",
    "\n",
    "for enga in [eng1, eng2, eng3]:\n",
    "    stats_test_dict[enga] = {}\n",
    "    for engb in [eng1, eng2, eng3]:\n",
    "        if enga == engb:\n",
    "            stats_test_dict[enga][engb] = 100\n",
    "        else:\n",
    "            # check normally distributed\n",
    "            if (\n",
    "                _stats.shapiro(\n",
    "                    abs(np.array(eng_list_dict[enga] - np.array(eng_list_dict[engb])))\n",
    "                )[1]\n",
    "                > 0.05\n",
    "            ):\n",
    "                print(\n",
    "                    f\"data is normally distributed for {enga} and {engb}!! Still carrying out wilcoxon signed rank ....\"\n",
    "                )\n",
    "\n",
    "            t, p = _stats.wilcoxon(\n",
    "                eng_list_dict[enga], eng_list_dict[engb]\n",
    "            )  # absolute error  # ttest_rel\n",
    "            stats_test_dict[enga][engb] = p\n",
    "        # print(enga, engb, t, p)\n",
    "\n",
    "df_col = pd.DataFrame(stats_test_dict).applymap(lambda x: float(x))\n",
    "print(\"statistical significance between the perturbations calculated\")\n",
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to each other\n",
    "mad = ana_obj.calc_mad_engines(pert_val=\"pert\", recalculate=False)\n",
    "mad[0].update(mad[0].applymap(lambda x: f\"\" if x == 0 else f\"{x:.2f}\"))\n",
    "mad[2].update(\n",
    "    mad[2].applymap(lambda x: f\"\" if x[0] == 0 else f\"({x[0]:.2f}, {x[1]:.2f})\")\n",
    ")\n",
    "df_val = mad[0].astype(str) + \"\\n\" + mad[2].astype(str)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the stats test\n",
    "\n",
    "# threshold for colour labels\n",
    "color_labels = df_col.applymap(\n",
    "    lambda x: \"white\"\n",
    "    if x == 100\n",
    "    else \"grey\"  # same engine, no stats test\n",
    "    if x > 0.05\n",
    "    else \"pink\"  # no statistically significant difference\n",
    ")  # statistically significant difference\n",
    "\n",
    "# mapping dictionary\n",
    "color_mapping = {\"pink\": \"#FFC0CB\", \"white\": \"#FFFFFF\", \"grey\": \"#BEBEBE\"}\n",
    "\n",
    "# Convert text labels to a numerical array\n",
    "color_numeric = df_col.applymap(lambda x: 0 if x == 100 else 1 if x > 0.05 else 2)\n",
    "\n",
    "# below as otherwise problem if only two colours\n",
    "array_col_dict = {\n",
    "    0: color_mapping[\"white\"],\n",
    "    1: color_mapping[\"grey\"],\n",
    "    2: color_mapping[\"pink\"],\n",
    "}\n",
    "\n",
    "numeric_colours_list = flatten_comprehension(color_numeric.values.tolist())\n",
    "\n",
    "cmap = mcolors.ListedColormap(\n",
    "    [\n",
    "        array_col_dict[key]\n",
    "        for key in array_col_dict.keys()\n",
    "        if key in numeric_colours_list\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot heatmap using numeric mapping for colors\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "sns.heatmap(color_numeric, annot=df_val, fmt=\"s\", cmap=cmap, cbar=False, ax=ax)\n",
    "\n",
    "legend_patches = [  # mpatches.Patch(color=color_mapping[\"white\"], label=\"\"),\n",
    "    mpatches.Patch(color=color_mapping[\"pink\"], label=\"p â¤ 0.05\"),\n",
    "    mpatches.Patch(color=color_mapping[\"grey\"], label=\"p > 0.05\"),\n",
    "]\n",
    "\n",
    "# Add legend to the plot\n",
    "plt.legend(\n",
    "    handles=legend_patches,\n",
    "    loc=\"center left\",\n",
    "    title=\"Statistical significance\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "\n",
    "plt.title(\"MAD (kcal/mol) between engines (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the perts values to investigate significant difference if present in the above plot\n",
    "# histogram\n",
    "# plt.hist(eng_list_dict[eng1], density=True, color=pipeline.analysis.set_colours()[eng1], label=eng_dict_name[eng1], alpha=0.5)\n",
    "plt.hist(\n",
    "    eng_list_dict[eng2],\n",
    "    density=True,\n",
    "    color=pipeline.analysis.set_colours()[eng2],\n",
    "    label=eng_dict_name[eng2],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(\n",
    "    eng_list_dict[eng3],\n",
    "    density=True,\n",
    "    color=pipeline.analysis.set_colours()[eng3],\n",
    "    label=eng_dict_name[eng3],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(f\"ddG value (kcal/mol)\")\n",
    "plt.ylabel(\"Density\")\n",
    "# plt.title(prot_name_dict[protein])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plots\n",
    "data = {\n",
    "    \"engine\": [f\"{eng_dict_name[eng1]}\"] * len(first_err_vals)\n",
    "    + [f\"{eng_dict_name[eng2]}\"] * len(second_err_vals)\n",
    "    + [f\"{eng_dict_name[eng3]}\"] * len(third_err_vals),\n",
    "    \"error\": flatten_comprehension([first_err_vals, second_err_vals, third_err_vals]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.violinplot(x=\"engine\", y=\"error\", data=df, inner=\"box\", palette=col_dict)\n",
    "\n",
    "# plt.title(\"MAE Distribution for Different MD Engines\")\n",
    "plt.xlabel(\"MD Engine\")\n",
    "plt.ylabel(f\"{stats_name} (kcal/mol)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "plt.hist(\n",
    "    first_err_vals,\n",
    "    density=True,\n",
    "    color=pipeline.analysis.set_colours()[eng1],\n",
    "    label=eng_dict_name[eng1],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(\n",
    "    second_err_vals,\n",
    "    density=True,\n",
    "    color=pipeline.analysis.set_colours()[eng2],\n",
    "    label=eng_dict_name[eng2],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(\n",
    "    third_err_vals,\n",
    "    density=True,\n",
    "    color=pipeline.analysis.set_colours()[eng3],\n",
    "    label=eng_dict_name[eng3],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(f\"ddG {stats_name} (kcal/mol)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(prot_name_dict[protein])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historgrams of SEM for the legs or repeats\n",
    "\n",
    "ana_obj.plot_histogram_repeats()\n",
    "ana_obj.plot_histogram_legs()\n",
    "\n",
    "# ana_obj.plot_histogram_sem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d contour plot\n",
    "stats_name = \"MAE\"\n",
    "\n",
    "for eng1, eng2 in ([\"AMBER\", \"SOMD\"], [\"AMBER\", \"GROMACS\"], [\"GROMACS\", \"SOMD\"]):\n",
    "    first_err_vals = []\n",
    "    second_err_vals = []\n",
    "\n",
    "    filtered_keys = [\n",
    "        key\n",
    "        for key in ana_obj.calc_pert_dict[eng1]\n",
    "        if key\n",
    "        in ana_obj.calc_pert_dict[eng2]  # and key in ana_obj.calc_pert_dict[eng3]\n",
    "        and not (\n",
    "            np.isnan(ana_obj.calc_pert_dict[eng1][key]).any()\n",
    "            or np.isnan(ana_obj.calc_pert_dict[eng2][key]).any()  # or\n",
    "            # np.isnan(ana_obj.calc_pert_dict[eng3][key]).any()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if stats_name == \"SEM\":\n",
    "        # MAE\n",
    "        f_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng1][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "            for key in filtered_keys\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "        s_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng2][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "            for key in filtered_keys\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "\n",
    "    elif stats_name == \"MAE\":\n",
    "        # SEM\n",
    "        f_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng1][key][1]) for key in filtered_keys\n",
    "        ]\n",
    "        s_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng2][key][1]) for key in filtered_keys\n",
    "        ]\n",
    "\n",
    "    first_err_vals.append(f_err_vals)\n",
    "    second_err_vals.append(s_err_vals)\n",
    "\n",
    "    x = flatten_comprehension(first_err_vals)\n",
    "    y = flatten_comprehension(second_err_vals)\n",
    "    z = np.abs(np.array(x) - np.array(y))  # z = np.sin(x) + np.cos(y)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.kdeplot(x=x, y=y, cmap=\"PuRd\", fill=True, levels=10, thresh=0.05)\n",
    "    # # Scatter plot on top to show data points\n",
    "    plt.scatter(x, y, c=z, cmap=\"Purples\", edgecolors=\"black\")\n",
    "    plt.colorbar(label=f\"Absolute difference\\n between engine {stats_name} (kcal/mol)\")\n",
    "\n",
    "    # Labels and Title\n",
    "    plt.xlabel(f\"{eng1} {stats_name}\")\n",
    "    plt.ylabel(f\"{eng2} {stats_name}\")\n",
    "    plt.title(f\"{stats_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d contour plot\n",
    "stats_name = \"MAE (kcal/mol)\"\n",
    "\n",
    "for eng1, eng2, eng3 in [\n",
    "    (\"GROMACS\", \"SOMD\", \"AMBER\"),\n",
    "    (\"SOMD\", \"AMBER\", \"GROMACS\"),\n",
    "    (\"AMBER\", \"GROMACS\", \"SOMD\"),\n",
    "]:\n",
    "    first_err_vals = []\n",
    "    second_err_vals = []\n",
    "    third_err_vals = []\n",
    "\n",
    "    filtered_keys = [\n",
    "        key\n",
    "        for key in ana_obj.calc_pert_dict[eng1]\n",
    "        if key in ana_obj.calc_pert_dict[eng2]\n",
    "        and key in ana_obj.calc_pert_dict[eng3]\n",
    "        and not (\n",
    "            np.isnan(ana_obj.calc_pert_dict[eng1][key]).any()\n",
    "            or np.isnan(ana_obj.calc_pert_dict[eng2][key]).any()\n",
    "            or np.isnan(ana_obj.calc_pert_dict[eng3][key]).any()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # MAE\n",
    "    f_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng1][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "        for key in filtered_keys\n",
    "        if not \"Intermediate\" in key\n",
    "    ]\n",
    "    s_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng2][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "        for key in filtered_keys\n",
    "        if not \"Intermediate\" in key\n",
    "    ]\n",
    "    t_err_vals = [\n",
    "        abs(ana_obj.calc_pert_dict[eng3][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "        for key in filtered_keys\n",
    "        if not \"Intermediate\" in key\n",
    "    ]\n",
    "\n",
    "    # SEM\n",
    "    # f_err_vals = [abs(ana_obj.calc_pert_dict[eng1][key][1]) for key in filtered_keys]\n",
    "    # s_err_vals = [abs(ana_obj.calc_pert_dict[eng2][key][1]) for key in filtered_keys]\n",
    "    # t_err_vals = [abs(ana_obj.calc_pert_dict[eng3][key][1]) for key in filtered_keys]\n",
    "\n",
    "    first_err_vals.append(f_err_vals)\n",
    "    second_err_vals.append(s_err_vals)\n",
    "    third_err_vals.append(t_err_vals)\n",
    "\n",
    "    x = np.array(flatten_comprehension(first_err_vals)) - np.array(\n",
    "        flatten_comprehension(second_err_vals)\n",
    "    )\n",
    "    y = np.array(flatten_comprehension(third_err_vals)) - np.array(\n",
    "        flatten_comprehension(second_err_vals)\n",
    "    )\n",
    "    z = np.abs(np.array(x) - np.array(y))  # z = np.sin(x) + np.cos(y)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.kdeplot(x=x, y=y, cmap=\"PuRd\", fill=True, levels=10, thresh=0.05)\n",
    "    # # Scatter plot on top to show data points\n",
    "    plt.scatter(x, y, c=second_err_vals, cmap=\"Purples\", edgecolors=\"black\")\n",
    "    plt.colorbar(label=f\"{eng2} {stats_name}\")\n",
    "    ax.axhline(0, color=\"black\", linewidth=1)\n",
    "    ax.axvline(0, color=\"black\", linewidth=1)\n",
    "\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f\"better than {eng3}\\nworse than {eng1}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax.text(\n",
    "        0.70,\n",
    "        0.10,\n",
    "        f\"worse than {eng3}\\nbetter than {eng1}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.10,\n",
    "        f\"worse than {eng3}\\nworse than {eng1}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax.text(\n",
    "        0.70,\n",
    "        0.95,\n",
    "        f\"better than {eng3}\\nbetter than {eng1}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    # Labels and Title\n",
    "    plt.xlabel(f\"{eng1}-{eng2} {stats_name}\")\n",
    "    plt.ylabel(f\"{eng3}-{eng2} {stats_name}\")\n",
    "    plt.title(f\"{eng2} {stats_name.replace('(kcal/mol)','')}comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the literature results\n",
    "\n",
    "file = (\n",
    "    f\"/home/anna/Documents/benchmark/inputs/other_computed/fepplus/{protein}_perts.csv\"\n",
    ")\n",
    "df = pd.read_csv(file, delimiter=\",\")\n",
    "\n",
    "# for perturbations\n",
    "fepplus_perts_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    fepplus_perts_dict[\n",
    "        f\"lig_{row['Lig 1'].replace(' flip', '').replace('-charged-pKa-8.1', '').replace(' redocked', '').replace('_n', '').replace(' ground state', '').replace('docked ', '').replace(' adjust', '').replace('ejm_', 'ejm').replace('jmc_', 'jmc').strip()}~lig_{row['Lig 2'].replace(' flip', '').replace('-charged-pKa-8.1', '').replace(' redocked', '').replace('_n', '').replace(' ground state', '').replace('docked ', '').replace(' adjust', '').replace('ejm_', 'ejm').replace('jmc_', 'jmc').strip()}\"\n",
    "    ] = (\n",
    "        row[\"Bennett ddG (kcal/mol)\"],\n",
    "        row[\"Bennett std. error (kcal/mol)\"],\n",
    "    )\n",
    "\n",
    "write_perts_file(\n",
    "    fepplus_perts_dict,\n",
    "    # .csv\n",
    "    file_path=f\"/home/anna/Documents/benchmark/inputs/{protein}/perts_file_fepplus_new\",\n",
    ")\n",
    "\n",
    "# for ligands\n",
    "file = (\n",
    "    f\"/home/anna/Documents/benchmark/inputs/other_computed/fepplus/{protein}_ligs.csv\"\n",
    ")\n",
    "df = pd.read_csv(file, delimiter=\",\")\n",
    "\n",
    "fepplus_ligs_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    fepplus_ligs_dict[\n",
    "        f\"lig_{row['Ligand name'].replace(' flip', '').replace('-charged-pKa-8.1', '').replace(' redocked', '').replace('_n', '').replace(' ground state', '').replace('docked ', '').replace(' adjust', '').replace('ejm_', 'ejm').replace('jmc_', 'jmc').strip()}\"\n",
    "    ] = (\n",
    "        row[\"Pred. dG (kcal/mol)\"],\n",
    "        row[\"Pred. dG std. error (kcal/mol)\"],\n",
    "    )\n",
    "\n",
    "normalised_ligs_dict = {}\n",
    "avg = np.mean([val[0] for val in fepplus_ligs_dict.values()])\n",
    "for lig in fepplus_ligs_dict:\n",
    "    normalised_ligs_dict[lig] = (\n",
    "        fepplus_ligs_dict[lig][0] - avg,\n",
    "        fepplus_ligs_dict[lig][1],\n",
    "    )\n",
    "\n",
    "fepplus_ligs_dict = normalised_ligs_dict\n",
    "\n",
    "write_vals_file(\n",
    "    fepplus_ligs_dict,\n",
    "    # .csv\n",
    "    file_path=f\"/home/anna/Documents/benchmark/inputs/{protein}/ligs_file_fepplus_new\",\n",
    ")\n",
    "\n",
    "\n",
    "# Hahn et al\n",
    "\n",
    "file = f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/{protein}.dat\"\n",
    "\n",
    "df = pd.read_csv(file, delimiter=\"  \")\n",
    "\n",
    "hahn_perts_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    hahn_perts_dict[f\"{row['edge']}\"] = (float(row[\"ddg\"]), float(row[\"ddg_err\"]))\n",
    "\n",
    "# need to convert into kcal/mol\n",
    "for key in hahn_perts_dict:\n",
    "    hahn_perts_dict[key] = (\n",
    "        hahn_perts_dict[key][0] * 0.239006,\n",
    "        hahn_perts_dict[key][1] * 0.239006,\n",
    "    )\n",
    "\n",
    "write_perts_file(\n",
    "    hahn_perts_dict,\n",
    "    # .csv\n",
    "    file_path=f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/perts_file_{protein}\",\n",
    ")\n",
    "\n",
    "files = [\n",
    "    f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/perts_file_{protein}.csv\"\n",
    "]\n",
    "\n",
    "calc_diff_dict = make_dict.comp_results(files)  # older method\n",
    "\n",
    "perts, ligs = get_info_network_from_dict(calc_diff_dict)\n",
    "exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "convert.cinnabar_file(\n",
    "    files,\n",
    "    exper_dict,\n",
    "    f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/cinnabar_{protein}\",\n",
    "    perturbations=perts,\n",
    "    method=None,\n",
    ")\n",
    "\n",
    "# compute the per ligand for the network\n",
    "network = _wrangle.FEMap(\n",
    "    f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/cinnabar_{protein}.csv\"\n",
    ")\n",
    "\n",
    "# for self plotting of per ligand\n",
    "hahn_ligs_dict = make_dict.from_cinnabar_network_node(network, \"calc\")\n",
    "hahn_perts_dict = make_dict.from_cinnabar_network_edges(network, \"calc\", perts)\n",
    "\n",
    "\n",
    "# OpenFE\n",
    "if protein == \"syk\":\n",
    "    openfe_ligs_dict = {lig: (np.nan, np.nan) for lig in ana_obj.ligands}\n",
    "    openfe_perts_dict = {lig: (np.nan, np.nan) for lig in ana_obj.perturbations}\n",
    "else:\n",
    "    df_main = pd.read_csv(\n",
    "        \"/home/anna/Documents/benchmark/inputs/other_computed/openfe/combined_pymbar3_edge_data.csv\"\n",
    "    )\n",
    "\n",
    "    for rep in [0, 1, 2]:\n",
    "        df = df_main[df_main[\"system name\"] == protein]\n",
    "        df[\"freenrg\"] = (\n",
    "            df[f\"complex_repeat_{rep}_DG (kcal/mol)\"]\n",
    "            - df[f\"solvent_repeat_{rep}_DG (kcal/mol)\"]\n",
    "        )\n",
    "        df[\"dG_err_temp\"] = df[f\"complex_repeat_{rep}_DG (kcal/mol)\"].apply(\n",
    "            lambda x: math.pow(x, 2)\n",
    "        ) + df[f\"solvent_repeat_{rep}_DG (kcal/mol)\"].apply(lambda x: math.pow(x, 2))\n",
    "        df[\"error\"] = df[f\"dG_err_temp\"].apply(lambda x: math.sqrt(x))\n",
    "        df[\"lig_0\"] = \"lig_\" + df[\"ligand_A\"].str.replace(\n",
    "            \"_redocked\", \"\", regex=True\n",
    "        ).replace(\"-charged-pKa-8.1\", \"\", regex=True).replace(\n",
    "            \"-flip\", \"\", regex=True\n",
    "        ).replace(\n",
    "            \"ejm_\", \"ejm\", regex=True\n",
    "        ).replace(\n",
    "            \"jmc_\", \"jmc\", regex=True\n",
    "        )\n",
    "        df[\"lig_1\"] = \"lig_\" + df[\"ligand_B\"].str.replace(\n",
    "            \"_redocked\", \"\", regex=True\n",
    "        ).replace(\"-charged-pKa-8.1\", \"\", regex=True).replace(\n",
    "            \"-flip\", \"\", regex=True\n",
    "        ).replace(\n",
    "            \"ejm_\", \"ejm\", regex=True\n",
    "        ).replace(\n",
    "            \"jmc_\", \"jmc\", regex=True\n",
    "        )\n",
    "        df.to_csv(\n",
    "            f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/{protein}_{rep}.csv\",\n",
    "            columns=[\"lig_0\", \"lig_1\", \"freenrg\", \"error\"],\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    files = [\n",
    "        f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/{protein}_{rep}.csv\"\n",
    "        for rep in [0, 1, 2]\n",
    "    ]\n",
    "\n",
    "    calc_diff_dict = make_dict.comp_results(files)  # older method\n",
    "\n",
    "    perts, ligs = get_info_network_from_dict(calc_diff_dict)\n",
    "    exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "    convert.cinnabar_file(\n",
    "        files,\n",
    "        exper_dict,\n",
    "        f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/cinnabar_{protein}\",\n",
    "        perturbations=perts,\n",
    "        method=None,\n",
    "    )\n",
    "\n",
    "    # compute the per ligand for the network\n",
    "    network = _wrangle.FEMap(\n",
    "        f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/cinnabar_{protein}.csv\"\n",
    "    )\n",
    "\n",
    "    # for self plotting of per ligand\n",
    "    openfe_ligs_dict = make_dict.from_cinnabar_network_node(network, \"calc\")\n",
    "    openfe_perts_dict = make_dict.from_cinnabar_network_edges(network, \"calc\", perts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate perturbation statistics\n",
    "\n",
    "stats_name = \"MAE\"\n",
    "print(stats_name)\n",
    "\n",
    "if stats_name == \"MAE\":\n",
    "    func = ana_obj.calc_mae_engines\n",
    "    cinn_stats_name = \"MUE\"\n",
    "\n",
    "elif stats_name == \"RMSE\":\n",
    "    func = ana_obj.calc_rmse_engines\n",
    "    cinn_stats_name = \"RMSE\"\n",
    "else:\n",
    "    print(\"no\")\n",
    "\n",
    "val_dict = {}\n",
    "val_dict[protein] = {}\n",
    "\n",
    "res = func(pert_val=\"pert\", recalculate=False)  # mae / rmse\n",
    "for eng in ana_obj.engines:\n",
    "    val_dict[protein][eng_dict_name[eng]] = (\n",
    "        res[0][eng][\"experimental\"],\n",
    "        res[1][eng][\"experimental\"],\n",
    "        res[2][eng][\"experimental\"],\n",
    "    )\n",
    "# print(res)\n",
    "\n",
    "# literature\n",
    "\n",
    "exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "for lit_perts_dict, name in zip(\n",
    "    [openfe_perts_dict, hahn_perts_dict, fepplus_perts_dict],\n",
    "    [\"openfe\", \"hahn\", \"fepplus\"],\n",
    "):  #\n",
    "    x = []\n",
    "    y = []\n",
    "    xerr = []\n",
    "    yerr = []\n",
    "\n",
    "    perturbations = []\n",
    "    excl = 0\n",
    "    incl = 0\n",
    "    for pert in lit_perts_dict:\n",
    "        if (\n",
    "            pert.split(\"~\")[0] in exper_dict.keys()\n",
    "            and pert.split(\"~\")[1] in exper_dict.keys()\n",
    "        ):\n",
    "            perturbations.append(pert)\n",
    "            incl += 1\n",
    "        else:\n",
    "            excl += 1\n",
    "    print(\n",
    "        \"only including perturbations that also have the same ligands used. Not necessarily the same perturbations.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{excl} perturbations excluded for {name}, {incl} included: {incl/(incl+excl)*100}\"\n",
    "    )\n",
    "\n",
    "    # additionally only if there are the same perturbations, check what this would be\n",
    "    # use_perts = []\n",
    "    # reverse_perts = []\n",
    "    # for pert in ana_obj.perturbations:\n",
    "    #     if pert in perturbations:\n",
    "    #         use_perts.append(pert)\n",
    "    #     if f\"{pert.split('~')[1]}~{pert.split('~')[0]}\" in perturbations:\n",
    "    #         reverse_perts.append(pert)\n",
    "    # print(f\"{len(use_perts)+len(reverse_perts)} perturbations of these would be the same/reverse perturbations ({(len(use_perts)+len(reverse_perts))/(perturbations)*100} %)\")\n",
    "    # perturbations = flatten_comprehension([use_perts, reverse_perts])\n",
    "\n",
    "    exper_pert_dict = make_dict.exper_from_perturbations(exper_dict, perturbations)\n",
    "\n",
    "    for pert in perturbations:\n",
    "        x.append(lit_perts_dict[pert][0])\n",
    "        xerr.append(lit_perts_dict[pert][1])\n",
    "        y.append(exper_pert_dict[pert][0])\n",
    "        yerr.append(exper_pert_dict[pert][1])\n",
    "\n",
    "    # calculate statistics\n",
    "\n",
    "    res = stats_engines.compute_stats(\n",
    "        x=x, xerr=xerr, y=y, yerr=yerr, statistic=cinn_stats_name\n",
    "    )\n",
    "    # print(\"cinnabar\", name, res)\n",
    "\n",
    "    val_dict[protein][eng_dict_name[name]] = (\n",
    "        res[0],\n",
    "        res[1],\n",
    "        res[2],\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(val_dict)\n",
    "# df.to_markdown()\n",
    "df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_res = pd.DataFrame(val_dict).T.map(lambda x: x[0])\n",
    "ax = val_res.plot.bar(\n",
    "    color=col_dict,\n",
    "    yerr=pd.DataFrame(val_dict).T.map(lambda x: x[1]),\n",
    "    xlabel=\"protein\",\n",
    "    ylabel=f\"{stats_name} (kcal/mol)\",\n",
    ")\n",
    "ax.legend(\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 1.0),  # fancybox=True, shadow=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlating the number of perturbed atoms with precision (SEM) and accuracy (MAE)\n",
    "\n",
    "pert_overlap_dict = {}\n",
    "\n",
    "df = ana_obj.perturbing_atoms_and_overlap(read_file=True)\n",
    "\n",
    "df[\"score\"] = np.nan\n",
    "# read in all the lomap scores\n",
    "score_dict = {}\n",
    "# print(f\"{main_dir}/execution_model/network_scores.dat\")\n",
    "with open(f\"{main_dir}/execution_model/network_scores.dat\") as lfile:\n",
    "    for line in lfile:\n",
    "        score_dict[\n",
    "            f\"{line.split(',')[0].strip()}~{line.split(',')[1].strip()}\"\n",
    "        ] = float(line.split(\",\")[-1].strip())\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"perturbation\"] not in ana_obj.perturbations:\n",
    "        df = df.drop(index)\n",
    "    else:\n",
    "        try:\n",
    "            df.at[index, \"score\"] = score_dict[row[\"perturbation\"]]\n",
    "        except:\n",
    "            try:\n",
    "                df.at[index, \"score\"] = score_dict[\n",
    "                    f'{row[\"perturbation\"].split(\"~\")[1]}~{row[\"perturbation\"].split(\"~\")[0]}'\n",
    "                ]\n",
    "            except:\n",
    "                # print(f\"not {row['perturbation']}\")\n",
    "                pass\n",
    "\n",
    "pert_overlap_dict[protein] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the df below to check things\n",
    "df_plot.sort_values(by=\"Overlap > 0.03 (%)\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df  # df.dropna()\n",
    "df_plot.rename(\n",
    "    columns={\n",
    "        \"perturbing_atoms\": \"Average number of perturbing atoms\",\n",
    "        \"diff_to_exp\": \"MAE (kcal/mol)\",\n",
    "        \"percen_overlap_okay\": \"Overlap > 0.03 (%)\",\n",
    "        \"error\": \"SEM (kcal/mol)\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "x = \"Average number of perturbing atoms\"\n",
    "y = \"MAE (kcal/mol)\"\n",
    "z = \"SEM (kcal/mol)\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# sns.kdeplot(x=df_plot[x], y=df_plot[y], cmap=\"PuRd\", fill=True, levels=10, thresh=0.05)\n",
    "df_plot.plot.scatter(\n",
    "    x,\n",
    "    y,\n",
    "    c=z,\n",
    "    colormap=\"plasma\",  # vmin=0, vmax=100, ax=ax\n",
    ")\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    df2 = df[df[\"engine\"] == eng]\n",
    "    df2.plot.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        c=z,\n",
    "        colormap=\"plasma\",\n",
    "        title=eng_dict_name[eng],  # vmin=80, vmax=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking perturbations from below\n",
    "val_dict = {}\n",
    "val_dict[\"value\"] = {}\n",
    "val_dict[\"difference\"] = {}\n",
    "pert = \"lig_ejm42~lig_ejm43\"\n",
    "for eng in [\"SOMD\", \"AMBER\", \"GROMACS\"]:\n",
    "    val_dict[\"value\"][\n",
    "        eng\n",
    "    ] = f\"{ana_obj.calc_pert_dict[eng][pert][0]:.2f} ({ana_obj.calc_pert_dict[eng][pert][1]:.2f})\"\n",
    "    val_dict[\"difference\"][\n",
    "        eng\n",
    "    ] = f\"{abs(ana_obj.calc_pert_dict[eng][pert][0] - ana_obj.exper_pert_dict[pert][0]):.2f}\"\n",
    "val_dict[\"value\"][\n",
    "    \"experimental\"\n",
    "] = f\"{ana_obj.exper_pert_dict[pert][0]:.2f} ({ana_obj.exper_pert_dict[pert][1]:.2f})\"\n",
    "ana_obj.draw_perturbations([pert])\n",
    "\n",
    "nets = []\n",
    "for key in network_dict.keys():\n",
    "    aj = network_dict[key][\"plain\"]\n",
    "    if pert in aj.perturbations:\n",
    "        nets.append(key)\n",
    "print(pert)\n",
    "print(nets)\n",
    "print(\n",
    "    f\"difference: {max([ana_obj.calc_pert_dict[eng][pert][0] for eng in ana_obj.engines]) - min([ana_obj.calc_pert_dict[eng][pert][0] for eng in ana_obj.engines]):.2f}\"\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(val_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the greatest difference to experimental\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    diff_dict = {}\n",
    "    for pert in ana_obj.calc_pert_dict[eng]:\n",
    "        if \"Intermediate\" in pert:\n",
    "            pass\n",
    "        else:\n",
    "            diff_dict[pert] = abs(\n",
    "                ana_obj.calc_pert_dict[eng][pert][0] - ana_obj.exper_pert_dict[pert][0]\n",
    "            )\n",
    "\n",
    "    print(eng)\n",
    "    sorted_items = sorted(diff_dict.items(), key=lambda kv: (kv[1], kv[0]))\n",
    "\n",
    "    df = pd.DataFrame(sorted_items, columns=[\"perturbation\", \"mae\"])\n",
    "    df[\"results\"] = df[\"perturbation\"].map(lambda x: ana_obj.calc_pert_dict[eng][x])\n",
    "    df[\"experimental\"] = df[\"perturbation\"].map(lambda x: ana_obj.exper_pert_dict[x])\n",
    "    print(df.nlargest(5, \"mae\"))\n",
    "\n",
    "    # ana_obj.draw_perturbations([sorted_items[-1][0], sorted_items[-2][0], sorted_items[-3][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the greatest difference between engines\n",
    "\n",
    "# Get shared keys\n",
    "keys = (\n",
    "    ana_obj.calc_pert_dict[\"AMBER\"].keys()\n",
    "    & ana_obj.calc_pert_dict[\"SOMD\"].keys()\n",
    "    & ana_obj.calc_pert_dict[\"GROMACS\"].keys()\n",
    ")\n",
    "\n",
    "# Compute max difference for each key\n",
    "diffs = {\n",
    "    key: max(\n",
    "        ana_obj.calc_pert_dict[\"AMBER\"][key][0],\n",
    "        ana_obj.calc_pert_dict[\"SOMD\"][key][0],\n",
    "        ana_obj.calc_pert_dict[\"GROMACS\"][key][0],\n",
    "    )\n",
    "    - min(\n",
    "        ana_obj.calc_pert_dict[\"AMBER\"][key][0],\n",
    "        ana_obj.calc_pert_dict[\"SOMD\"][key][0],\n",
    "        ana_obj.calc_pert_dict[\"GROMACS\"][key][0],\n",
    "    )\n",
    "    for key in keys\n",
    "}\n",
    "\n",
    "# Sort keys by difference in descending order\n",
    "sorted_keys = sorted(diffs, key=diffs.get, reverse=True)\n",
    "\n",
    "for key in sorted_keys:\n",
    "    print(key, diffs[key])\n",
    "    print(\n",
    "        \"AMBER\",\n",
    "        ana_obj.calc_pert_dict[\"AMBER\"][key],\n",
    "        \"SOMD\",\n",
    "        ana_obj.calc_pert_dict[\"SOMD\"][key],\n",
    "        \"GROMACS\",\n",
    "        ana_obj.calc_pert_dict[\"GROMACS\"][key],\n",
    "        \"experimental\",\n",
    "        ana_obj.exper_pert_dict[key],\n",
    "    )\n",
    "\n",
    "# ana_obj.draw_perturbations(sorted_keys[:5])\n",
    "# ana_obj.draw_perturbations(sorted_keys[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligand analysis\n",
    "ana_obj = network_dict[\"combined\"][\"plain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ana_obj.remove_perturbations([\"lig_CHEMBL3402754_40~lig_CHEMBL3402755_4200\"])\n",
    "# ana_obj.compute_results()\n",
    "# for eng in ana_obj.engines:\n",
    "#     ana_obj.disconnected_ligands(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for literature results\n",
    "# calculate value statistics\n",
    "\n",
    "for stats_name, stats, func in zip(\n",
    "    [\"MAE (kcal/mol)\", \"Kendall's Rank\", \"R2\"],\n",
    "    [\"MUE\", \"KTAU\", \"R2\"],\n",
    "    [\n",
    "        ana_obj.calc_mae_engines,\n",
    "        ana_obj.calc_kendalls_rank_engines,\n",
    "        ana_obj.calc_r2_engines,\n",
    "    ],\n",
    "):\n",
    "    print(stats_name)\n",
    "\n",
    "    val_dict = {}\n",
    "    val_dict[protein] = {}\n",
    "\n",
    "    res = func(pert_val=\"val\", recalculate=False)  # mae / kendalls_rank / r2\n",
    "    for eng in ana_obj.engines:\n",
    "        val_dict[protein][eng_dict_name[eng]] = (\n",
    "            res[0][eng][\"experimental\"],\n",
    "            res[1][eng][\"experimental\"],\n",
    "            res[2][eng][\"experimental\"],\n",
    "        )\n",
    "        # print(\"cinnabar\", eng, res[0][eng][\"experimental\"], res[1][eng][\"experimental\"], res[2][eng][\"experimental\"])\n",
    "\n",
    "    # add the experimental values\n",
    "\n",
    "    # normalise exper dict\n",
    "    exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "    normalised_exper_dict = {}\n",
    "    avg = np.mean([val[0] for val in exper_dict.values()])\n",
    "    for lig in exper_dict:\n",
    "        normalised_exper_dict[lig] = (exper_dict[lig][0] - avg, exper_dict[lig][1])\n",
    "\n",
    "    for lit_val_dict, name in zip(\n",
    "        [openfe_ligs_dict, hahn_ligs_dict, fepplus_ligs_dict],\n",
    "        [\"openfe\", \"hahn\", \"fepplus\"],\n",
    "    ):  #\n",
    "        x = []\n",
    "        y = []\n",
    "        xerr = []\n",
    "        yerr = []\n",
    "        for lig in ana_obj.ligands:\n",
    "            if lig in lit_val_dict.keys():\n",
    "                if not np.isnan(lit_val_dict[lig][0]):\n",
    "                    x.append(lit_val_dict[lig][0])\n",
    "                    xerr.append(lit_val_dict[lig][1])\n",
    "                    y.append(normalised_exper_dict[lig][0])\n",
    "                    yerr.append(normalised_exper_dict[lig][1])\n",
    "\n",
    "        # calculate statistics\n",
    "\n",
    "        res = stats_engines.compute_stats(\n",
    "            x=x, xerr=xerr, y=y, yerr=yerr, statistic=stats\n",
    "        )  # MUE, KTAU, R2\n",
    "        # print(\"cinnabar\", name, res)\n",
    "\n",
    "        val_dict[protein][eng_dict_name[name]] = (\n",
    "            res[0],\n",
    "            res[1],\n",
    "            res[2],\n",
    "        )\n",
    "\n",
    "    val_res = pd.DataFrame(val_dict).T.map(lambda x: x[0])\n",
    "    ax = val_res.plot.bar(\n",
    "        color=col_dict,\n",
    "        yerr=pd.DataFrame(val_dict).T.map(lambda x: x[1]),\n",
    "        xlabel=\"protein\",\n",
    "        ylabel=f\"{stats_name}\",\n",
    "    )\n",
    "    ax.legend(\n",
    "        loc=\"lower center\",\n",
    "        bbox_to_anchor=(0.5, 1.0),  # fancybox=True, shadow=True\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(val_dict)\n",
    "    df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the a/d optimal networks together w their counterpart\n",
    "\n",
    "stats_name = \"MAE\"\n",
    "net = \"lomap\"\n",
    "\n",
    "plotting_dict = {}\n",
    "for network in [f\"{net}\", f\"{net}-a-optimal\", f\"{net}-d-optimal\"]:\n",
    "    plotting_dict[network] = {}\n",
    "    aj = network_dict[network][\"plain\"]\n",
    "\n",
    "    if stats_name == \"MAE\":\n",
    "        func = aj.calc_mae_engines\n",
    "    elif stats_name == \"KTAU\":\n",
    "        func = aj.calc_kendalls_rank_engines\n",
    "    elif stats_name == \"R2\":\n",
    "        func = aj.calc_r2_engines\n",
    "    else:\n",
    "        print(\"no\")\n",
    "        func = None\n",
    "\n",
    "    vals = func(pert_val=\"val\", recalculate=False)\n",
    "\n",
    "    for eng in aj.engines:\n",
    "        data_point = (\n",
    "            vals[0][eng][\"experimental\"],\n",
    "            vals[1][eng][\"experimental\"],\n",
    "            vals[2][eng][\"experimental\"],\n",
    "        )\n",
    "\n",
    "        # print(network, protein, eng, data_point)\n",
    "\n",
    "        plotting_dict[network][eng] = data_point\n",
    "\n",
    "# print(plotting_dict)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# plt.xlim = ()\n",
    "# plt.ylim = ()\n",
    "\n",
    "df = pd.DataFrame(plotting_dict).applymap(lambda x: x[0]).T\n",
    "df_err = pd.DataFrame(plotting_dict).applymap(lambda x: x[1]).T\n",
    "\n",
    "# engine colours\n",
    "col_dict = {\n",
    "    \"AMBER\": [\"orange\", \"moccasin\", \"oldlace\"],\n",
    "    \"SOMD\": [\"darkturquoise\", \"paleturquoise\", \"azure\"],\n",
    "    \"GROMACS\": [\"orchid\", \"plum\", \"pink\"],\n",
    "}\n",
    "df.plot(\n",
    "    kind=\"bar\",\n",
    "    color=col_dict,\n",
    "    yerr=df_err,\n",
    "    title=prot_dict_name[protein],\n",
    "    xlabel=\"Network Method\",\n",
    "    ylabel=f\"{stats_name}\",\n",
    "    legend=True,\n",
    ")\n",
    "# key = pipeline.analysis.set_colours()\n",
    "# key.pop(\"experimental\")\n",
    "# pos.legend(key)\n",
    "\n",
    "df = pd.DataFrame(plotting_dict)\n",
    "df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj.plot_scatter_dG(use_cinnabar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in ana_obj.engines:\n",
    "    ana_obj.plot_outliers(engines=[eng], pert_val=\"val\", no_outliers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligand analysis\n",
    "ana_obj = network_dict[\"rbfenn\"][\"plain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking ligands from below\n",
    "val = \"lig_2k\"\n",
    "\n",
    "val_dict = {}\n",
    "val_dict[\"value\"] = {}\n",
    "val_dict[\"difference\"] = {}\n",
    "\n",
    "for eng in [\"SOMD\", \"AMBER\", \"GROMACS\"]:\n",
    "    val_dict[\"value\"][\n",
    "        eng\n",
    "    ] = f\"{ana_obj.cinnabar_calc_val_dict[eng][val][0]:.2f} ({ana_obj.cinnabar_calc_val_dict[eng][val][1]:.2f})\"\n",
    "    val_dict[\"difference\"][\n",
    "        eng\n",
    "    ] = f\"{abs(ana_obj.cinnabar_calc_val_dict[eng][val][0] - ana_obj.normalised_exper_val_dict[val][0]):.2f}\"\n",
    "    perts = []\n",
    "    for pert in ana_obj._perturbations_dict[eng]:\n",
    "        if val in pert:\n",
    "            perts.append(pert)\n",
    "    print(eng, val, perts)\n",
    "val_dict[\"value\"][\n",
    "    \"experiemental\"\n",
    "] = f\"{ana_obj.normalised_exper_val_dict[val][0]:.2f} ({ana_obj.normalised_exper_val_dict[val][1]:.2f})\"\n",
    "ana_obj.draw_ligands([val])\n",
    "\n",
    "df = pd.DataFrame(val_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aj_dict = {}\n",
    "val_dict = {}\n",
    "\n",
    "for net in network_dict:\n",
    "    aj = network_dict[net][\"plain\"]\n",
    "    perts = []\n",
    "    for pert in aj.perturbations:\n",
    "        if val in pert:\n",
    "            perts.append(pert)\n",
    "    aj_dict[net] = [perts]\n",
    "\n",
    "    val_dict[net] = {}\n",
    "    for eng in [\"SOMD\", \"AMBER\", \"GROMACS\"]:\n",
    "        val_dict[net][\n",
    "            eng\n",
    "        ] = f\"{aj.cinnabar_calc_val_dict[eng][val][0]:.2f} ({aj.cinnabar_calc_val_dict[eng][val][1]:.2f})\"\n",
    "    val_dict[net][\n",
    "        \"experimental\"\n",
    "    ] = f\"{aj.normalised_exper_val_dict[val][0]:.2f} ({aj.normalised_exper_val_dict[val][1]:.2f})\"\n",
    "\n",
    "df_perts = pd.DataFrame(aj_dict).T\n",
    "plot_perts = list(set(flatten_comprehension(df_perts[0])))\n",
    "ana_obj.plot_bar_ddG(values=plot_perts)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(df_perts)\n",
    "\n",
    "df = pd.DataFrame(val_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the greatest difference to experimental\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    diff_dict = {}\n",
    "    for val in ana_obj.cinnabar_calc_val_dict[eng]:\n",
    "        if \"Intermediate\" not in val:\n",
    "            diff_dict[val] = abs(\n",
    "                ana_obj.cinnabar_calc_val_dict[eng][val][0]\n",
    "                - ana_obj.normalised_exper_val_dict[val][0]\n",
    "            )\n",
    "\n",
    "    print(eng)\n",
    "    sorted_items = sorted(diff_dict.items(), key=lambda kv: (kv[1], kv[0]))\n",
    "\n",
    "    df = pd.DataFrame(sorted_items, columns=[\"ligand\", \"mae\"])\n",
    "    df[\"results\"] = df[\"ligand\"].map(lambda x: ana_obj.cinnabar_calc_val_dict[eng][x])\n",
    "    df[\"experimental\"] = df[\"ligand\"].map(\n",
    "        lambda x: ana_obj.normalised_exper_val_dict[x]\n",
    "    )\n",
    "    print(df.nlargest(5, \"mae\"))\n",
    "\n",
    "    for lig in [sorted_items[-1][0], sorted_items[-2][0], sorted_items[-3][0]]:\n",
    "        perts = []\n",
    "        for pert in ana_obj._perturbations_dict[eng]:\n",
    "            if lig in pert:\n",
    "                perts.append(pert)\n",
    "        print(lig, perts)\n",
    "\n",
    "    # ana_obj.draw_ligands([sorted_items[-1][0], sorted_items[-2][0], sorted_items[-3][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligand analysis\n",
    "ana_obj = network_dict[\"rbfenn\"][\"plain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the greatest difference between engines\n",
    "\n",
    "# Get shared keys\n",
    "keys = (\n",
    "    ana_obj.cinnabar_calc_val_dict[\"AMBER\"].keys()\n",
    "    & ana_obj.cinnabar_calc_val_dict[\"SOMD\"].keys()\n",
    "    & ana_obj.cinnabar_calc_val_dict[\"GROMACS\"].keys()\n",
    ")\n",
    "\n",
    "# Compute max difference for each key\n",
    "diffs = {\n",
    "    key: max(\n",
    "        ana_obj.cinnabar_calc_val_dict[\"AMBER\"][key][0],\n",
    "        ana_obj.cinnabar_calc_val_dict[\"SOMD\"][key][0],\n",
    "        ana_obj.cinnabar_calc_val_dict[\"GROMACS\"][key][0],\n",
    "    )\n",
    "    - min(\n",
    "        ana_obj.cinnabar_calc_val_dict[\"AMBER\"][key][0],\n",
    "        ana_obj.cinnabar_calc_val_dict[\"SOMD\"][key][0],\n",
    "        ana_obj.cinnabar_calc_val_dict[\"GROMACS\"][key][0],\n",
    "    )\n",
    "    for key in keys\n",
    "}\n",
    "\n",
    "# Sort keys by difference in descending order\n",
    "sorted_keys = sorted(diffs, key=diffs.get, reverse=True)\n",
    "\n",
    "for key in sorted_keys:\n",
    "    print(key, diffs[key])\n",
    "    if \"Intermediate\" in key:\n",
    "        print(\n",
    "            \"AMBER\",\n",
    "            ana_obj.cinnabar_calc_val_dict[\"AMBER\"][key],\n",
    "            \"SOMD\",\n",
    "            ana_obj.cinnabar_calc_val_dict[\"SOMD\"][key],\n",
    "            \"GROMACS\",\n",
    "            ana_obj.cinnabar_calc_val_dict[\"GROMACS\"][key],\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"AMBER\",\n",
    "            ana_obj.cinnabar_calc_val_dict[\"AMBER\"][key],\n",
    "            \"SOMD\",\n",
    "            ana_obj.cinnabar_calc_val_dict[\"SOMD\"][key],\n",
    "            \"GROMACS\",\n",
    "            ana_obj.cinnabar_calc_val_dict[\"GROMACS\"][key],\n",
    "            \"experimental\",\n",
    "            ana_obj.normalised_exper_val_dict[key],\n",
    "        )\n",
    "\n",
    "for lig in sorted_keys[:3]:\n",
    "    perts = []\n",
    "    for pert in ana_obj._perturbations_dict[eng]:\n",
    "        if lig in pert:\n",
    "            perts.append(pert)\n",
    "    print(lig, perts)\n",
    "\n",
    "# ana_obj.draw_ligands(sorted_keys[:3])\n",
    "\n",
    "for lig in sorted_keys[-3:]:\n",
    "    perts = []\n",
    "    for pert in ana_obj._perturbations_dict[eng]:\n",
    "        if lig in pert:\n",
    "            perts.append(pert)\n",
    "    print(lig, perts)\n",
    "\n",
    "# ana_obj.draw_ligands(sorted_keys[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj.plot_bar_ddG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj.plot_bar_dG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating different network analysis methods:\n",
    "network = \"combined\"\n",
    "ana_obj = network_dict[network][\"plain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cinnabar stats into a dict\n",
    "net_ana_method_dict = {\"method\": [], \"engine\": [], \"protein\": [], \"value\": []}\n",
    "\n",
    "for eng in [\"AMBER\", \"SOMD\", \"GROMACS\"]:\n",
    "    dg_list = []\n",
    "\n",
    "    for key in ana_obj.cinnabar_calc_val_dict[eng].keys():\n",
    "        value = abs(\n",
    "            abs(\n",
    "                ana_obj.cinnabar_calc_val_dict[eng][key][0]\n",
    "                - ana_obj.cinnabar_exper_val_dict[eng][key][0]\n",
    "            )\n",
    "        )\n",
    "        dg_list.append(value)\n",
    "        if value > 5:\n",
    "            print(protein, eng, key, value)\n",
    "\n",
    "    net_ana_method_dict[\"method\"].append([\"cinnabar\" for l in range(0, len(dg_list))])\n",
    "    net_ana_method_dict[\"engine\"].append(\n",
    "        [eng_dict_name[eng] for l in range(0, len(dg_list))]\n",
    "    )\n",
    "    net_ana_method_dict[\"protein\"].append([prot_dict_name[protein] for val in dg_list])\n",
    "    net_ana_method_dict[\"value\"].append([val for val in dg_list])\n",
    "\n",
    "# also want to compare fwf and cinnabar\n",
    "fwf_path = (\n",
    "    \"/home/anna/Documents/september_2022_workshops/freenrgworkflows/networkanalysis\"\n",
    ")\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    print(eng)\n",
    "    dg_list = []\n",
    "\n",
    "    # add path for fwf\n",
    "    ana_obj._add_fwf_path(fwf_path)\n",
    "    ana_obj._get_exp_fwf()\n",
    "\n",
    "    try:\n",
    "        fwf_dict = ana_obj._get_ana_fwf(engine=eng, use_repeat_files=True)\n",
    "    except:\n",
    "        print(f\"{protein} {eng} did not fwf w repeat files, tring w out\")\n",
    "        # try:\n",
    "        #     fwf_dict = ana_obj._get_ana_fwf(engine=eng, use_repeat_files=False)\n",
    "        # except:\n",
    "        #     print(\"non repeat files also failed\")\n",
    "\n",
    "    try:\n",
    "        di2 = {}\n",
    "        for di in ana_obj._fwf_computed_DGs[eng]:\n",
    "            di2[[k for k in di.keys()][0]] = di[[k for k in di.keys()][0]]\n",
    "        # experimental computed normally outside of fwf and normalised\n",
    "        for key in di2.keys():\n",
    "            value = abs(di2[key] - ana_obj.normalised_exper_val_dict[key][0])\n",
    "            dg_list.append(value)\n",
    "            if value > 5:\n",
    "                print(protein, eng, key, value)\n",
    "    except:\n",
    "        print(\"did not fwf at all\")\n",
    "\n",
    "    net_ana_method_dict[\"method\"].append([\"fen\" for l in range(0, len(dg_list))])\n",
    "    net_ana_method_dict[\"engine\"].append(\n",
    "        [eng_dict_name[eng] for l in range(0, len(dg_list))]\n",
    "    )\n",
    "    net_ana_method_dict[\"protein\"].append([prot_dict_name[protein] for val in dg_list])\n",
    "    net_ana_method_dict[\"value\"].append([val for val in dg_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj.analyse_mbarnet(\n",
    "    compute_missing=True,\n",
    "    write_xml=True,\n",
    "    run_xml_py=True,\n",
    "    use_experimental=True,\n",
    "    overwrite=True,\n",
    "    engines=[\"SOMD\"],\n",
    "    normalise=True,\n",
    ")\n",
    "ana_obj._mbarnet_computed_DGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbarnet\n",
    "\n",
    "# compute all first\n",
    "for eng in ana_obj.engines:\n",
    "    try:\n",
    "        ana_obj.analyse_mbarnet(\n",
    "            compute_missing=False,\n",
    "            write_xml=False,\n",
    "            run_xml_py=False,\n",
    "            use_experimental=True,\n",
    "            overwrite=False,\n",
    "            engines=[eng],\n",
    "            normalise=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"failed for {eng}\")\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    dg_list = []\n",
    "    print(eng)\n",
    "\n",
    "    try:\n",
    "        for key in ana_obj._mbarnet_computed_DGs[eng].keys():\n",
    "            value = abs(\n",
    "                ana_obj._mbarnet_computed_DGs[eng][key][0]\n",
    "                - ana_obj.normalised_exper_val_dict[key][0]\n",
    "            )\n",
    "            dg_list.append(value)\n",
    "            if value > 5:\n",
    "                print(eng, key, value)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    net_ana_method_dict[\"method\"].append([\"MBARNet\" for l in range(0, len(dg_list))])\n",
    "    net_ana_method_dict[\"engine\"].append(\n",
    "        [eng_dict_name[eng] for l in range(0, len(dg_list))]\n",
    "    )\n",
    "    net_ana_method_dict[\"protein\"].append([prot_dict_name[protein] for val in dg_list])\n",
    "    net_ana_method_dict[\"value\"].append([val for val in dg_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stats_name, stats, func in zip(\n",
    "    [\"MAE (kcal/mol)\", \"Kendall's Rank\", \"R2\"],\n",
    "    [\"MUE\", \"KTAU\", \"R2\"],\n",
    "    [\n",
    "        ana_obj.calc_mae_engines,\n",
    "        ana_obj.calc_kendalls_rank_engines,\n",
    "        ana_obj.calc_r2_engines,\n",
    "    ],\n",
    "):\n",
    "    df_dict = {}\n",
    "\n",
    "    df_dict[\"cinnabar\"] = {}\n",
    "    df_dict[\"fen\"] = {}\n",
    "    df_dict[\"mbarnet\"] = {}\n",
    "\n",
    "    print(\"cinnabar\")\n",
    "    df_dict[\"cinnabar\"][protein] = {}\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        try:\n",
    "            df, df_err, df_ci = func(engines=[eng], pert_val=\"val\", recalculate=False)\n",
    "            df_dict[\"cinnabar\"][protein][eng] = (\n",
    "                df[eng][\"experimental\"],\n",
    "                df_err[eng][\"experimental\"],\n",
    "                df_ci[eng][\"experimental\"],\n",
    "            )\n",
    "            # print(stats_name, eng, df[eng][\"experimental\"], df_ci[eng][\"experimental\"])\n",
    "        except:\n",
    "            df_dict[\"cinnabar\"][protein][eng] = (0, 0, (0, 0))\n",
    "\n",
    "    df_dict[\"fen\"][protein] = {}\n",
    "\n",
    "    print(\"fen\")\n",
    "    for eng in ana_obj.engines:\n",
    "        try:\n",
    "            df, df_err, df_ci = ana_obj._get_stats_fwf(engines=[eng], statistic=stats)\n",
    "            df_dict[\"fen\"][protein][eng] = (\n",
    "                df[eng][\"experimental\"],\n",
    "                df_err[eng][\"experimental\"],\n",
    "                df_ci[eng][\"experimental\"],\n",
    "            )\n",
    "            # print(stats_name, eng, df[eng][\"experimental\"], df_ci[eng][\"experimental\"])\n",
    "        except:\n",
    "            print(\"ooft\")\n",
    "            df_dict[\"fen\"][protein][eng] = (0, 0, (0, 0))\n",
    "\n",
    "    df_dict[\"mbarnet\"][protein] = {}\n",
    "    print(\"mbarnet\")\n",
    "    for eng in ana_obj.engines:\n",
    "        try:\n",
    "            print(\n",
    "                protein,\n",
    "                eng,\n",
    "                len(ana_obj._perturbations_dict[eng]),\n",
    "                len(ana_obj._mbarnet_computed_DGs[eng]),\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        # try:\n",
    "        #     df, df_err, df_ci = ana_obj._get_stats_mbarnet(\n",
    "        #         engines=[eng], statistic=stats\n",
    "        #     )\n",
    "        #     df_dict[\"mbarnet\"][protein][eng] = (\n",
    "        #         df[eng][\"experimental\"],\n",
    "        #         df_err[eng][\"experimental\"],\n",
    "        #         df_ci[eng][\"experimental\"]\n",
    "        #     )\n",
    "        #     print(stats_name, eng, df[eng][\"experimental\"], df_ci[eng][\"experimental\"])\n",
    "        # except:\n",
    "        #     print(\"oop\")\n",
    "        df_dict[\"mbarnet\"][protein][eng] = (0, 0, (0, 0))\n",
    "\n",
    "    print(stats_name)\n",
    "    print(\"cinnabar\")\n",
    "    df = pd.DataFrame(df_dict[\"cinnabar\"])\n",
    "    df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "    print(df)\n",
    "    print(\"fen\")\n",
    "    df = pd.DataFrame(df_dict[\"fen\"])\n",
    "    df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "    print(df)\n",
    "    print(\"mbarnet\")\n",
    "    df = pd.DataFrame(df_dict[\"mbarnet\"])\n",
    "    df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "    print(df)\n",
    "\n",
    "    # compare stats\n",
    "    fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True)\n",
    "    plt.xlim = ()\n",
    "    plt.ylim = ()\n",
    "\n",
    "    df_cinnabar = (\n",
    "        pd.DataFrame(df_dict[\"cinnabar\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .rename({protein: \"cinnabar\"}, axis=1)\n",
    "    )\n",
    "    df_fen = (\n",
    "        pd.DataFrame(df_dict[\"fen\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .rename({protein: \"fen\"}, axis=1)\n",
    "    )\n",
    "    df_mbarnet = (\n",
    "        pd.DataFrame(df_dict[\"mbarnet\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .rename({protein: \"mbarnet\"}, axis=1)\n",
    "    )\n",
    "    df = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        [df_cinnabar, df_fen, df_mbarnet],\n",
    "    )\n",
    "\n",
    "    df_cinnabar = (\n",
    "        pd.DataFrame(df_dict[\"cinnabar\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .rename({protein: \"cinnabar\"}, axis=1)\n",
    "    )\n",
    "    df_fen = (\n",
    "        pd.DataFrame(df_dict[\"fen\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .rename({protein: \"fen\"}, axis=1)\n",
    "    )\n",
    "    df_mbarnet = (\n",
    "        pd.DataFrame(df_dict[\"mbarnet\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .rename({protein: \"mbarnet\"}, axis=1)\n",
    "    )\n",
    "    df_err = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        [df_cinnabar, df_fen, df_mbarnet],\n",
    "    )\n",
    "\n",
    "    # df_lower = df_err.applymap(lambda x: x[0])\n",
    "    # df_upper = df_err.applymap(lambda x: x[1])\n",
    "    # df_err = (df_upper - df_lower)/2\n",
    "\n",
    "    df.plot(\n",
    "        kind=\"bar\",\n",
    "        color=[\"purple\", \"orchid\", \"lavender\"],\n",
    "        yerr=df_err,\n",
    "        title=prot_dict_name[protein],\n",
    "        ax=ax,\n",
    "        xlabel=\"MD Engine\",\n",
    "        ylabel=f\"{stats_name}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_dict = {\n",
    "    \"method\": flatten_comprehension(net_ana_method_dict[\"method\"]),\n",
    "    \"MD engine\": flatten_comprehension(net_ana_method_dict[\"engine\"]),\n",
    "    \"MAE dG (kcal/mol)\": flatten_comprehension(net_ana_method_dict[\"value\"]),\n",
    "    \"Protein\": flatten_comprehension(net_ana_method_dict[\"protein\"]),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.25, 3.25), dpi=500)\n",
    "df = pd.DataFrame(plotting_dict)\n",
    "sns.boxplot(\n",
    "    df,\n",
    "    x=\"MD engine\",\n",
    "    y=\"MAE dG (kcal/mol)\",\n",
    "    hue=\"method\",\n",
    "    palette=[\"purple\", \"orchid\", \"lavender\"],\n",
    "    ax=ax,\n",
    ")\n",
    "# modify individual font size of elements\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlabel(\"MD Engine\", fontsize=10)\n",
    "plt.ylabel(\"MAE ÎG (kcal/mol)\", fontsize=10)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=10)\n",
    "# ax.set_ylim(top=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the different networks\n",
    "df_dict = {}\n",
    "for stats_name, stats, func in zip(\n",
    "    [\"MAE (kcal/mol)\", \"Kendall's Rank\", \"R2\"], [\"MUE\", \"KTAU\", \"R2\"], [\"x\", \"y\", \"z\"]\n",
    "):\n",
    "    df_dict[protein] = {}\n",
    "\n",
    "    for net_name in network_dict.keys():\n",
    "        print(net_name)\n",
    "\n",
    "        ana_obj = network_dict[net_name][\"plain\"]\n",
    "        func_dict = {\n",
    "            \"MUE\": ana_obj.calc_mae_engines,\n",
    "            \"KTAU\": ana_obj.calc_kendalls_rank_engines,\n",
    "            \"R2\": ana_obj.calc_r2_engines,\n",
    "        }\n",
    "        func = func_dict[stats]\n",
    "\n",
    "        df_dict[protein][net_name] = {}\n",
    "\n",
    "        df, df_err, df_ci = func(pert_val=\"val\", recalculate=False)\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            try:\n",
    "                df_dict[protein][net_name][eng] = (\n",
    "                    df[eng][\"experimental\"],\n",
    "                    df_err[eng][\"experimental\"],\n",
    "                    df_ci[eng][\"experimental\"],\n",
    "                )\n",
    "                # print(stats_name, eng, df[eng][\"experimental\"], df_ci[eng][\"experimental\"])\n",
    "            except:\n",
    "                df_dict[protein][net_name][eng] = (0, 0, (0, 0))\n",
    "\n",
    "        print(stats_name)\n",
    "        print(\"cinnabar\")\n",
    "        df = pd.DataFrame(df_dict[protein])\n",
    "        df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "        print(df)\n",
    "\n",
    "    # compare stats\n",
    "    fig, ax = plt.subplots(figsize=(5, 5), sharex=True, sharey=True)\n",
    "    plt.xlim = ()\n",
    "    plt.ylim = ()\n",
    "\n",
    "    df = pd.DataFrame(df_dict[protein]).applymap(lambda x: x[0])\n",
    "    df_err = pd.DataFrame(df_dict[protein]).applymap(lambda x: x[1])\n",
    "    # df_lower = df_err.applymap(lambda x: x[0])\n",
    "    # df_upper = df_err.applymap(lambda x: x[1])\n",
    "    # df_err = (df_upper - df_lower)/2\n",
    "\n",
    "    col_dict = {\n",
    "        \"AMBER\": plt.get_cmap(\"autumn\"),\n",
    "        \"SOMD\": plt.get_cmap(\"cool\"),\n",
    "        \"GROMACS\": plt.get_cmap(\"viridis\"),\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    df.plot(\n",
    "        kind=\"bar\",\n",
    "        color=plt.cm.plasma(np.linspace(0, 1, len(df.columns))),\n",
    "        yerr=df_err,\n",
    "        title=prot_dict_name[protein],\n",
    "        ax=ax,\n",
    "        xlabel=\"Network generation method\",\n",
    "        ylabel=f\"{stats_name}\",\n",
    "    )\n",
    "    ax.legend(\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(1, 0.5),  # fancybox=True, shadow=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline_annamherz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

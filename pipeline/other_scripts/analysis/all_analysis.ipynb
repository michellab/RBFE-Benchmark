{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis paper\n",
    "# import libraries\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as _stats\n",
    "from functools import reduce\n",
    "from pipeline.analysis import *\n",
    "from pipeline.utils import *\n",
    "from pipeline import *\n",
    "import logging\n",
    "import networkx as nx\n",
    "import glob\n",
    "from scipy.stats import sem as sem\n",
    "from matplotlib import colormaps\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from os.path import join\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from cinnabar import wrangle as _wrangle\n",
    "\n",
    "print(BSS.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normal_dist(values):\n",
    "    # check normally dist\n",
    "    if len(values) < 50:\n",
    "        stat, p = _stats.shapiro(values)\n",
    "    else:\n",
    "        stat, p = _stats.kstest(values)\n",
    "    if p < 0.05:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def flatten_comprehension(matrix):\n",
    "    return [item for row in matrix for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the analysis method to use\n",
    "ana_dicts = {\n",
    "    \"plain\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": False,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    \"subsampling\": {\n",
    "        \"estimator\": \"MBAR\",\n",
    "        \"method\": \"alchemlyb\",\n",
    "        \"check overlap\": True,\n",
    "        \"try pickle\": True,\n",
    "        \"save pickle\": True,\n",
    "        \"auto equilibration\": False,\n",
    "        \"statistical inefficiency\": True,\n",
    "        \"truncate lower\": 0,\n",
    "        \"truncate upper\": 100,\n",
    "        \"name\": None,\n",
    "    },\n",
    "    # \"1ns\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 25,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    # \"2ns\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 50,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    # \"3ns\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 75,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    # \"autoeq\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": True,\n",
    "    #     \"statistical inefficiency\": True,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    # \"TI\": {\n",
    "    # \"estimator\": \"TI\",\n",
    "    # \"method\": \"alchemlyb\",\n",
    "    # \"check overlap\": True,\n",
    "    # \"try pickle\": True,\n",
    "    # \"save pickle\": True,\n",
    "    # \"auto equilibration\": False,\n",
    "    # \"statistical inefficiency\": False,\n",
    "    # \"truncate lower\": 0,\n",
    "    # \"truncate upper\": 100,\n",
    "    # \"name\": None,\n",
    "    # },\n",
    "    #     \"single_0\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    #     \"single_1\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # },\n",
    "    #     \"single_2\": {\n",
    "    #     \"estimator\": \"MBAR\",\n",
    "    #     \"method\": \"alchemlyb\",\n",
    "    #     \"check overlap\": True,\n",
    "    #     \"try pickle\": True,\n",
    "    #     \"save pickle\": True,\n",
    "    #     \"auto equilibration\": False,\n",
    "    #     \"statistical inefficiency\": False,\n",
    "    #     \"truncate lower\": 0,\n",
    "    #     \"truncate upper\": 100,\n",
    "    #     \"name\": None,\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_dict_name = {\n",
    "    \"tyk2\": \"TYK2\",\n",
    "    \"mcl1\": \"MCL1\",\n",
    "    \"p38\": \"P38Î±\",\n",
    "    \"syk\": \"SYK\",\n",
    "    \"hif2a\": \"HIF2A\",\n",
    "    \"cmet\": \"CMET\",\n",
    "}\n",
    "eng_dict_name = {\n",
    "    \"AMBER\": \"AMBER22\",\n",
    "    \"SOMD\": \"SOMD1\",\n",
    "    \"GROMACS\": \"GROMACS23\",\n",
    "    \"hahn\": \"Hahn et al.\",\n",
    "    \"openfe\": \"OpenFE\",\n",
    "    \"fepplus\": \"Ross et al.\",\n",
    "}\n",
    "\n",
    "set_cols = pipeline.analysis.set_colours(\n",
    "    other_results_names=[\"hahn\", \"openfe\", \"fepplus\"],\n",
    "    colour_dict={\"openfe\": \"cadetblue\", \"hahn\": \"thistle\", \"fepplus\": \"indigo\"},\n",
    ")\n",
    "col_dict = {}\n",
    "for eng in eng_dict_name:\n",
    "    col_dict[eng_dict_name[eng]] = set_cols[eng]\n",
    "col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dict = {}\n",
    "# , \"rbfenn\", \"flare\", \"combined\", \"lomap-a-optimal\", \"lomap-d-optimal\", \"rbfenn-a-optimal\", \"rbfenn-d-optimal\"\n",
    "for network in [\n",
    "    \"lomap\",\n",
    "    \"rbfenn\",\n",
    "    \"flare\",\n",
    "    \"combined\",\n",
    "    \"lomap-a-optimal\",\n",
    "    \"lomap-d-optimal\",\n",
    "    \"rbfenn-a-optimal\",\n",
    "    \"rbfenn-d-optimal\",\n",
    "]:  # lomap rbfenn combined\n",
    "    # all the options\n",
    "    ana_obj_dict = {}\n",
    "\n",
    "    for protein in [\"tyk2\", \"mcl1\", \"p38\", \"syk\", \"hif2a\", \"cmet\"]:  #\n",
    "        ana_obj_dict[protein] = {}\n",
    "\n",
    "        for ana_dict in ana_dicts:\n",
    "            ana_prot = analysis_protocol(ana_dicts[ana_dict])\n",
    "\n",
    "            bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "            # main_dir = f\"{bench_folder}/reruns/{protein}\"\n",
    "            main_dir = f\"/backup/{protein}\"\n",
    "\n",
    "            # # if need size of protein\n",
    "            # try:\n",
    "            #     prot = BSS.IO.readMolecules(\n",
    "            #         [\n",
    "            #             f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.gro\",\n",
    "            #             f\"{bench_folder}/inputs/{protein}/{protein}_prep/{protein}.top\",\n",
    "            #         ]\n",
    "            #     )[0]\n",
    "            # except:\n",
    "            #     prot = BSS.IO.readMolecules(\n",
    "            #         [\n",
    "            #             f\"{bench_folder}/inputs/{protein}/{protein}_parameterised.prm7\",\n",
    "            #             f\"{bench_folder}/inputs/{protein}/{prot}_parameterised.rst7\",\n",
    "            #         ]\n",
    "            #     )[0]\n",
    "\n",
    "            # print(f\"no of residues in the prot: {prot.nResidues()}\")\n",
    "\n",
    "            # choose location for the files\n",
    "            if protein == \"syk\" or protein == \"cmet\" or protein == \"hif2a\":\n",
    "                # the lomap network\n",
    "                if network == \"lomap\":\n",
    "                    net_file = f\"{main_dir}/execution_model/network_lomap.dat\"\n",
    "                elif network == \"combined\":\n",
    "                    net_file = f\"{main_dir}/execution_model/network_lomap.dat\"\n",
    "                else:\n",
    "                    ana_obj_dict[protein][ana_dict] = None\n",
    "                    continue\n",
    "            elif protein == \"p38\":\n",
    "                if (\n",
    "                    network == \"lomap-a-optimal\"\n",
    "                    or network == \"lomap-d-optimal\"\n",
    "                    or network == \"rbfenn-a-optimal\"\n",
    "                    or network == \"rbfenn-d-optimal\"\n",
    "                ):\n",
    "                    ana_obj_dict[protein][ana_dict] = None\n",
    "                    continue\n",
    "                else:\n",
    "                    net_file = f\"{main_dir}/execution_model/network_{network}.dat\"\n",
    "\n",
    "            else:\n",
    "                net_file = f\"{main_dir}/execution_model/network_{network}.dat\"\n",
    "\n",
    "            exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "            output_folder = f\"{main_dir}/outputs_extracted\"\n",
    "\n",
    "            # prot_file = f\"{main_dir}/execution_model/protocol.dat\" # no protocol used , name added after if needed\n",
    "            pipeline_prot = pipeline_protocol(auto_validate=True)\n",
    "            # pipeline_prot.name(\"\")\n",
    "\n",
    "            # initialise the network object\n",
    "            all_analysis_object = analysis_network(\n",
    "                output_folder,\n",
    "                exp_file=exp_file,\n",
    "                net_file=net_file,\n",
    "                analysis_prot=ana_prot,\n",
    "                # method=pipeline_prot.name(),  # if the protocol had a name\n",
    "                # engines=pipeline_prot.engines(),\n",
    "            )\n",
    "\n",
    "            if ana_dict == \"single\":\n",
    "                all_analysis_object.file_ext = (\n",
    "                    all_analysis_object.file_ext + f\"_{ana_dict}\"\n",
    "                )\n",
    "\n",
    "            # compute\n",
    "            try:\n",
    "                all_analysis_object.compute_results()\n",
    "            except:\n",
    "                print(\"failed analysis\")\n",
    "\n",
    "            # add ligands folder\n",
    "            all_analysis_object.add_ligands_folder(\n",
    "                f\"{bench_folder}/inputs/reruns/{protein}/ligands_intermediates\"\n",
    "            )\n",
    "\n",
    "            ana_obj_dict[protein][ana_dict] = all_analysis_object\n",
    "\n",
    "    # print(ana_obj_dict)\n",
    "\n",
    "    network_dict[network] = ana_obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj_dict = network_dict[\"lomap\"]\n",
    "\n",
    "# initial\n",
    "ana_obj = ana_obj_dict[\"tyk2\"][\"plain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check maximum possible accuracy\n",
    "r2_dict = {}\n",
    "r2_error_dict = {}\n",
    "for prot in prot_dict_name.keys():\n",
    "    r2_dict[prot] = {}\n",
    "    r2_error_dict[prot] = {}\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "    print(prot, len(ana_obj.ligands))\n",
    "    print(\n",
    "        \"max\",\n",
    "        max(ana_obj.exper_val_dict.values())[0],\n",
    "        \"min\",\n",
    "        min(ana_obj.exper_val_dict.values())[0],\n",
    "        \"range\",\n",
    "        max(ana_obj.exper_val_dict.values())[0]\n",
    "        - min(ana_obj.exper_val_dict.values())[0],\n",
    "    )\n",
    "    avg = np.mean([val[1] for val in ana_obj.exper_val_dict.values()])\n",
    "    std = np.std([val[0] for val in ana_obj.exper_val_dict.values()])\n",
    "    print(\"mean of error\", avg, \"std of val\", std)\n",
    "    # experimental uncertainty is std of measurement error\n",
    "    # max is measurement error / std dev of the affinity , squared\n",
    "    # tyk2 mcl1 Ki 0.44\n",
    "    # others IC50 0.75\n",
    "    r2max = 1 - (avg / std) ** 2\n",
    "    print(r2max)\n",
    "    r2_dict[prot][\"maximum\"] = r2max\n",
    "    r2_error_dict[prot][\"maximum\"] = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make single vs triplicate results\n",
    "for prot in ana_obj_dict.keys():\n",
    "    for r in range(0, 3, 1):\n",
    "        ana_obj = ana_obj_dict[prot][f\"single_{r}\"]\n",
    "        # function for single dicts\n",
    "        ana_obj.compute_single_repeat_results(repeat=r)\n",
    "        for eng in [\"AMBER\", \"SOMD\", \"GROMACS\"]:\n",
    "            print(prot, eng)\n",
    "            ana_obj.change_name(eng, f\"{eng}_old\")\n",
    "            ana_obj.change_name(f\"{eng}_single\", eng)\n",
    "            if eng not in ana_obj.engines:\n",
    "                ana_obj.engines.append(eng)\n",
    "            if eng in ana_obj.other_results_names:\n",
    "                ana_obj.other_results_names.remove(eng)\n",
    "        print(ana_obj.engines + ana_obj.other_results_names)\n",
    "        print(ana_obj.calc_pert_dict[eng])\n",
    "\n",
    "# # error for a perturbation per single run\n",
    "\n",
    "# uncertainty_dict_single = {}\n",
    "\n",
    "# for eng in all_analysis_object.engines:\n",
    "#     uncertainty_dict_single[eng] = {}\n",
    "#     repeat = 0\n",
    "#     for file in all_analysis_object._results_repeat_files[eng]:\n",
    "#         uncertainty_dict_single[eng][repeat] = {}\n",
    "#         calc_diff_dict = make_dict.comp_results(\n",
    "#             file, all_analysis_object.perturbations, eng, name=None\n",
    "#         )\n",
    "\n",
    "#         for pert in calc_diff_dict.keys():\n",
    "#             uncertainty_dict_single[eng][repeat][pert] = calc_diff_dict[pert][1]\n",
    "\n",
    "#         repeat += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify any outliers and plot again if needed above\n",
    "failed_perts_dict_percen = {}\n",
    "failed_perts_dict = {}\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    failed_perts_dict_percen[prot_dict_name[prot]] = {}\n",
    "    failed_perts_dict[prot_dict_name[prot]] = {}\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "    print(prot)\n",
    "    for eng in ana_obj.engines:  # ana_obj.engines\n",
    "        failed_perts_dict_percen[prot_dict_name[prot]][eng_dict_name[eng]] = (\n",
    "            100 - ana_obj.successful_perturbations(eng)[1]\n",
    "        )\n",
    "        failed_perts_dict[prot_dict_name[prot]][\n",
    "            eng_dict_name[eng]\n",
    "        ] = ana_obj.failed_perturbations(eng)\n",
    "        print(\n",
    "            f\"failed percentage for {eng}: {100 - ana_obj.successful_perturbations(eng)[1]} ({len(ana_obj.perturbations) - len(ana_obj.successful_perturbations(eng)[2])} / {len(ana_obj.perturbations)})\"\n",
    "        )\n",
    "        print(f\"{eng} failed perturbations: {ana_obj.failed_perturbations(engine=eng)}\")\n",
    "        print(f\"{eng} disconnected ligands: {ana_obj.disconnected_ligands(engine=eng)}\")\n",
    "        print(f\"outliers {eng}: {ana_obj.get_outliers(threshold=10, name=eng)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the 2 fs and reverse runs\n",
    "failed_dict = failed_perts_dict\n",
    "twofs_run_dict = {\n",
    "    \"TYK2\": {\n",
    "        \"AMBER22\": [\n",
    "            \"lig_ejm48~lig_ejm53\",\n",
    "            \"lig_ejm31~lig_ejm54\",\n",
    "            \"lig_ejm31~lig_ejm43\",\n",
    "        ],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [],\n",
    "    },\n",
    "    \"MCL1\": {\n",
    "        \"AMBER22\": [\n",
    "            \"lig_27~lig_39\",\n",
    "            \"lig_32~lig_34\",\n",
    "            \"lig_65~lig_67\",\n",
    "            \"lig_53~lig_58\",\n",
    "            \"lig_53~lig_63\",\n",
    "            \"lig_37~lig_65\",\n",
    "            \"lig_37~lig_67\",\n",
    "            \"lig_39~lig_67\",\n",
    "            \"lig_61~lig_63\",\n",
    "            \"lig_27~lig_65\",\n",
    "            \"lig_27~lig_60\",\n",
    "            \"lig_27~lig_63\",\n",
    "            \"lig_34~lig_53\",\n",
    "            \"lig_27~lig_37\",\n",
    "            \"lig_50~lig_56\",\n",
    "        ],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [],\n",
    "    },\n",
    "    \"P38Î±\": {\n",
    "        \"AMBER22\": [\n",
    "            \"lig_2y~lig_2w\",\n",
    "            \"lig_2ee~lig_2a\",\n",
    "            \"lig_2ff~lig_2g\",\n",
    "            \"lig_2bb~lig_2z\",\n",
    "            \"lig_2ee~lig_2l\",\n",
    "            \"lig_2gg~lig_2j\",\n",
    "            \"lig_2ee~lig_2j\",\n",
    "            \"lig_2ee~lig_2w\",\n",
    "            \"lig_2p~lig_2t\",\n",
    "            \"lig_2ii~lig_2v\",\n",
    "            \"lig_2m~lig_2x\",\n",
    "            \"lig_2a~lig_2gg\",\n",
    "            \"lig_2ii~Intermediate_6\",\n",
    "        ],\n",
    "        \"SOMD1\": [\"lig_2b~lig_2h\", \"lig_2dd~lig_2hh\"],\n",
    "        \"GROMACS23\": [\n",
    "            \"lig_2bb~lig_2w\",\n",
    "            \"lig_2j~lig_2k\",\n",
    "            \"lig_2n~lig_2a\",\n",
    "            \"lig_2o~lig_2a\",\n",
    "            \"lig_2p~lig_2a\",\n",
    "            \"lig_2t~lig_2a\",\n",
    "            \"lig_2y~lig_2w\",\n",
    "            \"lig_2dd~lig_2w\",\n",
    "            \"lig_2b~Intermediate_2\",\n",
    "            \"lig_2d~Intermediate\",\n",
    "            \"lig_2bb~lig_2v\",\n",
    "            \"lig_2aa~lig_2v\",\n",
    "            \"lig_2b~lig_2w\",\n",
    "            \"lig_2b~lig_2z\",\n",
    "            \"lig_2ii~lig_2v\",\n",
    "            \"lig_2t~lig_2x\",\n",
    "            \"lig_2l~lig_2x\",\n",
    "            \"lig_2gg~lig_2k\",\n",
    "            \"lig_2a~lig_2k\",\n",
    "        ],\n",
    "    },\n",
    "    \"SYK\": {\n",
    "        \"AMBER22\": [\n",
    "            \"lig_CHEMBL3265005~lig_CHEMBL3265026\",\n",
    "            \"lig_CHEMBL3265016~lig_CHEMBL3265018\",\n",
    "            \"lig_CHEMBL3265018~lig_CHEMBL3265020\",\n",
    "            \"lig_CHEMBL3265025~lig_CHEMBL3265026\",\n",
    "            \"lig_CHEMBL3265017~lig_CHEMBL3265021\",\n",
    "        ],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [\n",
    "            \"lig_CHEMBL3259820~lig_CHEMBL3264999\",\n",
    "            \"lig_CHEMBL3264996~lig_CHEMBL3264999\",\n",
    "            \"lig_CHEMBL3265006~lig_CHEMBL3265009\",\n",
    "            \"lig_CHEMBL3259820~lig_CHEMBL3265005\",\n",
    "            \"lig_CHEMBL3265005~lig_CHEMBL3265026\",\n",
    "        ],\n",
    "    },\n",
    "    \"HIF2A\": {\n",
    "        \"AMBER22\": [],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [\"lig_235~lig_266\", \"lig_251~lig_256\"],\n",
    "    },\n",
    "    \"CMET\": {\n",
    "        \"AMBER22\": [\n",
    "            \"lig_CHEMBL3402753_200~lig_CHEMBL3402761_1\",\n",
    "            \"lig_CHEMBL3402744_300~lig_CHEMBL3402745_200\",\n",
    "            \"lig_CHEMBL3402747_3400~lig_CHEMBL3402751_2100\",\n",
    "            \"lig_CHEMBL3402754_40~lig_CHEMBL3402755_4200\",\n",
    "            \"lig_CHEMBL3402753_200~lig_CHEMBL3402754_40\",\n",
    "        ],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [\n",
    "            \"lig_CHEMBL3402744_300~lig_CHEMBL3402748_5300\",\n",
    "            \"lig_CHEMBL3402744_300~lig_CHEMBL3402753_200\",\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "reverse_run_dict = {\n",
    "    \"TYK2\": {\n",
    "        \"AMBER22\": [],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [],\n",
    "    },\n",
    "    \"MCL1\": {\n",
    "        \"AMBER22\": [\"lig_65~lig_67\", \"lig_37~lig_67\", \"lig_39~lig_67\", \"lig_61~lig_63\"],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [],\n",
    "    },\n",
    "    \"P38Î±\": {\n",
    "        \"AMBER22\": [],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [],\n",
    "    },\n",
    "    \"SYK\": {\n",
    "        \"AMBER22\": [],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [],\n",
    "    },\n",
    "    \"HIF2A\": {\n",
    "        \"AMBER22\": [],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [],\n",
    "    },\n",
    "    \"CMET\": {\n",
    "        \"AMBER22\": [],\n",
    "        \"SOMD1\": [],\n",
    "        \"GROMACS23\": [],\n",
    "    },\n",
    "}\n",
    "\n",
    "failed_actual_dict = {\n",
    "    \"TYK2\": {\n",
    "        \"AMBER22\": len(failed_dict[\"TYK2\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(failed_dict[\"TYK2\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(failed_dict[\"TYK2\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"MCL1\": {\n",
    "        \"AMBER22\": len(failed_dict[\"MCL1\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(failed_dict[\"MCL1\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(failed_dict[\"MCL1\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"P38Î±\": {\n",
    "        \"AMBER22\": len(failed_dict[\"P38Î±\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(failed_dict[\"P38Î±\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(failed_dict[\"P38Î±\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"SYK\": {\n",
    "        \"AMBER22\": len(failed_dict[\"SYK\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(failed_dict[\"SYK\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(failed_dict[\"SYK\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"HIF2A\": {\n",
    "        \"AMBER22\": len(failed_dict[\"HIF2A\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(failed_dict[\"HIF2A\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(failed_dict[\"HIF2A\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"CMET\": {\n",
    "        \"AMBER22\": len(failed_dict[\"CMET\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(failed_dict[\"CMET\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(failed_dict[\"CMET\"][\"GROMACS23\"]),\n",
    "    },\n",
    "}\n",
    "twofs_dict = {\n",
    "    \"TYK2\": {\n",
    "        \"AMBER22\": len(twofs_run_dict[\"TYK2\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(twofs_run_dict[\"TYK2\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(twofs_run_dict[\"TYK2\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"MCL1\": {\n",
    "        \"AMBER22\": len(twofs_run_dict[\"MCL1\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(twofs_run_dict[\"MCL1\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(twofs_run_dict[\"MCL1\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"P38Î±\": {\n",
    "        \"AMBER22\": len(twofs_run_dict[\"P38Î±\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(twofs_run_dict[\"P38Î±\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(twofs_run_dict[\"P38Î±\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"SYK\": {\n",
    "        \"AMBER22\": len(twofs_run_dict[\"SYK\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(twofs_run_dict[\"SYK\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(twofs_run_dict[\"SYK\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"HIF2A\": {\n",
    "        \"AMBER22\": len(twofs_run_dict[\"HIF2A\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(twofs_run_dict[\"HIF2A\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(twofs_run_dict[\"HIF2A\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"CMET\": {\n",
    "        \"AMBER22\": len(twofs_run_dict[\"CMET\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(twofs_run_dict[\"CMET\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(twofs_run_dict[\"CMET\"][\"GROMACS23\"]),\n",
    "    },\n",
    "}\n",
    "reverse_dict = {\n",
    "    \"TYK2\": {\n",
    "        \"AMBER22\": len(reverse_run_dict[\"TYK2\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(reverse_run_dict[\"TYK2\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(reverse_run_dict[\"TYK2\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"MCL1\": {\n",
    "        \"AMBER22\": len(reverse_run_dict[\"MCL1\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(reverse_run_dict[\"MCL1\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(reverse_run_dict[\"MCL1\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"P38Î±\": {\n",
    "        \"AMBER22\": len(reverse_run_dict[\"P38Î±\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(reverse_run_dict[\"P38Î±\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(reverse_run_dict[\"P38Î±\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"SYK\": {\n",
    "        \"AMBER22\": len(reverse_run_dict[\"SYK\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(reverse_run_dict[\"SYK\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(reverse_run_dict[\"SYK\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"HIF2A\": {\n",
    "        \"AMBER22\": len(reverse_run_dict[\"HIF2A\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(reverse_run_dict[\"HIF2A\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(reverse_run_dict[\"HIF2A\"][\"GROMACS23\"]),\n",
    "    },\n",
    "    \"CMET\": {\n",
    "        \"AMBER22\": len(reverse_run_dict[\"CMET\"][\"AMBER22\"]),\n",
    "        \"SOMD1\": len(reverse_run_dict[\"CMET\"][\"SOMD1\"]),\n",
    "        \"GROMACS23\": len(reverse_run_dict[\"CMET\"][\"GROMACS23\"]),\n",
    "    },\n",
    "}\n",
    "\n",
    "df_failed = pd.DataFrame(failed_actual_dict).T\n",
    "df_twofs = pd.DataFrame(twofs_dict).T\n",
    "df_reverse = pd.DataFrame(reverse_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the failed perturbations\n",
    "# df = pd.DataFrame(failed_perts_dict_percen).T\n",
    "# ax =df.plot(color=pipeline.analysis.set_colours(),\n",
    "#     kind=\"bar\", xlabel=\"Protein System\", ylabel=\"failed perturbations (%)\")\n",
    "\n",
    "\n",
    "ax = df_failed.plot(\n",
    "    color=col_dict,\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=\"Number of failed perturbations\",\n",
    ")\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_protocol_dict = {\n",
    "    \"AMBER22\": {\n",
    "        \"4 fs\": 354\n",
    "        - (\n",
    "            np.sum(df_reverse[\"AMBER22\"])\n",
    "            + np.sum(df_twofs[\"AMBER22\"])\n",
    "            + np.sum(df_failed[\"AMBER22\"])\n",
    "        ),\n",
    "        \"2 fs\": np.sum(df_twofs[\"AMBER22\"]),\n",
    "        \"2 fs reverse\": np.sum(df_reverse[\"AMBER22\"]),\n",
    "        \"failed\": np.sum(df_failed[\"AMBER22\"]),\n",
    "    },\n",
    "    \"GROMACS23\": {\n",
    "        \"4 fs\": 354\n",
    "        - (\n",
    "            np.sum(df_reverse[\"GROMACS23\"])\n",
    "            + np.sum(df_twofs[\"GROMACS23\"])\n",
    "            + np.sum(df_failed[\"GROMACS23\"])\n",
    "        ),\n",
    "        \"2 fs\": np.sum(df_twofs[\"GROMACS23\"]),\n",
    "        \"2 fs reverse\": np.sum(df_reverse[\"GROMACS23\"]),\n",
    "        \"failed\": np.sum(df_failed[\"GROMACS23\"]),\n",
    "    },\n",
    "    \"SOMD1\": {\n",
    "        \"4 fs\": 354\n",
    "        - (\n",
    "            np.sum(df_reverse[\"SOMD1\"])\n",
    "            + np.sum(df_twofs[\"SOMD1\"])\n",
    "            + np.sum(df_failed[\"SOMD1\"])\n",
    "        ),\n",
    "        \"2 fs\": np.sum(df_twofs[\"SOMD1\"]),\n",
    "        \"2 fs reverse\": np.sum(df_reverse[\"SOMD1\"]),\n",
    "        \"failed\": np.sum(df_failed[\"SOMD1\"]),\n",
    "    },\n",
    "}\n",
    "# for key in adaptive_protocol_dict:\n",
    "#     print(key)\n",
    "#     assert np.sum(adaptive_protocol_dict[key].values) == 354\n",
    "# total no of perturbations is 354\n",
    "df = pd.DataFrame(adaptive_protocol_dict).T.rename(eng_dict_name)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), dpi=500)\n",
    "df.plot(\n",
    "    color=[\"darkslateblue\", \"purple\", \"orchid\", \"lavender\"],\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"MD engine\",\n",
    "    ylabel=\"Number of perturbations\",\n",
    "    ax=ax,\n",
    "    width=0.8,\n",
    ")\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        str(p.get_height()),\n",
    "        (p.get_x() + p.get_width() / 2.0, p.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "ax.legend(loc=\"center right\", fontsize=10)\n",
    "plt.xlabel(\"MD Engine\", fontsize=12)\n",
    "plt.ylabel(\"Number of perturbations\", fontsize=12)\n",
    "plt.tick_params(axis=\"x\", labelsize=10, rotation=0)\n",
    "plt.tick_params(axis=\"y\", labelsize=10, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude outliers\n",
    "threshold = 10\n",
    "for prot in ana_obj_dict.keys():\n",
    "    for name in ana_dicts.keys():\n",
    "        print(prot, name)\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            ana_obj.file_ext = ana_obj.file_ext + f\"_outliers{threshold}removed\"\n",
    "            ana_obj.remove_outliers(threshold=threshold, name=eng)\n",
    "        # print(ana_obj.file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_range(val_list):\n",
    "    min_val = min(val_list)\n",
    "    max_val = max(val_list)\n",
    "    # print(min_val)\n",
    "    # print(max_val)\n",
    "\n",
    "    return max_val[0] - min_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max edge range\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        # names = [val for val in ana_obj.calc_pert_dict[eng].keys()]\n",
    "        # vals = [val[0] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "        # sems = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "        # print(prot, eng, names[sems.index(max(sems))],\n",
    "        #       vals[sems.index(max(sems))], sems[sems.index(max(sems))])\n",
    "        ranges = []\n",
    "        for pert in ana_obj._perturbations_dict[eng]:\n",
    "            try:\n",
    "                ra = val_range(\n",
    "                    [ana_obj.calc_repeat_pert_dict[eng][r][pert] for r in [0, 1, 2]]\n",
    "                )\n",
    "                ranges.append(ra)\n",
    "            except:\n",
    "                pass\n",
    "        clean_ranges = [x for x in ranges if str(x) != \"nan\"]\n",
    "        print(f\"{eng}, {np.mean(clean_ranges):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte the differences in SEM\n",
    "# SEM differences\n",
    "\n",
    "sem_dict = {}\n",
    "sem_dict_name = {}\n",
    "\n",
    "for name in ana_dicts:\n",
    "    sem_list_name = []\n",
    "    sem_dict[name] = {}\n",
    "\n",
    "    for prot in ana_obj_dict.keys():\n",
    "        sem_dict[name][prot] = {}\n",
    "\n",
    "        ana_obj = ana_obj_dict[prot][name]  # subsampling\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            sem_dict[name][prot][eng] = {}\n",
    "\n",
    "            sem_list = []\n",
    "            sems = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "            sem_list.append(sems)\n",
    "            sem_list_name.append(sems)\n",
    "\n",
    "            sem_list = reduce(lambda xs, ys: xs + ys, sem_list)\n",
    "            sem_list = [x for x in sem_list if str(x) != \"nan\"]\n",
    "\n",
    "            # if not check_normal_dist(sem_list):\n",
    "            #     print(f\"{prot} {name} not normally dist\")\n",
    "\n",
    "            mean = np.mean(sem_list)\n",
    "            lower_ci, upper_ci = _stats.norm.interval(\n",
    "                confidence=0.95, loc=np.mean(sem_list), scale=_stats.sem(sem_list)\n",
    "            )\n",
    "            print(prot, name, eng, mean, lower_ci, upper_ci)\n",
    "            sem_dict[name][prot][eng] = (\n",
    "                mean,\n",
    "                _stats.tstd(sem_list),\n",
    "                (lower_ci, upper_ci),\n",
    "                sem_list,\n",
    "            )\n",
    "\n",
    "    sem_list_name = reduce(lambda xs, ys: xs + ys, sem_list_name)\n",
    "    sem_list_name = [x for x in sem_list_name if str(x) != \"nan\"]\n",
    "    mean = np.mean(sem_list_name)\n",
    "    lower_ci, upper_ci = _stats.norm.interval(\n",
    "        confidence=0.95, loc=np.mean(sem_list_name), scale=_stats.sem(sem_list_name)\n",
    "    )\n",
    "    print(name, mean, lower_ci, upper_ci)\n",
    "    sem_dict_name[name] = (\n",
    "        mean,\n",
    "        _stats.tstd(sem_list_name),\n",
    "        (lower_ci, upper_ci),\n",
    "        sem_list_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also calc mae perts\n",
    "\n",
    "mae_dict = {}\n",
    "\n",
    "for name in ana_dicts:\n",
    "    mae_dict[name] = {}\n",
    "\n",
    "    for prot in ana_obj_dict.keys():\n",
    "        print(prot, name)\n",
    "\n",
    "        mae_dict[name][prot] = {}\n",
    "\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "\n",
    "        stats_string_all = \"\"\n",
    "        try:\n",
    "            mae = ana_obj.calc_mae_engines(pert_val=\"pert\", recalculate=False)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            stats_string = \"\"\n",
    "            try:\n",
    "                mae_dict[name][prot][eng] = (\n",
    "                    mae[0][eng][\"experimental\"],\n",
    "                    mae[1][eng][\"experimental\"],\n",
    "                    mae[2][eng][\"experimental\"],\n",
    "                )\n",
    "                stats_string += f\"{eng} MAE: {mae[0][eng]['experimental']:.2f} +/- {mae[1][eng]['experimental']:.2f} kcal/mol, \"\n",
    "\n",
    "                if sem_dict[name][prot][eng][0]:\n",
    "                    stats_string += f\"SEM: {sem_dict[name][prot][eng][0]:.2f} +/- {sem_dict[name][prot][eng][1]:.2f} kcal/mol\\n\"\n",
    "                elif name == \"single\":\n",
    "                    errors = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "                    stats_string += f\"error: {np.mean(errors):.2f} +/- {_stats.tstd(errors):.2f} kcal/mol\\n\"\n",
    "\n",
    "                print(stats_string)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"could not compute for {prot} {name} {eng}\")\n",
    "\n",
    "            # try:\n",
    "            #     ana_obj.plot_scatter_ddG(\n",
    "            #         engines=eng, suptitle=f\"{prot}, {method}\\n\", title=f\"{stats_string}\")\n",
    "            #     ana_obj.plot_scatter_ddG(engines=eng, use_cinnabar=True)\n",
    "            # except:\n",
    "            #     pass\n",
    "            # stats_string_all+=stats_string\n",
    "\n",
    "        # try:\n",
    "        #     ana_obj.plot_scatter_ddG(\n",
    "        #         suptitle=f\"{prot}, {method}\\n \\n \\n \\n \\n\", title=f\"{stats_string_all}\", engines=ana_obj.engines)\n",
    "        # except:\n",
    "        #     print(f\"could not plot {prot} {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs based on engine\n",
    "plotting_dict = sem_dict  # mae_dict or sem_dict\n",
    "stats_name = \"ÎÎG SEM\"  # MAE or SEM\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=3, ncols=1, figsize=(20, 20), sharex=True, sharey=True, dpi=500\n",
    ")\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "for engine, pos in zip(ana_obj.engines, [axes[0], axes[1], axes[2]]):\n",
    "    df_list = []\n",
    "    df_err_list = []\n",
    "    for name in ana_dicts:\n",
    "        # print(name)\n",
    "        df = (\n",
    "            pd.DataFrame(plotting_dict[name])\n",
    "            .applymap(lambda x: x[0])\n",
    "            .rename(prot_dict_name, axis=1)\n",
    "            .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "            .rename({engine: name}, axis=1)\n",
    "            .rename(\n",
    "                {\n",
    "                    \"plain\": \"Full data\",\n",
    "                    \"subsampling\": \"Subsampling\",\n",
    "                    \"autoeq\": \"Auto-equilibration\",\n",
    "                    \"1ns\": \"1 ns sampling\",\n",
    "                    \"2ns\": \"2 ns sampling\",\n",
    "                    \"3ns\": \"3 ns sampling\",\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        df_err = (\n",
    "            pd.DataFrame(plotting_dict[name])\n",
    "            .applymap(lambda x: x[1])\n",
    "            .rename(prot_dict_name, axis=1)\n",
    "            .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "            .rename({engine: name}, axis=1)\n",
    "            .rename(\n",
    "                {\n",
    "                    \"plain\": \"Full data\",\n",
    "                    \"subsampling\": \"Subsampling\",\n",
    "                    \"autoeq\": \"Auto-equilibration\",\n",
    "                    \"1ns\": \"1 ns sampling\",\n",
    "                    \"2ns\": \"2 ns sampling\",\n",
    "                    \"3ns\": \"3 ns sampling\",\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # df_lower = df_err.applymap(lambda x: x[0])\n",
    "        # df_upper = df_err.applymap(lambda x: x[1])\n",
    "        # df_err = (df_upper - df_lower) / 2\n",
    "\n",
    "        df_list.append(df)\n",
    "        df_err_list.append(df_err)\n",
    "\n",
    "    df = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        df_list,\n",
    "    )\n",
    "    df_err = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        df_err_list,\n",
    "    )\n",
    "\n",
    "    # print(df)\n",
    "    # print(engine)\n",
    "    # print(df.mean())\n",
    "    # print(df.sem())\n",
    "    # print(df_err)\n",
    "\n",
    "    # engine colours\n",
    "    # col_dict = {\n",
    "    #     \"AMBER\": plt.get_cmap(\"autumn\"),\n",
    "    #     \"SOMD\": plt.get_cmap(\"cool\"),\n",
    "    #     \"GROMACS\": plt.get_cmap(\"viridis\"),\n",
    "    # }\n",
    "\n",
    "    # scale data for compatibility with cmap\n",
    "    data = [i for i in range(1, len(df.columns) + 1)]\n",
    "    den = max(data) - min(data)\n",
    "    scaled_data = [(datum - min(data)) / den for datum in data]\n",
    "\n",
    "    # get colors corresponding to data\n",
    "    colors = []\n",
    "    my_cmap = plt.get_cmap(\"plasma\")  # col_dict[engine]\n",
    "\n",
    "    for decimal in scaled_data:\n",
    "        colors.append(my_cmap(decimal))\n",
    "\n",
    "    df.plot(\n",
    "        kind=\"bar\",\n",
    "        color=colors,\n",
    "        yerr=df_err,\n",
    "        title=eng_dict_name[engine],\n",
    "        ax=pos,\n",
    "        xlabel=\"Protein System\",\n",
    "        ylabel=f\"{stats_name} (kcal/mol)\",\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    if engine == \"AMBER\":\n",
    "        print(\"yay\")\n",
    "        # pos.set_ylim(bottom=0)\n",
    "        pos.legend(loc=\"upper left\", fontsize=12)\n",
    "\n",
    "# fig.suptitle(f'{stats_name} perturbations for LOMAP/RBFENN-score')\n",
    "plt.tick_params(axis=\"x\", labelsize=12, rotation=0)\n",
    "plt.tick_params(axis=\"y\", labelsize=12, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one graph for one method but that compared for each protein\n",
    "plotting_dict = sem_dict  # mae_dict or sem_dict\n",
    "stats_name = \"ÎÎG SEM\"  # MAE or SEM\n",
    "fig, ax = plt.subplots(figsize=(5, 5), dpi=500)\n",
    "plt.xlim = ()\n",
    "plt.ylim = (0, 2)\n",
    "\n",
    "name = \"plain\"\n",
    "df = (\n",
    "    pd.DataFrame(plotting_dict[name])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .rename(prot_dict_name, axis=1)\n",
    "    .T.rename(eng_dict_name, axis=1)\n",
    ")\n",
    "df_err = (\n",
    "    pd.DataFrame(plotting_dict[name])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .rename(prot_dict_name, axis=1)\n",
    "    .T.rename(eng_dict_name, axis=1)\n",
    ")\n",
    "# df_lower = df_err.applymap(lambda x: x[0])\n",
    "# df_upper = df_err.applymap(lambda x: x[1])\n",
    "# df_err = (df_upper - df_lower) / 2\n",
    "ax = df.plot(\n",
    "    kind=\"bar\",\n",
    "    color=col_dict,\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=f\"{stats_name} (kcal/mol)\",\n",
    "    yerr=df_err,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_ylim(bottom=0)\n",
    "plt.tick_params(axis=\"x\", rotation=0)\n",
    "plt.tick_params(axis=\"y\", rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the statistical significance and make a violin plot\n",
    "\n",
    "stats_name = \"ÎÎG SEM\"\n",
    "\n",
    "if stats_name == \"ÎG MAE\":\n",
    "    ana_obj_dict = network_dict[\"lomap\"]\n",
    "    print(\"yay\")\n",
    "else:\n",
    "    ana_obj_dict = network_dict[\"rbfenn\"]\n",
    "\n",
    "# checking for significance\n",
    "eng1 = \"AMBER\"\n",
    "eng2 = \"SOMD\"\n",
    "eng3 = \"GROMACS\"\n",
    "first_err_vals = []\n",
    "second_err_vals = []\n",
    "third_err_vals = []\n",
    "\n",
    "for prot in ana_obj_dict:\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "    filtered_keys = [\n",
    "        key\n",
    "        for key in ana_obj.calc_pert_dict[eng1]\n",
    "        if key in ana_obj.calc_pert_dict[eng2]\n",
    "        and key in ana_obj.calc_pert_dict[eng3]\n",
    "        and not (\n",
    "            np.isnan(ana_obj.calc_pert_dict[eng1][key]).any()\n",
    "            or np.isnan(ana_obj.calc_pert_dict[eng2][key]).any()\n",
    "            or np.isnan(ana_obj.calc_pert_dict[eng3][key]).any()\n",
    "        )\n",
    "    ]\n",
    "    if stats_name == \"ÎÎG MAE\":\n",
    "        # MAE\n",
    "        f_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng1][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "            for key in filtered_keys\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "        s_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng2][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "            for key in filtered_keys\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "        t_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng3][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "            for key in filtered_keys\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "    elif stats_name == \"ÎG MAE\":\n",
    "        # MAE\n",
    "        ligs = [lig for lig in ana_obj.ligands if \"lig_23\" not in lig]\n",
    "        f_err_vals = [\n",
    "            abs(\n",
    "                ana_obj.cinnabar_calc_val_dict[eng1][key][0]\n",
    "                - ana_obj.cinnabar_exper_val_dict[eng1][key][0]\n",
    "            )\n",
    "            for key in ligs\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "        s_err_vals = [\n",
    "            abs(\n",
    "                ana_obj.cinnabar_calc_val_dict[eng2][key][0]\n",
    "                - ana_obj.cinnabar_exper_val_dict[eng2][key][0]\n",
    "            )\n",
    "            for key in ana_obj.ligands\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "        t_err_vals = [\n",
    "            abs(\n",
    "                ana_obj.cinnabar_calc_val_dict[eng3][key][0]\n",
    "                - ana_obj.cinnabar_exper_val_dict[eng3][key][0]\n",
    "            )\n",
    "            for key in ana_obj.ligands\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "    elif stats_name == \"ÎÎG SEM\":\n",
    "        # SEM\n",
    "        f_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng1][key][1]) for key in filtered_keys\n",
    "        ]\n",
    "        s_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng2][key][1]) for key in filtered_keys\n",
    "        ]\n",
    "        t_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng3][key][1]) for key in filtered_keys\n",
    "        ]\n",
    "    else:\n",
    "        print(\"wrong name\")\n",
    "\n",
    "    first_err_vals.append(f_err_vals)\n",
    "    second_err_vals.append(s_err_vals)\n",
    "    third_err_vals.append(t_err_vals)\n",
    "\n",
    "first_err_vals = flatten_comprehension(first_err_vals)\n",
    "second_err_vals = flatten_comprehension(second_err_vals)\n",
    "third_err_vals = flatten_comprehension(third_err_vals)\n",
    "\n",
    "# filtered_data = [t for t in zip(first_err_vals, second_err_vals, third_err_vals) if not any(np.isnan(x) for x in t)]\n",
    "# first_err_vals, second_err_vals, third_err_val = map(list, zip(*filtered_data))\n",
    "valid_indices = [\n",
    "    i\n",
    "    for i in range(len(first_err_vals))\n",
    "    if not (\n",
    "        np.isnan(first_err_vals[i])\n",
    "        or np.isnan(second_err_vals[i])\n",
    "        or np.isnan(third_err_vals[i])\n",
    "    )\n",
    "]\n",
    "first_err_vals = [first_err_vals[i] for i in valid_indices]\n",
    "second_err_vals = [second_err_vals[i] for i in valid_indices]\n",
    "third_err_vals = [third_err_vals[i] for i in valid_indices]\n",
    "\n",
    "assert len(first_err_vals) == len(second_err_vals)\n",
    "assert len(first_err_vals) == len(third_err_vals)\n",
    "assert len(second_err_vals) == len(third_err_vals)\n",
    "\n",
    "eng_list_dict = {}\n",
    "eng_list_dict[eng1] = first_err_vals\n",
    "eng_list_dict[eng2] = second_err_vals\n",
    "eng_list_dict[eng3] = third_err_vals\n",
    "\n",
    "for eng, vals in zip(\n",
    "    [eng1, eng2, eng3], [first_err_vals, second_err_vals, third_err_vals]\n",
    "):\n",
    "    mean = np.mean(vals)\n",
    "    std = np.std(vals)\n",
    "    ci = 1.96 * (std / np.sqrt(len(vals)))\n",
    "    print(f\"{eng}, {mean:.2f} ({mean-ci:.2f},{mean+ci:.2f}) , {std:.2f}\")\n",
    "\n",
    "stats_test_dict = {}\n",
    "\n",
    "for enga in [eng1, eng2, eng3]:\n",
    "    stats_test_dict[enga] = {}\n",
    "    for engb in [eng1, eng2, eng3]:\n",
    "        if enga == engb:\n",
    "            stats_test_dict[enga][engb] = 100\n",
    "        else:\n",
    "            # check normally distributed\n",
    "            if (\n",
    "                _stats.shapiro(\n",
    "                    abs(np.array(eng_list_dict[enga] - np.array(eng_list_dict[engb])))\n",
    "                )[1]\n",
    "                > 0.05\n",
    "            ):\n",
    "                print(\"data is normally distributed !!\")\n",
    "            else:\n",
    "                # absolute error  # ttest_rel\n",
    "                t, p = _stats.wilcoxon(eng_list_dict[enga], eng_list_dict[engb])\n",
    "                stats_test_dict[enga][engb] = p\n",
    "        # print(enga, engb, t, p)\n",
    "\n",
    "df = pd.DataFrame(stats_test_dict).applymap(lambda x: float(x))\n",
    "print(f\"statistical significance for the {stats_name} between engines\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    first_err_vals,\n",
    "    density=True,\n",
    "    color=pipeline.analysis.set_colours()[eng1],\n",
    "    label=eng_dict_name[eng1],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(\n",
    "    second_err_vals,\n",
    "    density=True,\n",
    "    color=pipeline.analysis.set_colours()[eng2],\n",
    "    label=eng_dict_name[eng2],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(\n",
    "    third_err_vals,\n",
    "    density=True,\n",
    "    color=pipeline.analysis.set_colours()[eng3],\n",
    "    label=eng_dict_name[eng3],\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(f\"ddG {stats_name} (kcal/mol)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"All proteins\")\n",
    "# plot for all proteins, and ind proteins too\n",
    "# also check sem error sig again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plots\n",
    "data = {\n",
    "    \"engine\": [f\"{eng_dict_name[eng1]}\"] * len(first_err_vals)\n",
    "    + [f\"{eng_dict_name[eng2]}\"] * len(second_err_vals)\n",
    "    + [f\"{eng_dict_name[eng3]}\"] * len(third_err_vals),\n",
    "    \"error\": flatten_comprehension([first_err_vals, second_err_vals, third_err_vals]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5), dpi=500)\n",
    "sns.violinplot(x=\"engine\", y=\"error\", data=df, inner=\"box\", palette=col_dict)\n",
    "\n",
    "# plt.title(f\"{stats_name} Distribution for Different MD Engines across all protein systems\")\n",
    "plt.tick_params(axis=\"x\", labelsize=12, rotation=0)\n",
    "plt.tick_params(axis=\"y\", labelsize=12, rotation=0)\n",
    "plt.xlabel(\"MD Engine\")\n",
    "plt.ylabel(f\"{stats_name} (kcal/mol)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAD between engines\n",
    "\n",
    "eng1 = \"AMBER\"\n",
    "eng2 = \"SOMD\"\n",
    "eng3 = \"GROMACS\"\n",
    "first_err_vals = []\n",
    "second_err_vals = []\n",
    "third_err_vals = []\n",
    "\n",
    "for prot in ana_obj_dict:\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "    use_dict = ana_obj.calc_pert_dict  # use_dict = ana_obj.calc_pert_dict\n",
    "    filtered_keys = [\n",
    "        key\n",
    "        for key in use_dict[eng1]\n",
    "        if key in use_dict[eng2]\n",
    "        and key in use_dict[eng3]\n",
    "        and not (\n",
    "            np.isnan(use_dict[eng1][key]).any()\n",
    "            or np.isnan(use_dict[eng2][key]).any()\n",
    "            or np.isnan(use_dict[eng3][key]).any()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    f_err_vals = [use_dict[eng1][key][0] for key in filtered_keys]\n",
    "    s_err_vals = [use_dict[eng2][key][0] for key in filtered_keys]\n",
    "    t_err_vals = [use_dict[eng3][key][0] for key in filtered_keys]\n",
    "\n",
    "    first_err_vals.append(f_err_vals)\n",
    "    second_err_vals.append(s_err_vals)\n",
    "    third_err_vals.append(t_err_vals)\n",
    "\n",
    "first_err_vals = flatten_comprehension(first_err_vals)\n",
    "second_err_vals = flatten_comprehension(second_err_vals)\n",
    "third_err_vals = flatten_comprehension(third_err_vals)\n",
    "\n",
    "# filtered_data = [t for t in zip(first_err_vals, second_err_vals, third_err_vals) if not any(np.isnan(x) for x in t)]\n",
    "# first_err_vals, second_err_vals, third_err_val = map(list, zip(*filtered_data))\n",
    "valid_indices = [\n",
    "    i\n",
    "    for i in range(len(first_err_vals))\n",
    "    if not (\n",
    "        np.isnan(first_err_vals[i])\n",
    "        or np.isnan(second_err_vals[i])\n",
    "        or np.isnan(third_err_vals[i])\n",
    "    )\n",
    "]\n",
    "first_err_vals = [first_err_vals[i] for i in valid_indices]\n",
    "second_err_vals = [second_err_vals[i] for i in valid_indices]\n",
    "third_err_vals = [third_err_vals[i] for i in valid_indices]\n",
    "\n",
    "assert len(first_err_vals) == len(second_err_vals)\n",
    "assert len(first_err_vals) == len(third_err_vals)\n",
    "assert len(second_err_vals) == len(third_err_vals)\n",
    "\n",
    "eng_list_dict = {}\n",
    "eng_list_dict[eng1] = first_err_vals\n",
    "eng_list_dict[eng2] = second_err_vals\n",
    "eng_list_dict[eng3] = third_err_vals\n",
    "\n",
    "stats_test_dict = {}\n",
    "\n",
    "for enga in [eng1, eng2, eng3]:\n",
    "    stats_test_dict[enga] = {}\n",
    "    for engb in [eng1, eng2, eng3]:\n",
    "        if enga == engb:\n",
    "            stats_test_dict[enga][engb] = 100\n",
    "        else:\n",
    "            # check normally distributed\n",
    "            if (\n",
    "                _stats.shapiro(\n",
    "                    abs(np.array(eng_list_dict[enga] - np.array(eng_list_dict[engb])))\n",
    "                )[1]\n",
    "                > 0.05\n",
    "            ):\n",
    "                print(\n",
    "                    f\"data is normally distributed for {enga} and {engb}!! Still carrying out wilcoxon signed rank ....\"\n",
    "                )\n",
    "\n",
    "            t, p = _stats.wilcoxon(\n",
    "                eng_list_dict[enga], eng_list_dict[engb]\n",
    "            )  # absolute error  # ttest_rel\n",
    "            stats_test_dict[enga][engb] = p\n",
    "        # print(enga, engb, t, p)\n",
    "\n",
    "df_col = pd.DataFrame(stats_test_dict).applymap(lambda x: float(x))\n",
    "print(\"statistical significance between the perturbations calculated\")\n",
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to each other - MAD\n",
    "engines = ana_obj.engines\n",
    "\n",
    "df = pd.DataFrame(columns=engines, index=engines)\n",
    "df_err = pd.DataFrame(columns=engines, index=engines)\n",
    "df_ci = pd.DataFrame(columns=engines, index=engines)\n",
    "\n",
    "# iterate compared to experimental\n",
    "for eng1, eng2 in it.product(engines, engines):\n",
    "    res = stats_engines.compute_stats(\n",
    "        x=eng_list_dict[eng2], y=eng_list_dict[eng1], statistic=\"MUE\"\n",
    "    )\n",
    "\n",
    "    mean_absolute_error = res[0]  # the computed statistic\n",
    "    err = res[1]  # the stderr from bootstrapping\n",
    "    ci = res[2]\n",
    "\n",
    "    # loc index, column\n",
    "    df.loc[eng2, eng1] = mean_absolute_error\n",
    "    df_err.loc[eng2, eng1] = err\n",
    "    df_ci.loc[eng2, eng1] = ci\n",
    "\n",
    "mad = (df, df_err, df_ci)\n",
    "mad[0].update(mad[0].applymap(lambda x: f\"\" if x == 0 else f\"{x:.2f}\"))\n",
    "mad[2].update(\n",
    "    mad[2].applymap(lambda x: f\"\" if x[0] == 0 else f\"({x[0]:.2f}, {x[1]:.2f})\")\n",
    ")\n",
    "df_val = mad[0].astype(str) + \"\\n\" + mad[2].astype(str)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the stats test\n",
    "\n",
    "# threshold for colour labels\n",
    "color_labels = df_col.applymap(\n",
    "    lambda x: \"white\"\n",
    "    if x == 100\n",
    "    else \"grey\"  # same engine, no stats test\n",
    "    if x > 0.05\n",
    "    else \"pink\"  # no statistically significant difference\n",
    ")  # statistically significant difference\n",
    "\n",
    "# mapping dictionary\n",
    "color_mapping = {\"pink\": \"#FFC0CB\", \"white\": \"#FFFFFF\", \"grey\": \"#BEBEBE\"}\n",
    "\n",
    "# Convert text labels to a numerical array\n",
    "color_numeric = (\n",
    "    df_col.applymap(lambda x: 0 if x == 100 else 1 if x > 0.05 else 2)\n",
    "    .rename(eng_dict_name, axis=1)\n",
    "    .rename(eng_dict_name, axis=0)\n",
    ")\n",
    "\n",
    "# below as otherwise problem if only two colours\n",
    "array_col_dict = {\n",
    "    0: color_mapping[\"white\"],\n",
    "    1: color_mapping[\"grey\"],\n",
    "    2: color_mapping[\"pink\"],\n",
    "}\n",
    "\n",
    "numeric_colours_list = flatten_comprehension(color_numeric.values.tolist())\n",
    "\n",
    "cmap = mcolors.ListedColormap(\n",
    "    [\n",
    "        array_col_dict[key]\n",
    "        for key in array_col_dict.keys()\n",
    "        if key in numeric_colours_list\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot heatmap using numeric mapping for colors\n",
    "fig, ax = plt.subplots(figsize=(4, 4), dpi=500)\n",
    "sns.heatmap(\n",
    "    color_numeric,\n",
    "    annot=df_val,\n",
    "    fmt=\"s\",\n",
    "    cmap=cmap,\n",
    "    cbar=False,\n",
    "    ax=ax,\n",
    ")\n",
    "plt.xticks(rotation=0, fontsize=10)\n",
    "plt.yticks(rotation=90, fontsize=10)\n",
    "\n",
    "legend_patches = [  # mpatches.Patch(color=color_mapping[\"white\"], label=\"\"),\n",
    "    mpatches.Patch(color=color_mapping[\"pink\"], label=\"p â¤ 0.05\"),\n",
    "    mpatches.Patch(color=color_mapping[\"grey\"], label=\"p > 0.05\"),\n",
    "]\n",
    "\n",
    "# Add legend to the plot\n",
    "plt.legend(\n",
    "    handles=legend_patches,\n",
    "    loc=\"center left\",\n",
    "    title=\"Statistical significance\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "\n",
    "plt.title(\"ÎÎG MAD (kcal/mol) between MD engines (95% CI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d contour plot - for all proteins combined\n",
    "stats_name = \"SEM\"\n",
    "\n",
    "for eng1, eng2 in ([\"AMBER\", \"SOMD\"], [\"AMBER\", \"GROMACS\"], [\"GROMACS\", \"SOMD\"]):\n",
    "    first_err_vals = []\n",
    "    second_err_vals = []\n",
    "\n",
    "    for prot in ana_obj_dict:\n",
    "        ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "        filtered_keys = [\n",
    "            key\n",
    "            for key in ana_obj.calc_pert_dict[eng1]\n",
    "            if key\n",
    "            in ana_obj.calc_pert_dict[eng2]  # and key in ana_obj.calc_pert_dict[eng3]\n",
    "            and not (\n",
    "                np.isnan(ana_obj.calc_pert_dict[eng1][key]).any()\n",
    "                or np.isnan(ana_obj.calc_pert_dict[eng2][key]).any()  # or\n",
    "                # np.isnan(ana_obj.calc_pert_dict[eng3][key]).any()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if stats_name == \"SEM\":\n",
    "            # MAE\n",
    "            f_err_vals = [\n",
    "                abs(\n",
    "                    ana_obj.calc_pert_dict[eng1][key][0]\n",
    "                    - ana_obj.exper_pert_dict[key][0]\n",
    "                )\n",
    "                for key in filtered_keys\n",
    "                if not \"Intermediate\" in key\n",
    "            ]\n",
    "            s_err_vals = [\n",
    "                abs(\n",
    "                    ana_obj.calc_pert_dict[eng2][key][0]\n",
    "                    - ana_obj.exper_pert_dict[key][0]\n",
    "                )\n",
    "                for key in filtered_keys\n",
    "                if not \"Intermediate\" in key\n",
    "            ]\n",
    "\n",
    "        elif stats_name == \"MAE\":\n",
    "            # SEM\n",
    "            f_err_vals = [\n",
    "                abs(ana_obj.calc_pert_dict[eng1][key][1]) for key in filtered_keys\n",
    "            ]\n",
    "            s_err_vals = [\n",
    "                abs(ana_obj.calc_pert_dict[eng2][key][1]) for key in filtered_keys\n",
    "            ]\n",
    "\n",
    "        first_err_vals.append(f_err_vals)\n",
    "        second_err_vals.append(s_err_vals)\n",
    "\n",
    "    x = flatten_comprehension(first_err_vals)\n",
    "    y = flatten_comprehension(second_err_vals)\n",
    "    z = np.abs(np.array(x) - np.array(y))  # z = np.sin(x) + np.cos(y)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # # Scatter plot on top to show data points\n",
    "    plt.scatter(x, y, c=z, cmap=\"Purples\", edgecolors=\"black\")\n",
    "    sns.kdeplot(x=x, y=y, cmap=\"PuRd\", fill=True, levels=10, thresh=0.05, alpha=0.7)\n",
    "    plt.colorbar(label=f\"Absolute difference\\n between engine {stats_name} (kcal/mol)\")\n",
    "\n",
    "    # Labels and Title\n",
    "    plt.xlabel(f\"{eng1} {stats_name}\")\n",
    "    plt.ylabel(f\"{eng2} {stats_name}\")\n",
    "    plt.title(f\"{stats_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d contour plot\n",
    "stats_name = \"MAE (kcal/mol)\"\n",
    "\n",
    "for eng1, eng2, eng3 in [\n",
    "    (\"GROMACS\", \"SOMD\", \"AMBER\"),\n",
    "    (\"SOMD\", \"AMBER\", \"GROMACS\"),\n",
    "    (\"AMBER\", \"GROMACS\", \"SOMD\"),\n",
    "]:\n",
    "    first_err_vals = []\n",
    "    second_err_vals = []\n",
    "    third_err_vals = []\n",
    "\n",
    "    for prot in ana_obj_dict:\n",
    "        ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "        filtered_keys = [\n",
    "            key\n",
    "            for key in ana_obj.calc_pert_dict[eng1]\n",
    "            if key in ana_obj.calc_pert_dict[eng2]\n",
    "            and key in ana_obj.calc_pert_dict[eng3]\n",
    "            and not (\n",
    "                np.isnan(ana_obj.calc_pert_dict[eng1][key]).any()\n",
    "                or np.isnan(ana_obj.calc_pert_dict[eng2][key]).any()\n",
    "                or np.isnan(ana_obj.calc_pert_dict[eng3][key]).any()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # MAE\n",
    "        f_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng1][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "            for key in filtered_keys\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "        s_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng2][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "            for key in filtered_keys\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "        t_err_vals = [\n",
    "            abs(ana_obj.calc_pert_dict[eng3][key][0] - ana_obj.exper_pert_dict[key][0])\n",
    "            for key in filtered_keys\n",
    "            if not \"Intermediate\" in key\n",
    "        ]\n",
    "\n",
    "        # SEM\n",
    "        # f_err_vals = [abs(ana_obj.calc_pert_dict[eng1][key][1]) for key in filtered_keys]\n",
    "        # s_err_vals = [abs(ana_obj.calc_pert_dict[eng2][key][1]) for key in filtered_keys]\n",
    "        # t_err_vals = [abs(ana_obj.calc_pert_dict[eng3][key][1]) for key in filtered_keys]\n",
    "\n",
    "        first_err_vals.append(f_err_vals)\n",
    "        second_err_vals.append(s_err_vals)\n",
    "        third_err_vals.append(t_err_vals)\n",
    "\n",
    "    x = np.array(flatten_comprehension(first_err_vals)) - np.array(\n",
    "        flatten_comprehension(second_err_vals)\n",
    "    )\n",
    "    y = np.array(flatten_comprehension(third_err_vals)) - np.array(\n",
    "        flatten_comprehension(second_err_vals)\n",
    "    )\n",
    "    z = np.abs(np.array(x) - np.array(y))  # z = np.sin(x) + np.cos(y)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # # Scatter plot on top to show data points\n",
    "    plt.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        c=flatten_comprehension(second_err_vals),\n",
    "        cmap=\"Purples\",\n",
    "        edgecolors=\"black\",\n",
    "    )\n",
    "    plt.colorbar(label=f\"{eng2} {stats_name}\")\n",
    "    sns.kdeplot(x=x, y=y, cmap=\"PuRd\", fill=True, levels=10, thresh=0.05, alpha=0.7)\n",
    "    ax.axhline(0, color=\"black\", linewidth=1)\n",
    "    ax.axvline(0, color=\"black\", linewidth=1)\n",
    "\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f\"better than {eng3}\\nworse than {eng1}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax.text(\n",
    "        0.70,\n",
    "        0.10,\n",
    "        f\"worse than {eng3}\\nbetter than {eng1}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.10,\n",
    "        f\"worse than {eng3}\\nworse than {eng1}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax.text(\n",
    "        0.70,\n",
    "        0.95,\n",
    "        f\"better than {eng3}\\nbetter than {eng1}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    # Labels and Title\n",
    "    plt.xlabel(f\"{eng1}-{eng2} {stats_name}\")\n",
    "    plt.ylabel(f\"{eng3}-{eng2} {stats_name}\")\n",
    "    plt.title(f\"{eng2} {stats_name.replace('(kcal/mol)','')}comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlating the number of perturbed atoms with precision (SEM) and accuracy (MAE)\n",
    "\n",
    "pert_overlap_dict = {}\n",
    "\n",
    "for prot in ana_obj_dict:\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "    df = ana_obj.perturbing_atoms_and_overlap(read_file=True)\n",
    "\n",
    "    df[\"score\"] = np.nan\n",
    "    # read in all the lomap scores\n",
    "    score_dict = {}\n",
    "    # print(f\"{main_dir}/execution_model/network_scores.dat\")\n",
    "    with open(\n",
    "        f\"{join('/', *ana_obj.output_folder.split('/')[:-1])}/execution_model/network_scores.dat\"\n",
    "    ) as lfile:\n",
    "        for line in lfile:\n",
    "            score_dict[\n",
    "                f\"{line.split(',')[0].strip()}~{line.split(',')[1].strip()}\"\n",
    "            ] = float(line.split(\",\")[-1].strip())\n",
    "    print(score_dict)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"perturbation\"] not in ana_obj.perturbations:\n",
    "            df = df.drop(index)\n",
    "        else:\n",
    "            try:\n",
    "                df.at[index, \"score\"] = score_dict[row[\"perturbation\"]]\n",
    "            except:\n",
    "                try:\n",
    "                    df.at[index, \"score\"] = score_dict[\n",
    "                        f'{row[\"perturbation\"].split(\"~\")[1]}~{row[\"perturbation\"].split(\"~\")[0]}'\n",
    "                    ]\n",
    "                except:\n",
    "                    # print(f\"not {row['perturbation']}\")\n",
    "                    pass\n",
    "\n",
    "    pert_overlap_dict[prot] = df\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        df2 = df[df[\"engine\"] == eng]\n",
    "        print(prot, eng, len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.concat(pert_overlap_dict.values())\n",
    "\n",
    "df_plot.rename(\n",
    "    columns={\n",
    "        \"perturbing_atoms\": \"Average number of perturbing atoms\",\n",
    "        \"diff_to_exp\": \"MAE (kcal/mol)\",\n",
    "        \"percen_overlap_okay\": \"Overlap > 0.03 (%)\",\n",
    "        \"error\": \"SEM (kcal/mol)\",\n",
    "        \"score\": \"LOMAP-score\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "x = \"LOMAP-score\"\n",
    "y = \"MAE (kcal/mol)\"\n",
    "z = \"SEM (kcal/mol)\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# sns.kdeplot(x=df_plot[x], y=df_plot[y], cmap=\"PuRd\", fill=True, levels=10, thresh=0.05)\n",
    "df_plot.plot.scatter(\n",
    "    x,\n",
    "    y,\n",
    "    c=z,\n",
    "    colormap=\"plasma\",\n",
    "    ax=ax,  # vmin=0, vmax=100, ax=ax\n",
    ")\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    df2 = df_plot[df_plot[\"engine\"] == eng]\n",
    "    print(len(df2))\n",
    "    df2.plot.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        c=z,\n",
    "        colormap=\"plasma\",\n",
    "        title=eng_dict_name[eng],  # vmin=80, vmax=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = {}\n",
    "len_list = {}\n",
    "for eng in ana_obj.engines:\n",
    "    mae_list[eng_dict_name[eng]] = []\n",
    "    len_list[eng_dict_name[eng]] = []\n",
    "    df2 = df_plot[df_plot[\"engine\"] == eng]\n",
    "    print(len(df2))\n",
    "    df_check_good = df2[df2[\"Overlap > 0.03 (%)\"] >= 100]\n",
    "\n",
    "    for percen_hi, percen_l in zip([120, 100, 80, 40, 20], [100, 80, 40, 20, 0]):\n",
    "        # df3 = df2[df2[\"Overlap > 0.03 (%)\"] >= percen_l]\n",
    "        df_check_bad = df2[df2[\"Overlap > 0.03 (%)\"] < percen_hi]\n",
    "        print(len(df_check_bad))\n",
    "        mae_list[eng_dict_name[eng]].append(df_check_bad[\"MAE (kcal/mol)\"].mean())\n",
    "        len_list[eng_dict_name[eng]].append(len(df_check_bad))\n",
    "\n",
    "    print(eng, np.sum(len_list[eng_dict_name[eng]]))\n",
    "\n",
    "    # print(eng, len(df_check_good), len(df_check_bad))\n",
    "    print(mae_list[eng_dict_name[eng]])\n",
    "\n",
    "# doubel check w lomap score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Plot the MAE data\n",
    "df = pd.DataFrame(mae_list)\n",
    "ax1.plot(\n",
    "    [100, 80, 60, 40, 20], df[\"AMBER22\"], color=col_dict[\"AMBER22\"], label=\"AMBER22\"\n",
    ")\n",
    "ax1.plot([100, 80, 60, 40, 20], df[\"SOMD1\"], color=col_dict[\"SOMD1\"], label=\"SOMD1\")\n",
    "ax1.plot(\n",
    "    [100, 80, 60, 40, 20],\n",
    "    df[\"GROMACS23\"],\n",
    "    color=col_dict[\"GROMACS23\"],\n",
    "    label=\"GROMACS23\",\n",
    ")\n",
    "ax1.set_xlabel(\n",
    "    \"Amount of overlap off-diagonals greater\\nthan 0.03 per perturbation (%)\"\n",
    ")\n",
    "ax1.set_ylabel(\"ÎÎG MAE (kcal/mol)\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "\n",
    "# Create a secondary y-axis\n",
    "# ax2 = ax1.twinx()\n",
    "\n",
    "# # Plot the length data\n",
    "# df_len = pd.DataFrame(len_list)\n",
    "# bar_width = 2\n",
    "# positions = [100, 80, 60, 40, 20]\n",
    "\n",
    "# ax2.bar([p - bar_width for p in positions], df_len[\"AMBER22\"], width=bar_width, color=col_dict[\"AMBER22\"], linestyle='--', alpha=0.5)\n",
    "# ax2.bar(positions, df_len[\"SOMD1\"], width=bar_width, color=col_dict[\"SOMD1\"], linestyle='--', alpha=0.5)\n",
    "# ax2.bar([p + bar_width for p in positions], df_len[\"GROMACS23\"], width=bar_width, color=col_dict[\"GROMACS23\"], linestyle='--', alpha=0.5)\n",
    "# ax2.set_ylabel(\"Number of Perturbations\", rotation=270, labelpad=15)\n",
    "\n",
    "# ax2.plot(positions, df_len[\"AMBER22\"],color=col_dict[\"AMBER22\"], linestyle='--', alpha=0.5)\n",
    "# ax2.plot(positions, df_len[\"SOMD1\"], color=col_dict[\"SOMD1\"], linestyle='--', alpha=0.5)\n",
    "# ax2.plot(positions, df_len[\"GROMACS23\"],color=col_dict[\"GROMACS23\"], linestyle='--', alpha=0.5)\n",
    "# ax2.set_ylabel(\"Number of Perturbations (---)\", rotation=270, labelpad=15)\n",
    "\n",
    "# Combine legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"lower left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj_dict = network_dict[\"lomap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing to the literature results for plotting\n",
    "\n",
    "# obtain the literature results\n",
    "\n",
    "fepplus_ligs_dict = {}\n",
    "fepplus_perts_dict = {}\n",
    "hahn_ligs_dict = {}\n",
    "hahn_perts_dict = {}\n",
    "openfe_ligs_dict = {}\n",
    "openfe_perts_dict = {}\n",
    "\n",
    "for prot in ana_obj_dict:\n",
    "    print(prot)\n",
    "\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "    file = (\n",
    "        f\"/home/anna/Documents/benchmark/inputs/other_computed/fepplus/{prot}_perts.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(file, delimiter=\",\")\n",
    "\n",
    "    # for perturbations\n",
    "    fepplus_perts_dict[prot] = {}\n",
    "    for index, row in df.iterrows():\n",
    "        fepplus_perts_dict[prot][\n",
    "            f\"lig_{row['Lig 1'].replace(' flip', '').replace('-charged-pKa-8.1', '').replace(' redocked', '').replace('_n', '').replace(' ground state', '').replace('docked ', '').replace(' adjust', '').replace('ejm_', 'ejm').replace('jmc_', 'jmc').strip()}~lig_{row['Lig 2'].replace(' flip', '').replace('-charged-pKa-8.1', '').replace(' redocked', '').replace('_n', '').replace(' ground state', '').replace('docked ', '').replace(' adjust', '').replace('ejm_', 'ejm').replace('jmc_', 'jmc').strip()}\"\n",
    "        ] = (\n",
    "            row[\"Bennett ddG (kcal/mol)\"],\n",
    "            row[\"Bennett std. error (kcal/mol)\"],\n",
    "        )\n",
    "\n",
    "    write_perts_file(\n",
    "        fepplus_perts_dict[prot],\n",
    "        # .csv\n",
    "        file_path=f\"/home/anna/Documents/benchmark/inputs/{prot}/perts_file_fepplus_new\",\n",
    "    )\n",
    "\n",
    "    # for ligands\n",
    "    file = (\n",
    "        f\"/home/anna/Documents/benchmark/inputs/other_computed/fepplus/{prot}_ligs.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(file, delimiter=\",\")\n",
    "\n",
    "    fepplus_ligs_dict[prot] = {}\n",
    "    for index, row in df.iterrows():\n",
    "        fepplus_ligs_dict[prot][\n",
    "            f\"lig_{row['Ligand name'].replace(' flip', '').replace('-charged-pKa-8.1', '').replace(' redocked', '').replace('_n', '').replace(' ground state', '').replace('docked ', '').replace(' adjust', '').replace('ejm_', 'ejm').replace('jmc_', 'jmc').strip()}\"\n",
    "        ] = (\n",
    "            row[\"Pred. dG (kcal/mol)\"],\n",
    "            row[\"Pred. dG std. error (kcal/mol)\"],\n",
    "        )\n",
    "\n",
    "    normalised_ligs_dict = {}\n",
    "    avg = np.mean([val[0] for val in fepplus_ligs_dict[prot].values()])\n",
    "    for lig in fepplus_ligs_dict[prot]:\n",
    "        normalised_ligs_dict[lig] = (\n",
    "            fepplus_ligs_dict[prot][lig][0] - avg,\n",
    "            fepplus_ligs_dict[prot][lig][1],\n",
    "        )\n",
    "\n",
    "    fepplus_ligs_dict[prot] = normalised_ligs_dict\n",
    "\n",
    "    write_vals_file(\n",
    "        fepplus_ligs_dict[prot],\n",
    "        # .csv\n",
    "        file_path=f\"/home/anna/Documents/benchmark/inputs/{prot}/ligs_file_fepplus_new\",\n",
    "    )\n",
    "\n",
    "    # Hahn et al\n",
    "\n",
    "    file = f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/{prot}.dat\"\n",
    "\n",
    "    df = pd.read_csv(file, delimiter=\"  \")\n",
    "\n",
    "    hahn_perts_dict[prot] = {}\n",
    "    for index, row in df.iterrows():\n",
    "        hahn_perts_dict[prot][f\"{row['edge']}\"] = (\n",
    "            float(row[\"ddg\"]),\n",
    "            float(row[\"ddg_err\"]),\n",
    "        )\n",
    "\n",
    "    # need to convert into kcal/mol\n",
    "    for key in hahn_perts_dict[prot]:\n",
    "        hahn_perts_dict[prot][key] = (\n",
    "            hahn_perts_dict[prot][key][0] * 0.239006,\n",
    "            hahn_perts_dict[prot][key][1] * 0.239006,\n",
    "        )\n",
    "\n",
    "    write_perts_file(\n",
    "        hahn_perts_dict[prot],\n",
    "        # .csv\n",
    "        file_path=f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/perts_file_{prot}\",\n",
    "    )\n",
    "\n",
    "    files = [\n",
    "        f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/perts_file_{prot}.csv\"\n",
    "    ]\n",
    "\n",
    "    calc_diff_dict = make_dict.comp_results(files)  # older method\n",
    "\n",
    "    perts, ligs = get_info_network_from_dict(calc_diff_dict)\n",
    "    exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "    convert.cinnabar_file(\n",
    "        files,\n",
    "        exper_dict,\n",
    "        f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/cinnabar_{prot}\",\n",
    "        perturbations=perts,\n",
    "        method=None,\n",
    "    )\n",
    "\n",
    "    # compute the per ligand for the network\n",
    "    network = _wrangle.FEMap(\n",
    "        f\"/home/anna/Documents/benchmark/inputs/other_computed/hahn/cinnabar_{prot}.csv\"\n",
    "    )\n",
    "\n",
    "    # for self plotting of per ligand\n",
    "    hahn_ligs_dict[prot] = make_dict.from_cinnabar_network_node(network, \"calc\")\n",
    "    hahn_perts_dict[prot] = make_dict.from_cinnabar_network_edges(\n",
    "        network, \"calc\", perts\n",
    "    )\n",
    "\n",
    "    # OpenFE\n",
    "    if prot == \"syk\":\n",
    "        openfe_ligs_dict[prot] = {lig: (np.nan, np.nan) for lig in ana_obj.ligands}\n",
    "        openfe_perts_dict[prot] = {\n",
    "            lig: (np.nan, np.nan) for lig in ana_obj.perturbations\n",
    "        }\n",
    "    else:\n",
    "        df_main = pd.read_csv(\n",
    "            \"/home/anna/Documents/benchmark/inputs/other_computed/openfe/combined_pymbar3_edge_data.csv\"\n",
    "        )\n",
    "\n",
    "        for rep in [0, 1, 2]:\n",
    "            df = df_main[df_main[\"system name\"] == prot]\n",
    "            df[\"freenrg\"] = (\n",
    "                df[f\"complex_repeat_{rep}_DG (kcal/mol)\"]\n",
    "                - df[f\"solvent_repeat_{rep}_DG (kcal/mol)\"]\n",
    "            )\n",
    "            df[\"dG_err_temp\"] = df[f\"complex_repeat_{rep}_DG (kcal/mol)\"].apply(\n",
    "                lambda x: math.pow(x, 2)\n",
    "            ) + df[f\"solvent_repeat_{rep}_DG (kcal/mol)\"].apply(\n",
    "                lambda x: math.pow(x, 2)\n",
    "            )\n",
    "            df[\"error\"] = df[f\"dG_err_temp\"].apply(lambda x: math.sqrt(x))\n",
    "            df[\"lig_0\"] = \"lig_\" + df[\"ligand_A\"].str.replace(\n",
    "                \"_redocked\", \"\", regex=True\n",
    "            ).replace(\"-charged-pKa-8.1\", \"\", regex=True).replace(\n",
    "                \"-flip\", \"\", regex=True\n",
    "            ).replace(\n",
    "                \"ejm_\", \"ejm\", regex=True\n",
    "            ).replace(\n",
    "                \"jmc_\", \"jmc\", regex=True\n",
    "            )\n",
    "            df[\"lig_1\"] = \"lig_\" + df[\"ligand_B\"].str.replace(\n",
    "                \"_redocked\", \"\", regex=True\n",
    "            ).replace(\"-charged-pKa-8.1\", \"\", regex=True).replace(\n",
    "                \"-flip\", \"\", regex=True\n",
    "            ).replace(\n",
    "                \"ejm_\", \"ejm\", regex=True\n",
    "            ).replace(\n",
    "                \"jmc_\", \"jmc\", regex=True\n",
    "            )\n",
    "            df.to_csv(\n",
    "                f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/{prot}_{rep}.csv\",\n",
    "                columns=[\"lig_0\", \"lig_1\", \"freenrg\", \"error\"],\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        files = [\n",
    "            f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/{prot}_{rep}.csv\"\n",
    "            for rep in [0, 1, 2]\n",
    "        ]\n",
    "\n",
    "        calc_diff_dict = make_dict.comp_results(files)  # older method\n",
    "\n",
    "        perts, ligs = get_info_network_from_dict(calc_diff_dict)\n",
    "        exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "        convert.cinnabar_file(\n",
    "            files,\n",
    "            exper_dict,\n",
    "            f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/cinnabar_{prot}\",\n",
    "            perturbations=perts,\n",
    "            method=None,\n",
    "        )\n",
    "\n",
    "        # compute the per ligand for the network\n",
    "        print(\n",
    "            f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/cinnabar_{prot}.csv\"\n",
    "        )\n",
    "        network = _wrangle.FEMap(\n",
    "            f\"/home/anna/Documents/benchmark/inputs/other_computed/openfe/cinnabar_{prot}.csv\"\n",
    "        )\n",
    "\n",
    "        # for self plotting of per ligand\n",
    "        openfe_ligs_dict[prot] = make_dict.from_cinnabar_network_node(network, \"calc\")\n",
    "        openfe_perts_dict[prot] = make_dict.from_cinnabar_network_edges(\n",
    "            network, \"calc\", perts\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate perturbation statistics\n",
    "\n",
    "stats_name = \"KTAU\"\n",
    "print(stats_name)\n",
    "\n",
    "val_dict = {}\n",
    "\n",
    "for prot in ana_obj_dict:\n",
    "    print(prot)\n",
    "\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "    if stats_name == \"MAE\":\n",
    "        func = ana_obj.calc_mae_engines\n",
    "        cinn_stats_name = \"MUE\"\n",
    "\n",
    "    elif stats_name == \"RMSE\":\n",
    "        func = ana_obj.calc_rmse_engines\n",
    "        cinn_stats_name = \"RMSE\"\n",
    "    elif stats_name == \"KTAU\":\n",
    "        func = ana_obj.calc_kendalls_rank_engines\n",
    "        cinn_stats_name = \"KTAU\"\n",
    "\n",
    "    else:\n",
    "        print(\"no\")\n",
    "\n",
    "    val_dict[prot] = {}\n",
    "\n",
    "    res = func(pert_val=\"val\", recalculate=False)  # TODO val/pert\n",
    "    for eng in ana_obj.engines:\n",
    "        val_dict[prot][eng_dict_name[eng]] = (\n",
    "            res[0][eng][\"experimental\"],\n",
    "            res[1][eng][\"experimental\"],\n",
    "            res[2][eng][\"experimental\"],\n",
    "        )\n",
    "    # print(res)\n",
    "\n",
    "    # literature\n",
    "\n",
    "    exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "    for lit_perts_dict, name in zip(\n",
    "        [openfe_ligs_dict[prot], hahn_ligs_dict[prot], fepplus_ligs_dict[prot]],\n",
    "        [\"openfe\", \"hahn\", \"fepplus\"],\n",
    "    ):\n",
    "        # for lit_perts_dict, name in zip([openfe_perts_dict[prot], hahn_perts_dict[prot], fepplus_perts_dict[prot]], [\"openfe\", \"hahn\", \"fepplus\"]):  #\n",
    "        print(name)\n",
    "\n",
    "        if prot == \"syk\" and name == \"openfe\":\n",
    "            val_dict[prot][eng_dict_name[name]] = (\n",
    "                0,\n",
    "                0,\n",
    "                (0, 0),\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        xerr = []\n",
    "        yerr = []\n",
    "\n",
    "        # perturbations = []\n",
    "        # excl = 0\n",
    "        # incl = 0\n",
    "        # for pert in lit_perts_dict:\n",
    "        #     if pert.split(\"~\")[0] in exper_dict.keys() and pert.split(\"~\")[1] in exper_dict.keys():\n",
    "        #         perturbations.append(pert)\n",
    "        #         incl += 1\n",
    "        #     else:\n",
    "        #         excl += 1\n",
    "        # print(\"only including perturbations that also have the same ligands used. Not necessarily the same perturbations.\")\n",
    "        # print(f\"{excl} perturbations excluded for {name}, {incl} included: {incl/(incl+excl)*100}\")\n",
    "\n",
    "        # # additionally only if there are the same perturbations, check what this would be\n",
    "        # use_perts = []\n",
    "        # reverse_perts = []\n",
    "        # for pert in ana_obj.perturbations:\n",
    "        #     if pert in perturbations:\n",
    "        #         use_perts.append(pert)\n",
    "        #     if f\"{pert.split('~')[1]}~{pert.split('~')[0]}\" in perturbations:\n",
    "        #         reverse_perts.append(pert)\n",
    "        # print(f\"{len(use_perts)+len(reverse_perts)} perturbations of these would be the same/reverse perturbations ({(len(use_perts)+len(reverse_perts))/(perturbations)*100} %)\")\n",
    "        # perturbations = flatten_comprehension([use_perts, reverse_perts])\n",
    "\n",
    "        # exper_pert_dict = make_dict.exper_from_perturbations(exper_dict, perturbations)\n",
    "\n",
    "        exper_pert_dict = {}\n",
    "        avg = np.mean([val[0] for val in exper_dict.values()])\n",
    "        for lig in exper_dict:\n",
    "            exper_pert_dict[lig] = (exper_dict[lig][0] - avg, exper_dict[lig][1])\n",
    "\n",
    "        for pert in ana_obj.ligands:  # perturbations\n",
    "            try:\n",
    "                x.append(lit_perts_dict[pert][0])\n",
    "                xerr.append(lit_perts_dict[pert][1])\n",
    "                y.append(exper_pert_dict[pert][0])\n",
    "                yerr.append(exper_pert_dict[pert][1])\n",
    "            except:\n",
    "                print(pert)\n",
    "\n",
    "        # calculate statistics\n",
    "\n",
    "        res = stats_engines.compute_stats(\n",
    "            x=x, xerr=xerr, y=y, yerr=yerr, statistic=cinn_stats_name\n",
    "        )\n",
    "        # print(\"cinnabar\", name, res)\n",
    "\n",
    "        val_dict[prot][eng_dict_name[name]] = (\n",
    "            res[0],\n",
    "            res[1],\n",
    "            res[2],\n",
    "        )\n",
    "\n",
    "df = pd.DataFrame(val_dict)\n",
    "# df.to_markdown()\n",
    "df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_res = pd.DataFrame(val_dict).T.map(lambda x: x[0])\n",
    "fig, ax = plt.subplots(figsize=(8, 5), dpi=500)\n",
    "\n",
    "df_err = pd.DataFrame(val_dict).T.map(lambda x: x[2])\n",
    "df_lower = val_res - df_err.applymap(lambda x: x[0])\n",
    "df_upper = df_err.applymap(lambda x: x[1]) - val_res\n",
    "df_err = np.stack([df_lower.T.values, df_upper.T.values], axis=1)\n",
    "\n",
    "val_res.plot.bar(\n",
    "    color=col_dict,\n",
    "    yerr=df_err,\n",
    "    xlabel=\"All Protein Systems\",\n",
    "    ylabel=f\"{stats_name} (kcal/mol)\",\n",
    "    ax=ax,\n",
    "    legend=None,\n",
    ")\n",
    "# ax.legend(loc='center right', bbox_to_anchor=( # lower center (0.5,1)\n",
    "#     1.35, 0.5), #fancybox=True, shadow=True\n",
    "#     )\n",
    "ax.set_xticklabels([val for val in prot_dict_name.values()], rotation=0)  # [],\n",
    "# ax.set_ylabel(\"Kendall's Tau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# calculate perturbation statistics for all proteins together\n",
    "# comments to plot ligands\n",
    "stats_name = \"RMSE\"\n",
    "print(stats_name)\n",
    "\n",
    "if stats_name == \"MAE\":\n",
    "    cinn_stats_name = \"MUE\"\n",
    "elif stats_name == \"RMSE\":\n",
    "    cinn_stats_name = \"RMSE\"\n",
    "elif stats_name == \"KTAU\":\n",
    "    cinn_stats_name = \"KTAU\"\n",
    "elif stats_name == \"R2\":\n",
    "    cinn_stats_name = \"R2\"\n",
    "\n",
    "val_dict = {}\n",
    "val_dict[\"all\"] = {}\n",
    "\n",
    "for eng in ana_obj.engines:  #\n",
    "    x = []\n",
    "    y = []\n",
    "    xerr = []\n",
    "    yerr = []\n",
    "\n",
    "    for prot in ana_obj_dict:\n",
    "        ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "        exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "        perturbations = []\n",
    "        excl = 0\n",
    "        incl = 0\n",
    "        for pert in ana_obj._perturbations_dict[eng]:\n",
    "            try:\n",
    "                if (\n",
    "                    str(ana_obj.calc_pert_dict[eng][pert][0]) != \"nan\"\n",
    "                    and \"Intermediate\" not in pert\n",
    "                ):\n",
    "                    perturbations.append(pert)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        exper_pert_dict = make_dict.exper_from_perturbations(exper_dict, perturbations)\n",
    "\n",
    "        # exper_pert_dict = {}\n",
    "        # avg = np.mean([val[0] for val in exper_dict.values()])\n",
    "        # for lig in exper_dict:\n",
    "        #     exper_pert_dict[lig] = (exper_dict[lig][0] - avg, exper_dict[lig][1])\n",
    "\n",
    "        for pert in perturbations:\n",
    "            # for pert in ana_obj.ligands:\n",
    "            try:\n",
    "                x.append(ana_obj.calc_pert_dict[eng][pert][0])\n",
    "                xerr.append(ana_obj.calc_pert_dict[eng][pert][1])\n",
    "                # x.append(ana_obj.cinnabar_calc_val_dict[eng][pert][0])\n",
    "                # xerr.append(ana_obj.cinnabar_calc_val_dict[eng][pert][1])\n",
    "                y.append(exper_pert_dict[pert][0])\n",
    "                yerr.append(exper_pert_dict[pert][1])\n",
    "            except:\n",
    "                print(pert)\n",
    "\n",
    "    res = stats_engines.compute_stats(\n",
    "        x=x, xerr=xerr, y=y, yerr=yerr, statistic=cinn_stats_name\n",
    "    )\n",
    "    # print(\"cinnabar\", name, res)\n",
    "\n",
    "    val_dict[\"all\"][eng_dict_name[eng]] = (\n",
    "        res[0],\n",
    "        res[1],\n",
    "        res[2],\n",
    "    )\n",
    "\n",
    "# for lit_perts_dict, name in zip([openfe_ligs_dict, hahn_ligs_dict, fepplus_ligs_dict], [\"openfe\", \"hahn\", \"fepplus\"]):\n",
    "for lit_perts_dict, name in zip(\n",
    "    [openfe_perts_dict, hahn_perts_dict, fepplus_perts_dict],\n",
    "    [\"openfe\", \"hahn\", \"fepplus\"],\n",
    "):  #\n",
    "    print(name)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    xerr = []\n",
    "    yerr = []\n",
    "\n",
    "    for prot in ana_obj_dict:\n",
    "        print(prot)\n",
    "\n",
    "        if prot == \"syk\" and name == \"openfe\":\n",
    "            continue\n",
    "\n",
    "        ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "        exper_dict = ana_obj.exper_val_dict\n",
    "\n",
    "        perturbations = []\n",
    "        excl = 0\n",
    "        incl = 0\n",
    "        for pert in lit_perts_dict[prot]:\n",
    "            if (\n",
    "                pert.split(\"~\")[0] in exper_dict.keys()\n",
    "                and pert.split(\"~\")[1] in exper_dict.keys()\n",
    "            ):\n",
    "                perturbations.append(pert)\n",
    "\n",
    "        exper_pert_dict = make_dict.exper_from_perturbations(exper_dict, perturbations)\n",
    "\n",
    "        # exper_pert_dict = {}\n",
    "        # avg = np.mean([val[0] for val in exper_dict.values()])\n",
    "        # for lig in exper_dict:\n",
    "        #     exper_pert_dict[lig] = (exper_dict[lig][0] - avg, exper_dict[lig][1])\n",
    "\n",
    "        # additionally only if there are the same perturbations, check what this would be\n",
    "        # use_perts = []\n",
    "        # reverse_perts = []\n",
    "        # for pert in ana_obj.perturbations:\n",
    "        #     if pert in perturbations:\n",
    "        #         use_perts.append(pert)\n",
    "        #     if f\"{pert.split('~')[1]}~{pert.split('~')[0]}\" in perturbations:\n",
    "        #         reverse_perts.append(pert)\n",
    "        # print(f\"{prot}, {len(use_perts)+len(reverse_perts)} perturbations of these would be the same/reverse perturbations ({(len(use_perts)+len(reverse_perts))/(len(perturbations))*100} %)\")\n",
    "        # perturbations = flatten_comprehension([use_perts, reverse_perts])\n",
    "\n",
    "        for pert in perturbations:  # ligands:\n",
    "            if pert in lit_perts_dict[prot].keys():\n",
    "                x.append(lit_perts_dict[prot][pert][0])\n",
    "                xerr.append(lit_perts_dict[prot][pert][1])\n",
    "                y.append(exper_pert_dict[pert][0])\n",
    "                yerr.append(exper_pert_dict[pert][1])\n",
    "\n",
    "        # calculate statistics\n",
    "\n",
    "    res = stats_engines.compute_stats(\n",
    "        x=x, xerr=xerr, y=y, yerr=yerr, statistic=cinn_stats_name\n",
    "    )\n",
    "    # print(\"cinnabar\", name, res)\n",
    "\n",
    "    val_dict[\"all\"][eng_dict_name[name]] = (\n",
    "        res[0],\n",
    "        res[1],\n",
    "        res[2],\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(val_dict)\n",
    "# df.to_markdown()\n",
    "df = df.applymap(lambda x: f\"{x[0]:.2f} ({x[2][0]:.2f},{x[2][1]:.2f})\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all proteins - radial plot\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    categories = list([prot_dict_name[key] for key in prot_dict_name.keys()])\n",
    "    data = []\n",
    "\n",
    "    for prot in prot_dict_name.keys():\n",
    "        ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "        x = np.array(\n",
    "            [\n",
    "                ana_obj.exper_pert_dict[val][0]\n",
    "                for val in ana_obj.cinnabar_calc_pert_dict[eng]\n",
    "                if \"Intermediate\" not in val\n",
    "            ]\n",
    "        )\n",
    "        y = np.array(\n",
    "            [\n",
    "                ana_obj.cinnabar_calc_pert_dict[eng][val][0]\n",
    "                for val in ana_obj.cinnabar_calc_pert_dict[eng]\n",
    "                if \"Intermediate\" not in val\n",
    "            ]\n",
    "        )\n",
    "        abs_error = y - x  # Absolute error calculation - np.abs\n",
    "        for xi, yi, err in zip(x, y, abs_error):\n",
    "            data.append([prot_dict_name[prot], xi, yi, err])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"Category\",\n",
    "            \"Experimental dG (kcal/mol)\",\n",
    "            \"Predicted dG (kcal/mol)\",\n",
    "            \"Error\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Set up polar plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": \"polar\"})\n",
    "\n",
    "    # Convert categories to base angles (evenly spaced)\n",
    "    base_angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)\n",
    "    category_to_angle = {\n",
    "        category: angle for category, angle in zip(categories, base_angles)\n",
    "    }\n",
    "\n",
    "    # Define max angle spread per category (e.g., Â±10 degrees)\n",
    "    max_angle_spread = np.radians(10)\n",
    "\n",
    "    mae_thresholds = [0.5, 1, 2, 3]\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=len(mae_thresholds))\n",
    "\n",
    "    for i, threshold in enumerate(mae_thresholds):\n",
    "        for category, angle in category_to_angle.items():\n",
    "            ax.fill_between(\n",
    "                # Need high res or you'll fill a triangle\n",
    "                np.linspace(\n",
    "                    angle - threshold * max_angle_spread / 2,\n",
    "                    angle + threshold * max_angle_spread / 2,\n",
    "                ),\n",
    "                -4,\n",
    "                4,\n",
    "                alpha=0.1,\n",
    "                color=cm.Grays(norm(i), bytes=False),\n",
    "            )\n",
    "\n",
    "    # Create a color mapping using the \"plasma\" colormap\n",
    "    cmap = cm.get_cmap(\"plasma\", len(categories))\n",
    "    category_color_map = {\n",
    "        cat: cmap(i / (len(categories) - 1)) for i, cat in enumerate(categories)\n",
    "    }\n",
    "\n",
    "    # Plot each category\n",
    "    for category, base_angle in category_to_angle.items():\n",
    "        subset = df[df[\"Category\"] == category]\n",
    "\n",
    "        r = subset[\"Experimental dG (kcal/mol)\"]  # Radial distance\n",
    "        abs_err_norm = subset[\n",
    "            \"Error\"\n",
    "        ]  # / subset[\"Absolute_Error\"].max()  # Normalize error\n",
    "        angles = (\n",
    "            base_angle + (abs_err_norm) * max_angle_spread / 2\n",
    "        )  # Spread points in segment\n",
    "\n",
    "        sc = ax.scatter(\n",
    "            angles,\n",
    "            r,\n",
    "            c=category_color_map[category],\n",
    "            cmap=\"plasma\",\n",
    "            edgecolors=None,\n",
    "            alpha=0.75,\n",
    "        )\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xticks(base_angles)\n",
    "    ax.set_xticklabels(categories, fontsize=12)\n",
    "    ax.set_ylim(\n",
    "        df[\"Experimental dG (kcal/mol)\"].min() - 0.5,\n",
    "        df[\"Experimental dG (kcal/mol)\"].max() + 0.5,\n",
    "    )  # Adjust radial range\n",
    "    ax.set_title(\n",
    "        f\"Radial Error Plot for {eng_dict_name[eng]} (Angle = Error, Radius = Experimental ÎÎG)\"\n",
    "    )\n",
    "    # ax.set_xlabel(\"Experimental dG (kcal/mol)\")\n",
    "    ax.text(\n",
    "        0.68,\n",
    "        0.56,\n",
    "        f\"Experimental ÎÎG (kcal/mol)\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        rotation=21,\n",
    "        rotation_mode=\"anchor\",\n",
    "    )\n",
    "\n",
    "    legend_patches = [\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"w\",\n",
    "            markerfacecolor=category_color_map[cat],\n",
    "            markersize=10,\n",
    "            label=cat,\n",
    "        )\n",
    "        for cat in categories\n",
    "    ]\n",
    "    ax.legend(\n",
    "        handles=legend_patches,\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(-0.3, -0.1),  # fancybox=True, shadow=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all proteins engines together - radial plot\n",
    "\n",
    "# Set up polar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": \"polar\"})\n",
    "\n",
    "categories = list([prot_dict_name[key] for key in prot_dict_name.keys()])\n",
    "\n",
    "# Convert categories to base angles (evenly spaced)\n",
    "base_angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)\n",
    "category_to_angle = {\n",
    "    category: angle for category, angle in zip(categories, base_angles)\n",
    "}\n",
    "\n",
    "# Define max angle spread per category (e.g., Â±10 degrees)\n",
    "max_angle_spread = np.radians(10)\n",
    "\n",
    "mae_thresholds = [0.5, 1, 2, 3]\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=len(mae_thresholds))\n",
    "\n",
    "for i, threshold in enumerate(mae_thresholds):\n",
    "    for category, angle in category_to_angle.items():\n",
    "        ax.fill_between(\n",
    "            # Need high res or you'll fill a triangle\n",
    "            np.linspace(\n",
    "                angle - threshold * max_angle_spread / 2,\n",
    "                angle + threshold * max_angle_spread / 2,\n",
    "            ),\n",
    "            -4,\n",
    "            4,\n",
    "            alpha=0.1,\n",
    "            color=cm.Grays(norm(i), bytes=False),\n",
    "        )\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    data = []\n",
    "\n",
    "    for prot in prot_dict_name.keys():\n",
    "        ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "        x = np.array(\n",
    "            [\n",
    "                ana_obj.exper_pert_dict[val][0]\n",
    "                for val in ana_obj.cinnabar_calc_pert_dict[eng]\n",
    "                if \"Intermediate\" not in val\n",
    "            ]\n",
    "        )\n",
    "        y = np.array(\n",
    "            [\n",
    "                ana_obj.cinnabar_calc_pert_dict[eng][val][0]\n",
    "                for val in ana_obj.cinnabar_calc_pert_dict[eng]\n",
    "                if \"Intermediate\" not in val\n",
    "            ]\n",
    "        )\n",
    "        abs_error = y - x  # Absolute error calculation - np.abs\n",
    "        for xi, yi, err in zip(x, y, abs_error):\n",
    "            data.append([prot_dict_name[prot], xi, yi, err])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"Category\",\n",
    "            \"Experimental dG (kcal/mol)\",\n",
    "            \"Predicted dG (kcal/mol)\",\n",
    "            \"Error\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Create a color mapping using the \"plasma\" colormap\n",
    "    cmap = cm.get_cmap(\"plasma\", len(categories))\n",
    "    category_color_map = {\n",
    "        cat: cmap(i / (len(categories) - 1)) for i, cat in enumerate(categories)\n",
    "    }\n",
    "\n",
    "    # Plot each category\n",
    "    for category, base_angle in category_to_angle.items():\n",
    "        subset = df[df[\"Category\"] == category]\n",
    "\n",
    "        r = subset[\"Experimental dG (kcal/mol)\"]  # Radial distance\n",
    "        abs_err_norm = subset[\n",
    "            \"Error\"\n",
    "        ]  # / subset[\"Absolute_Error\"].max()  # Normalize error\n",
    "        angles = (\n",
    "            base_angle + (abs_err_norm) * max_angle_spread / 2\n",
    "        )  # Spread points in segment\n",
    "\n",
    "        sc = ax.scatter(angles, r, c=col_dict[eng_dict_name[eng]], edgecolors=None)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xticks(base_angles)\n",
    "ax.set_xticklabels(categories, fontsize=12)\n",
    "ax.set_ylim(\n",
    "    df[\"Experimental dG (kcal/mol)\"].min() - 0.5,\n",
    "    df[\"Experimental dG (kcal/mol)\"].max() + 0.5,\n",
    ")  # Adjust radial range\n",
    "ax.set_title(\n",
    "    f\"Radial Error Plot for all engines (Angle = Error, Radius = Experimental ÎÎG)\"\n",
    ")\n",
    "# ax.set_xlabel(\"Experimental dG (kcal/mol)\")\n",
    "ax.text(\n",
    "    0.68,\n",
    "    0.56,\n",
    "    f\"Experimental ÎÎG (kcal/mol)\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=10,\n",
    "    color=\"black\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    rotation=21,\n",
    "    rotation_mode=\"anchor\",\n",
    ")\n",
    "\n",
    "# legend_patches = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=col_dict,\n",
    "#                             markersize=10, label=eng_dict_name[eng]) for eng in ana_obj.engines]\n",
    "# ax.legend(handles=legend_patches, loc='lower left', bbox_to_anchor=(\n",
    "#         -0.3,-0.1), #fancybox=True, shadow=True\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cinnabar stats into a dict\n",
    "net_ana_method_dict = {\"method\": [], \"engine\": [], \"protein\": [], \"value\": []}\n",
    "\n",
    "for method in list(ana_dicts.keys()):  # + [\"single_0\", \"single_1\", \"single_2\"]:\n",
    "    print(method)\n",
    "    for eng in ana_obj.engines:\n",
    "        overall_dg_list = []\n",
    "\n",
    "        for prot in ana_obj_dict.keys():\n",
    "            print(prot, eng)\n",
    "            dg_list = []\n",
    "\n",
    "            if \"single\" in method:\n",
    "                print(f\"method is {method}!\")\n",
    "                ana_obj = ana_obj_dict[prot][method]\n",
    "                ana_obj.calc_pert_dict = ana_obj.calc_repeat_pert_dict[eng][\n",
    "                    int(method.split(\"_\")[-1])\n",
    "                ]\n",
    "            else:\n",
    "                ana_obj = ana_obj_dict[prot][method]\n",
    "                ana_obj.calc_pert_dict = ana_obj.calc_pert_dict[eng]\n",
    "\n",
    "            for key in ana_obj.calc_pert_dict.keys():\n",
    "                if key not in ana_obj._perturbations_dict[eng]:\n",
    "                    print(f\"{key} not in pert dict\")\n",
    "                    continue\n",
    "                try:\n",
    "                    value = abs(\n",
    "                        ana_obj.calc_pert_dict[key][0] - ana_obj.exper_pert_dict[key][0]\n",
    "                    )\n",
    "                    # if value > 10:\n",
    "                    #     print(prot, eng, key, value)\n",
    "                    # else:\n",
    "                    dg_list.append(value)\n",
    "                except:\n",
    "                    print(f\"{key} not in dict for {eng} {method}\")\n",
    "\n",
    "            net_ana_method_dict[\"method\"].append(\n",
    "                [method for l in range(0, len(dg_list))]\n",
    "            )\n",
    "            net_ana_method_dict[\"engine\"].append([eng for l in range(0, len(dg_list))])\n",
    "            net_ana_method_dict[\"protein\"].append([prot for val in dg_list])\n",
    "            net_ana_method_dict[\"value\"].append([val for val in dg_list])\n",
    "            overall_dg_list.append(dg_list)\n",
    "\n",
    "        print(\n",
    "            f\"{eng} {method} mean is {np.mean([dg for dg in flatten_comprehension(overall_dg_list) if dg])}\"\n",
    "        )\n",
    "\n",
    "\n",
    "plotting_dict = {\n",
    "    \"method\": flatten_comprehension(net_ana_method_dict[\"method\"]),\n",
    "    \"MD engine\": flatten_comprehension(net_ana_method_dict[\"engine\"]),\n",
    "    \"MAE ddG (kcal/mol)\": flatten_comprehension(net_ana_method_dict[\"value\"]),\n",
    "    \"Protein\": flatten_comprehension(net_ana_method_dict[\"protein\"]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(plotting_dict)\n",
    "ax = sns.boxplot(\n",
    "    df, x=\"MD engine\", y=\"MAE ddG (kcal/mol)\", hue=\"method\", palette=\"plasma\"\n",
    ")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(df, x=\"MAE ddG (kcal/mol)\", hue=\"MD engine\", palette=\"plasma\")\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(\n",
    "    df, x=\"MD engine\", y=\"MAE ddG (kcal/mol)\", hue=\"method\", errorbar=(\"ci\")  # 95%\n",
    ")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "val_dict = {\n",
    "    method: {}\n",
    "    for method in list(ana_dicts.keys()) + [\"single_0\", \"single_1\", \"single_2\"]\n",
    "}\n",
    "\n",
    "for p, l, name in zip(\n",
    "    ax.patches,\n",
    "    ax.lines,\n",
    "    it.product(\n",
    "        list(ana_dicts.keys()) + [\"single_0\", \"single_1\", \"single_2\"], ana_obj.engines\n",
    "    ),\n",
    "):\n",
    "    xy = l.get_xydata()\n",
    "    # print(f\"{name}: {p.get_height():.2f} ({xy[0][1]:.2f}, {xy[1][1]:.2f})\")\n",
    "    val_dict[name[0]][\n",
    "        name[1]\n",
    "    ] = f\"{p.get_height():.2f} ({xy[0][1]:.2f}, {xy[1][1]:.2f})\"\n",
    "\n",
    "df_val = pd.DataFrame(val_dict)\n",
    "df_val.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the perturbations that are 'well' converged\n",
    "\n",
    "splitby = \"all\"\n",
    "ana_obj_dict = network_dict[\"combined\"]\n",
    "\n",
    "con_vals = []\n",
    "noncon_vals = []\n",
    "all_vals = []\n",
    "for prot in ana_obj_dict:\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "    ana_obj.check_convergence(compute_missing=False)\n",
    "\n",
    "    for eng in [\"AMBER\"]:\n",
    "        print(prot, eng)\n",
    "        con_perts = []\n",
    "        noncon_perts = []\n",
    "        for pert in ana_obj.convergence_dict[eng]:\n",
    "            try:\n",
    "                if splitby == \"all\":\n",
    "                    con_arr = np.array(\n",
    "                        [val for val in ana_obj.convergence_dict[eng][pert].values()]\n",
    "                    )\n",
    "                if splitby == \"free\":\n",
    "                    con_arr = np.array(\n",
    "                        [\n",
    "                            ana_obj.convergence_dict[eng][pert][key]\n",
    "                            for key in ana_obj.convergence_dict[eng][pert]\n",
    "                            if \"free\" in key\n",
    "                        ]\n",
    "                    )\n",
    "                if splitby == \"bound\":\n",
    "                    con_arr = np.array(\n",
    "                        [\n",
    "                            ana_obj.convergence_dict[eng][pert][key]\n",
    "                            for key in ana_obj.convergence_dict[eng][pert]\n",
    "                            if \"bound\" in key\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                con_arr = [c for c in con_arr if c]\n",
    "\n",
    "                # con_arr = con_arr[~np.isnan(con_arr)]\n",
    "                mean = np.mean(con_arr)\n",
    "                if mean > 0.75:\n",
    "                    con_perts.append(pert)\n",
    "                else:\n",
    "                    noncon_perts.append(pert)\n",
    "            except:\n",
    "                print(pert, \"failed\")\n",
    "\n",
    "        con_vals.append(\n",
    "            [\n",
    "                abs(\n",
    "                    ana_obj.calc_pert_dict[eng][pert][0]\n",
    "                    - ana_obj.exper_pert_dict[pert][0]\n",
    "                )\n",
    "                for pert in con_perts\n",
    "                if \"Intermediate\" not in pert\n",
    "            ]\n",
    "        )\n",
    "        noncon_vals.append(\n",
    "            [\n",
    "                abs(\n",
    "                    ana_obj.calc_pert_dict[eng][pert][0]\n",
    "                    - ana_obj.exper_pert_dict[pert][0]\n",
    "                )\n",
    "                for pert in noncon_perts\n",
    "                if \"Intermediate\" not in pert\n",
    "            ]\n",
    "        )\n",
    "        all_vals.append(\n",
    "            [\n",
    "                abs(\n",
    "                    ana_obj.calc_pert_dict[eng][pert][0]\n",
    "                    - ana_obj.exper_pert_dict[pert][0]\n",
    "                )\n",
    "                for pert in ana_obj.convergence_dict[eng]\n",
    "                if \"Intermediate\" not in pert\n",
    "            ]\n",
    "        )\n",
    "        print(len(con_vals), len(noncon_vals), len(all_vals))\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=500)\n",
    "plt.hist(\n",
    "    flatten_comprehension(con_vals),\n",
    "    density=True,\n",
    "    color=\"magenta\",\n",
    "    label=\"Converged\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(\n",
    "    flatten_comprehension(noncon_vals),\n",
    "    density=True,\n",
    "    color=\"plum\",\n",
    "    label=\"Non-converged\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "# plt.hist(flatten_comprehension(all_vals), density=True, color=\"darkblue\", label=\"All\", alpha=0.5)\n",
    "print(\n",
    "    np.mean(flatten_comprehension(con_vals)),\n",
    "    np.mean(flatten_comprehension(noncon_vals)),\n",
    "    np.mean(flatten_comprehension(all_vals)),\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(f\"MAE (kcal/mol)\")\n",
    "plt.ylabel(f\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***cycle closures***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle closures\n",
    "\n",
    "cc_dict = {}\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    for name in ana_dicts:\n",
    "        ana_obj = ana_obj_dict[prot][name]\n",
    "\n",
    "        print(prot, name)\n",
    "        ana_obj.compute_cycle_closures()\n",
    "        cc_dict[f\"{prot_dict_name[prot]}\"] = ana_obj.cycle_dict\n",
    "\n",
    "# plot the cycle closures\n",
    "# plot the errors\n",
    "df = pd.DataFrame.from_dict(cc_dict).transpose()\n",
    "\n",
    "df_ci = df.map(lambda x: x[3]).rename(eng_dict_name, axis=1)\n",
    "df_mean = df.map(lambda x: x[1]).fillna(0).rename(eng_dict_name, axis=1)\n",
    "df_low = df_mean - df_ci.map(lambda x: x[0])\n",
    "df_high = df_ci.map(lambda x: x[1]) - df_mean\n",
    "df_err = np.stack([df_low.T.values, df_high.T.values], axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5), dpi=500)\n",
    "df_mean.plot.bar(\n",
    "    color=col_dict,\n",
    "    yerr=df_err,\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=\"Cycle Closure Error (kcal/mol)\",\n",
    "    ax=ax,\n",
    ")\n",
    "plt.tick_params(axis=\"x\", rotation=0)\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***grow/shrink***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directionality, data from denoting perturbations as grow or shrink\n",
    "\n",
    "ana_obj_dict = network_dict[\"combined\"]\n",
    "\n",
    "grow_shrink_dict = {}\n",
    "for eng in ana_obj.engines:\n",
    "    grow_shrink_dict[eng] = {}\n",
    "\n",
    "df_list = {}\n",
    "for eng in ana_obj.engines:\n",
    "    df_list[eng] = []\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        diff_dict = {\n",
    "            key: abs(\n",
    "                ana_obj.calc_pert_dict[eng][key][0] - ana_obj.exper_pert_dict[key][0]\n",
    "            )\n",
    "            for key in ana_obj._perturbations_dict[eng]\n",
    "            if not \"Intermediate\" in key\n",
    "        }\n",
    "        error_dict = {\n",
    "            key: abs(ana_obj.calc_pert_dict[eng][key][1])\n",
    "            for key in ana_obj._perturbations_dict[eng]\n",
    "        }\n",
    "\n",
    "        df = pd.read_csv(\n",
    "            f\"{join('/', *ana_obj.output_folder.split('/')[:-1])}/execution_model/grow_shrink_featurise.dat\"\n",
    "        )\n",
    "        df[f\"error_{eng}\"] = df[\"pert\"].map(error_dict)\n",
    "        df[f\"diff_{eng}\"] = df[\"pert\"].map(diff_dict)\n",
    "        df = df.dropna()\n",
    "\n",
    "        df_list[eng].append(df)\n",
    "\n",
    "        group1 = df.loc[df[\"grow/shrink\"] == \"grow\"][f\"error_{eng}\"]\n",
    "        group2 = df.loc[df[\"grow/shrink\"] == \"shrink\"][f\"error_{eng}\"]\n",
    "        group3 = df.loc[df[\"grow/shrink\"] == \"same\"][f\"error_{eng}\"]\n",
    "        print(\"grow \", len(group1), \"shrink \", len(group2), \"same \", len(group3))\n",
    "        ustats, pvalue = _stats.mannwhitneyu(group1, group2)\n",
    "        print(f\"mann u for error {eng}: {ustats, pvalue}\")\n",
    "        print(\n",
    "            f\"mean for error {eng} grow: {np.mean(group1)}, and for shrink: {np.mean(group2)}, and for same: {np.mean(group3)}\"\n",
    "        )\n",
    "\n",
    "        group1 = df.loc[df[\"grow/shrink\"] == \"grow\"][f\"diff_{eng}\"]\n",
    "        group2 = df.loc[df[\"grow/shrink\"] == \"shrink\"][f\"diff_{eng}\"]\n",
    "        group3 = df.loc[df[\"grow/shrink\"] == \"same\"][f\"diff_{eng}\"]\n",
    "        ustats, pvalue = _stats.mannwhitneyu(group1, group2)\n",
    "        print(f\"mann u for diff to exp {eng}: {ustats, pvalue}\")\n",
    "        print(\n",
    "            f\"mean for diff to exp {eng} grow: {np.mean(group1)}, and for shrink: {np.mean(group2)} and for same: {np.mean(group3)}\"\n",
    "        )\n",
    "\n",
    "# across the systems\n",
    "print(\"all\")\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    df = pd.concat(df_list[eng], ignore_index=True)\n",
    "\n",
    "    group1 = df.loc[df[\"grow/shrink\"] == \"grow\"][f\"error_{eng}\"]\n",
    "    group2 = df.loc[df[\"grow/shrink\"] == \"shrink\"][f\"error_{eng}\"]\n",
    "    group3 = df.loc[df[\"grow/shrink\"] == \"same\"][f\"error_{eng}\"]\n",
    "    print(\"grow \", len(group1), \"shrink \", len(group2), \"same \", len(group3))\n",
    "\n",
    "    ustats, pvalue = _stats.mannwhitneyu(group1, group2)\n",
    "    print(f\"mann u for error {eng}: {ustats, pvalue}\")\n",
    "    print(\n",
    "        f\"mean for error {eng} grow: {np.mean(group1)}, and for shrink: {np.mean(group2)}, and for same: {np.mean(group3)}\"\n",
    "    )\n",
    "\n",
    "    # Plotting the distribution of the stats test\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.histplot(group1, color=\"cadetblue\", label=\"Grow\", kde=True)\n",
    "    sns.histplot(group2, color=\"pink\", label=\"Shrink\", kde=True)\n",
    "    sns.histplot(group3, color=\"plum\", label=\"Same\", kde=True)\n",
    "\n",
    "    # sns.kdeplot(group1, color='cadetblue', label='Grow')\n",
    "    # sns.kdeplot(group2, color='pink', label='Shrink')\n",
    "    # sns.kdeplot(group3, color='plum', label='Same')\n",
    "\n",
    "    # # Plotting the mean and std as a shaded area\n",
    "    # mean1, std1 = np.mean(group1), np.std(group1)\n",
    "    # mean2, std2 = np.mean(group2), np.std(group2)\n",
    "    # mean3, std3 = np.mean(group3), np.std(group3)\n",
    "\n",
    "    # upper_ylim = plt.gca().get_ylim()[1]\n",
    "\n",
    "    # plt.axvline(mean1, color='cadetblue', linestyle='--')\n",
    "    # plt.axvline(mean2, color='pink', linestyle='--')\n",
    "    # plt.axvline(mean3, color='plum', linestyle='--')\n",
    "\n",
    "    # plt.fill_betweenx([0, upper_ylim], mean1 - std1, mean1 + std1, color='cadetblue', alpha=0.2)\n",
    "    # plt.fill_betweenx([0, upper_ylim], mean2 - std2, mean2 + std2, color='pink', alpha=0.2)\n",
    "    # plt.fill_betweenx([0, upper_ylim], mean3 - std3, mean3 + std3, color='plum', alpha=0.2)\n",
    "\n",
    "    plt.title(f\"{eng_dict_name[eng]}\")\n",
    "    plt.xlabel(\"SEM (kcal/mol)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    group1 = df.loc[df[\"grow/shrink\"] == \"grow\"][f\"diff_{eng}\"]\n",
    "    group2 = df.loc[df[\"grow/shrink\"] == \"shrink\"][f\"diff_{eng}\"]\n",
    "    group3 = df.loc[df[\"grow/shrink\"] == \"same\"][f\"diff_{eng}\"]\n",
    "\n",
    "    ustats, pvalue = _stats.mannwhitneyu(group1, group2)\n",
    "    print(f\"mann u for diff to exp {eng}: {ustats, pvalue}\")\n",
    "    print(\n",
    "        f\"mean for diff to exp {eng} grow: {np.mean(group1)}, and for shrink: {np.mean(group2)} and for same: {np.mean(group3)}\"\n",
    "    )\n",
    "\n",
    "    # Plotting the distribution of the stats test\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.histplot(group1, color=\"cadetblue\", label=\"Grow\", kde=True)\n",
    "    sns.histplot(group2, color=\"pink\", label=\"Shrink\", kde=True)\n",
    "    sns.histplot(group3, color=\"plum\", label=\"Same\", kde=True)\n",
    "\n",
    "    # sns.kdeplot(group1, color='cadetblue', label='Grow')\n",
    "    # sns.kdeplot(group2, color='pink', label='Shrink')\n",
    "    # sns.kdeplot(group3, color='plum', label='Same')\n",
    "\n",
    "    # # Plotting the mean and std as a shaded area\n",
    "    # mean1, std1 = np.mean(group1), np.std(group1)\n",
    "    # mean2, std2 = np.mean(group2), np.std(group2)\n",
    "    # mean3, std3 = np.mean(group3), np.std(group3)\n",
    "\n",
    "    # upper_ylim = plt.gca().get_ylim()[1]\n",
    "\n",
    "    # plt.axvline(mean1, color='cadetblue', linestyle='--')\n",
    "    # plt.axvline(mean2, color='pink', linestyle='--')\n",
    "    # plt.axvline(mean3, color='plum', linestyle='--')\n",
    "\n",
    "    # plt.fill_betweenx([0, upper_ylim], mean1 - std1, mean1 + std1, color='cadetblue', alpha=0.2)\n",
    "    # plt.fill_betweenx([0, upper_ylim], mean2 - std2, mean2 + std2, color='pink', alpha=0.2)\n",
    "    # plt.fill_betweenx([0, upper_ylim], mean3 - std3, mean3 + std3, color='plum', alpha=0.2)\n",
    "\n",
    "    plt.title(f\"{eng_dict_name[eng]}\")\n",
    "    plt.xlabel(\"MAE (kcal/mol)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# if below 0.05 (if confidence interval) there is significant difference (reject null hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different between engines significant?\n",
    "\n",
    "res_dict = {}\n",
    "\n",
    "for size in [\"grow_err\", \"shrink_err\", \"grow_diff\", \"shrink_diff\"]:\n",
    "    res_dict[size] = {}\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        res_dict[size][eng] = {}\n",
    "\n",
    "    for combo in it.product(grow_shrink_dict.keys(), grow_shrink_dict.keys()):\n",
    "        eng1 = combo[0]\n",
    "        eng2 = combo[1]\n",
    "\n",
    "        if eng1 == eng2:\n",
    "            continue\n",
    "\n",
    "        group1 = grow_shrink_dict[eng1][size]\n",
    "        group2 = grow_shrink_dict[eng2][size]\n",
    "\n",
    "        ustats, pvalue = _stats.mannwhitneyu(group1, group2)\n",
    "        print(f\"{eng1, eng2}, {size}: {ustats, pvalue}\")\n",
    "        print(f\"mean for {eng1}: {np.mean(group1)}, and for {eng2}: {np.mean(group2)}\")\n",
    "\n",
    "        res_dict[size][eng1][eng2] = pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***AUTOEQUILIBRATION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_dict_avg = {}\n",
    "\n",
    "overall_array = {}\n",
    "for eng in ana_obj.engines:\n",
    "    overall_array[eng] = np.array([])\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    ana_obj = ana_obj_dict[prot][\"plain\"]\n",
    "    ana_obj.check_Ac(compute_missing=False)\n",
    "\n",
    "    ac_dict_avg[prot] = {}\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        # print(eng)\n",
    "        ac_dict_avg[prot][eng] = []\n",
    "        for pert in ana_obj.ac_dict[eng].keys():\n",
    "            pert_ac_list = []\n",
    "            try:\n",
    "                for key in ana_obj.ac_dict[eng][pert].keys():\n",
    "                    if ana_obj.ac_dict[eng][pert][key] != None:\n",
    "                        pert_ac_list.append(ana_obj.ac_dict[eng][pert][key])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            ac_dict_avg[prot][eng].append(pert_ac_list)\n",
    "\n",
    "        ac_dict_avg[prot][eng] = flatten_comprehension(ac_dict_avg[prot][eng])\n",
    "        print(prot, eng, np.mean(ac_dict_avg[prot][eng]), len(ac_dict_avg[prot][eng]))\n",
    "        overall_array[eng] = np.concatenate(\n",
    "            [overall_array[eng], ac_dict_avg[prot][eng]]\n",
    "        )\n",
    "for eng in ana_obj.engines:\n",
    "    print(eng, np.mean(overall_array[eng]), len(overall_array[eng]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default autoeq time for each engine\n",
    "# recalculate eq times if needed\n",
    "for prot in ana_obj_dict.keys():\n",
    "    try:\n",
    "        print(prot)\n",
    "        ana_obj = ana_obj_dict[prot][\"autoeq\"]\n",
    "        ana_obj.compute_equilibration_times(compute_missing=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"could not for {prot}\")\n",
    "\n",
    "# check equilibration times\n",
    "eq_dict_avg = {}\n",
    "std_dict_avg = {}\n",
    "sem_dict_avg = {}\n",
    "overall_array = {}\n",
    "for eng in ana_obj_dict[\"tyk2\"][\"autoeq\"].engines:\n",
    "    overall_array[eng] = np.array([])\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "\n",
    "    eq_dict_avg[prot] = {}\n",
    "    std_dict_avg[prot] = {}\n",
    "    sem_dict_avg[prot] = {}\n",
    "\n",
    "    ana_obj = ana_obj_dict[prot][\"autoeq\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        # print(eng)\n",
    "        eq_dict_avg[prot][eng] = []\n",
    "        for pert in ana_obj.eq_times_dict[eng].keys():\n",
    "            eq_dict_avg[prot][eng].append(\n",
    "                [\n",
    "                    ana_obj.eq_times_dict[eng][pert][key][\"mean\"]\n",
    "                    for key in ana_obj.eq_times_dict[eng][pert].keys()\n",
    "                    if ana_obj.eq_times_dict[eng][pert][key][\"mean\"] != None\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        eq_dict_avg[prot][eng] = flatten_comprehension(eq_dict_avg[prot][eng])\n",
    "        print(prot, eng, eq_dict_avg[prot][eng])\n",
    "        overall_array[eng] = np.concatenate(\n",
    "            [overall_array[eng], eq_dict_avg[prot][eng]]\n",
    "        )\n",
    "\n",
    "        sem_dict_avg[prot][eng] = _stats.sem(eq_dict_avg[prot][eng])\n",
    "        std_dict_avg[prot][eng] = _stats.tstd(eq_dict_avg[prot][eng])\n",
    "        eq_dict_avg[prot][eng] = np.mean(eq_dict_avg[prot][eng])\n",
    "\n",
    "df = pd.DataFrame.from_dict(eq_dict_avg).transpose() * 100  # transpose for per engine\n",
    "df_sem = (\n",
    "    pd.DataFrame.from_dict(sem_dict_avg).transpose() * 100\n",
    ")  # transpose for per engine\n",
    "df_std = (\n",
    "    pd.DataFrame.from_dict(std_dict_avg).transpose() * 100\n",
    ")  # transpose for per engine\n",
    "print(df)\n",
    "\n",
    "dict_lower = {}\n",
    "dict_higher = {}\n",
    "for eng in ana_obj.engines:\n",
    "    # check normally dist\n",
    "    # if not check_normal_dist(overall_array[eng]):\n",
    "    #     print(\"not normal distribution\")\n",
    "\n",
    "    mean = np.mean(overall_array[eng])\n",
    "    lower_ci, upper_ci = _stats.norm.interval(\n",
    "        confidence=0.95,\n",
    "        loc=np.mean(overall_array[eng]),\n",
    "        scale=_stats.sem(overall_array[eng]),\n",
    "    )\n",
    "    print(eng, mean, lower_ci, upper_ci)\n",
    "    dict_lower[eng] = [lower_ci * 100]\n",
    "    dict_higher[eng] = [upper_ci * 100]\n",
    "\n",
    "mean = np.mean(flatten_comprehension(overall_array.values()))\n",
    "lower_ci, upper_ci = _stats.norm.interval(\n",
    "    confidence=0.95,\n",
    "    loc=np.mean(flatten_comprehension(overall_array.values())),\n",
    "    scale=_stats.sem(flatten_comprehension(overall_array.values())),\n",
    ")\n",
    "print(\"all\", mean, lower_ci, upper_ci)\n",
    "dict_lower[eng] = [lower_ci * 100]\n",
    "dict_higher[eng] = [upper_ci * 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average for the engines and also per system\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharex=False, sharey=True, dpi=500)\n",
    "\n",
    "df_plot = df\n",
    "df_plot.rename(prot_dict_name, inplace=True)\n",
    "df_plot.rename(eng_dict_name, inplace=True, axis=1)\n",
    "\n",
    "# plt.tick_params(axis=\"x\", labelsize=10, rotation=45)\n",
    "# plt.tick_params(axis=\"y\", labelsize=10)\n",
    "\n",
    "df_plot.T.mean().plot.bar(\n",
    "    color=\"purple\",\n",
    "    yerr=df_plot.T.sem(),\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=\"Average amount of run\\ndiscarded by auto-equilibration (%)\",\n",
    "    ax=axes[0],\n",
    ")\n",
    "plt.tick_params(axis=\"x\", rotation=0)\n",
    "# plt.tick_params(axis=\"x\", labelsize=10, rotation=45)\n",
    "# plt.tick_params(axis=\"y\", labelsize=10)\n",
    "\n",
    "df_plot.plot.bar(\n",
    "    color=col_dict.values(),\n",
    "    yerr=df_sem,\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=\"Average amount of run\\ndiscarded by auto-equilibration (%)\",\n",
    "    ax=axes[1],\n",
    ")\n",
    "plt.tick_params(axis=\"x\", rotation=0)\n",
    "plt.legend(loc=\"best\")\n",
    "loc='', bbox_to_anchor=(0.5, 0.5)\n",
    "df_plot.mean().plot.bar(\n",
    "    color=col_dict.values(),\n",
    "    yerr=df_plot.sem(),\n",
    "    xlabel=\"MD engine\",\n",
    "    ylabel=\"Average amount of run\\ndiscarded by auto-equilibration (%)\",\n",
    "    ax=axes[2],\n",
    ")\n",
    "plt.tick_params(axis=\"x\", rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = df.set_index(\"protein\")\n",
    "except:\n",
    "    pass\n",
    "# plotting w the bars representing how much of the average is each engine\n",
    "df.div(df.sum(axis=1), axis=0).mul(df.mean(axis=1), axis=0).plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    color=pipeline.analysis.set_colours(),\n",
    "    xlabel=\"protein system\",\n",
    "    ylabel=\"Average amount of run\\ndiscarded by auto-equilibration (%)\",\n",
    ")\n",
    "plt.errorbar(x=df.index, y=df.T.mean(), yerr=df.T.sem(), ecolor=\"black\", linestyle=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Network Analysis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting statistics\n",
    "\n",
    "plotting_dict = {}\n",
    "\n",
    "stats_name = \"ÎG MAE (kcal/mol)\"\n",
    "print(stats_name)\n",
    "\n",
    "for network in [\n",
    "    \"lomap\",\n",
    "    \"rbfenn\",\n",
    "    \"flare\",\n",
    "    \"combined\",\n",
    "    \"lomap-a-optimal\",\n",
    "    \"lomap-d-optimal\",\n",
    "    \"rbfenn-a-optimal\",\n",
    "    \"rbfenn-d-optimal\",\n",
    "]:  # , \"lomap-a-optimal\", \"lomap-d-optimal\", \"rbfenn-a-optimal\", \"rbfenn-d-optimal\"\n",
    "    plotting_dict[network] = {}\n",
    "\n",
    "    for prot in [\"tyk2\", \"mcl1\"]:  # ana_obj_dict.keys():\n",
    "        print(network, prot)\n",
    "        plotting_dict[network][prot] = {}\n",
    "\n",
    "        try:\n",
    "            ana_obj = network_dict[network][prot][\"plain\"]\n",
    "            # print(len(ana_obj.perturbations))\n",
    "\n",
    "            pert_val = \"val\"\n",
    "\n",
    "            if stats_name == \"ÎG MAE (kcal/mol)\":\n",
    "                func = ana_obj.calc_mae_engines\n",
    "            if stats_name == \"ÎÎG MAE (kcal/mol)\":\n",
    "                func = ana_obj.calc_mae_engines\n",
    "                pert_val = \"pert\"\n",
    "            elif stats_name == \"$r^2$\":\n",
    "                func = ana_obj.calc_r2_engines\n",
    "            elif stats_name == \"Kendall's Tau\":\n",
    "                func = ana_obj.calc_kendalls_rank_engines\n",
    "            else:\n",
    "                print(\"no\")\n",
    "\n",
    "            stats_string_all = \"\"\n",
    "            mae = func(pert_val=pert_val, recalculate=False)\n",
    "\n",
    "            for eng in ana_obj.engines:\n",
    "                # print(\n",
    "                #     f\"{eng} MAE: {mae[0][eng]['experimental']:.2f} {mae[2][eng]['experimental']}\"\n",
    "                # )\n",
    "                plotting_dict[network][prot][eng] = (\n",
    "                    mae[0][eng][\"experimental\"],\n",
    "                    mae[1][eng][\"experimental\"],\n",
    "                    mae[2][eng][\"experimental\"],\n",
    "                )\n",
    "\n",
    "        except:\n",
    "            for eng in network_dict[\"lomap\"][\"tyk2\"][\"plain\"].engines:\n",
    "                plotting_dict[network][prot][eng] = (0, 0, [0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"lomap\"\n",
    "df = (\n",
    "    pd.DataFrame(plotting_dict[name])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .rename(eng_dict_name)\n",
    "    .T.rename(prot_dict_name)\n",
    ")\n",
    "df_err = (\n",
    "    pd.DataFrame(plotting_dict[name])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .rename(eng_dict_name)\n",
    "    .T.rename(prot_dict_name)\n",
    ")\n",
    "\n",
    "# df_lower = df - df_err.applymap(lambda x: x[0])\n",
    "# df_upper = df_err.applymap(lambda x: x[1]) - df\n",
    "# df_err = np.stack([df_lower.T.values, df_upper.T.values], axis=1)\n",
    "\n",
    "# df.drop([\"AMBER_adjusted_GROMACS\"], axis=1, inplace=True)\n",
    "# df_err.drop([\"AMBER_adjusted_GROMACS\"], axis=1, inplace=True)\n",
    "fig, ax = plt.subplots(figsize=(5, 5), dpi=500)\n",
    "\n",
    "ax = df.plot(\n",
    "    kind=\"bar\",\n",
    "    color=col_dict,\n",
    "    yerr=df_err,\n",
    "    ax=ax,\n",
    ")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Protein System\")\n",
    "plt.ylabel(f\"{stats_name}\")\n",
    "plt.tick_params(axis=\"x\", rotation=0)\n",
    "plt.tick_params(axis=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs based on engine\n",
    "ana_obj = network_dict[\"lomap\"][\"tyk2\"][\"plain\"]\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=3, figsize=(15, 5), sharex=True, sharey=True, dpi=500\n",
    ")\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "for engine, pos in zip(ana_obj.engines, [axes[0], axes[1], axes[2]]):\n",
    "    df_lomap = (\n",
    "        pd.DataFrame(plotting_dict[\"lomap\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"LOMAP-score\"}, axis=1)\n",
    "        .rename(prot_dict_name)\n",
    "    )\n",
    "    df_rbfenn = (\n",
    "        pd.DataFrame(plotting_dict[\"rbfenn\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"RBFENN-score\"}, axis=1)\n",
    "        .rename(prot_dict_name)\n",
    "    )\n",
    "    df = df_lomap.merge(df_rbfenn, left_index=True, right_index=True)\n",
    "\n",
    "    df_lomap = (\n",
    "        pd.DataFrame(plotting_dict[\"lomap\"])\n",
    "        .applymap(lambda x: x[2])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"LOMAP-score\"}, axis=1)\n",
    "        .rename(prot_dict_name)\n",
    "    )\n",
    "    df_rbfenn = (\n",
    "        pd.DataFrame(plotting_dict[\"rbfenn\"])\n",
    "        .applymap(lambda x: x[2])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"RBFENN-score\"}, axis=1)\n",
    "        .rename(prot_dict_name)\n",
    "    )\n",
    "    df_err = df_lomap.merge(df_rbfenn, left_index=True, right_index=True)\n",
    "\n",
    "    df_lower = df_err.applymap(lambda x: x[0])\n",
    "    df_upper = df_err.applymap(lambda x: x[1])\n",
    "    df_err = (df_upper - df_lower) / 2\n",
    "\n",
    "    # engine colours\n",
    "    col_dict = {\n",
    "        \"AMBER\": [\"orange\", \"moccasin\"],\n",
    "        \"SOMD\": [\"darkturquoise\", \"paleturquoise\"],\n",
    "        \"GROMACS\": [\"orchid\", \"plum\"],\n",
    "    }\n",
    "    df.plot(\n",
    "        kind=\"bar\",\n",
    "        color=col_dict[engine],  # [\"mediumslateblue\",\"indigo\"],\n",
    "        yerr=df_err,\n",
    "        title=eng_dict_name[engine],\n",
    "        ax=pos,\n",
    "        xlabel=\"Protein System\",\n",
    "        ylabel=f\"{stats_name}\",\n",
    "    )\n",
    "    pos.tick_params(axis=\"x\", rotation=0)\n",
    "    pos.legend(loc=\"upper right\")\n",
    "# fig.suptitle(f'{stats_name} perturbations for LOMAP/RBFENN-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of perts in each network normalised by the no of ligands\n",
    "\n",
    "no_ligands_dict = {\n",
    "    \"kuhn\": [16, 42, 34],\n",
    "    \"lomap\": [17, 15, 34],\n",
    "    \"rbfenn\": [17, 15, 34],\n",
    "    \"flare\": [17, 15, 34],\n",
    "    \"combined\": [17, 15, 34],\n",
    "    \"lomap-a-optimal\": [17, 15, 34],\n",
    "    \"lomap-d-optimal\": [17, 15, 34],\n",
    "    \"rbfenn-a-optimal\": [17, 15, 34],\n",
    "    \"rbfenn-d-optimal\": [17, 15, 34],\n",
    "}\n",
    "no_perts_dict = {\n",
    "    \"kuhn\": [23, 70, 54],\n",
    "    \"lomap\": [24, 17, 49],\n",
    "    \"rbfenn\": [30, 20, 51],\n",
    "    \"flare\": [24, 19, 62],\n",
    "    \"combined\": [62, 53, 132],\n",
    "    \"lomap-a-optimal\": [24, 17, 49],\n",
    "    \"lomap-d-optimal\": [24, 17, 49],\n",
    "    \"rbfenn-a-optimal\": [30, 20, 51],\n",
    "    \"rbfenn-d-optimal\": [30, 20, 51],\n",
    "}\n",
    "normalised_dict = {}\n",
    "for key in no_ligands_dict.keys():\n",
    "    normalised_dict[key] = [\n",
    "        pert / val for pert, val in zip(no_perts_dict[key], no_ligands_dict[key])\n",
    "    ]\n",
    "\n",
    "# [1.4,1.7,1.3,1.4,1.4,1.4,1.8,1.3,1.5,2.6,2.5,2.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a specific engine\n",
    "# can adjust which are getting plotted in reduce\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3.25), dpi=500)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "\n",
    "ana_obj = network_dict[\"lomap\"][\"tyk2\"][\"plain\"]\n",
    "engine = \"GROMACS\"\n",
    "\n",
    "df_lomap = (\n",
    "    pd.DataFrame(plotting_dict[\"lomap\"])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"LOMAP-score\"}, axis=1)\n",
    ")\n",
    "df_rbfenn = (\n",
    "    pd.DataFrame(plotting_dict[\"rbfenn\"])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"RBFENN-score\"}, axis=1)\n",
    ")\n",
    "df_flare = (\n",
    "    pd.DataFrame(plotting_dict[\"flare\"])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"Flare\"}, axis=1)\n",
    ")\n",
    "df_lomapa = (\n",
    "    pd.DataFrame(plotting_dict[\"lomap-a-optimal\"])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"LOMAP-A-optimal\"}, axis=1)\n",
    ")\n",
    "df_lomapd = (\n",
    "    pd.DataFrame(plotting_dict[\"lomap-d-optimal\"])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"LOMAP-D-optimal\"}, axis=1)\n",
    ")\n",
    "df_rbfenna = (\n",
    "    pd.DataFrame(plotting_dict[\"rbfenn-a-optimal\"])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"RBFENN-A-optimal\"}, axis=1)\n",
    ")\n",
    "df_rbfennd = (\n",
    "    pd.DataFrame(plotting_dict[\"rbfenn-d-optimal\"])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"RBFENN-D-optimal\"}, axis=1)\n",
    ")\n",
    "df_combined = (\n",
    "    pd.DataFrame(plotting_dict[\"combined\"])\n",
    "    .applymap(lambda x: x[0])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"Combined\"}, axis=1)\n",
    ")\n",
    "df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "    [\n",
    "        df_lomap,\n",
    "        df_rbfenn,\n",
    "        df_flare,\n",
    "        df_combined,\n",
    "    ],  # , df_lomap, df_lomapa, df_lomapd, df_rbfenn, df_rbfenna, df_rbfennd\n",
    ")\n",
    "# df.insert(0, \"Kuhn et al.\", [0.70, 0.94, 1.18], True) # dG\n",
    "# df.insert(0, \"Kuhn et al.\", [0.54, 0.56, 0.54], True)  # ktau\n",
    "\n",
    "# TODO consider error which\n",
    "df_lomap = (\n",
    "    pd.DataFrame(plotting_dict[\"lomap\"])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"LOMAP-score\"}, axis=1)\n",
    ")\n",
    "df_rbfenn = (\n",
    "    pd.DataFrame(plotting_dict[\"rbfenn\"])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"RBFENN-score\"}, axis=1)\n",
    ")\n",
    "df_flare = (\n",
    "    pd.DataFrame(plotting_dict[\"flare\"])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"Flare\"}, axis=1)\n",
    ")\n",
    "df_lomapa = (\n",
    "    pd.DataFrame(plotting_dict[\"lomap-a-optimal\"])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"LOMAP-A-optimal\"}, axis=1)\n",
    ")\n",
    "df_lomapd = (\n",
    "    pd.DataFrame(plotting_dict[\"lomap-d-optimal\"])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"LOMAP-D-optimal\"}, axis=1)\n",
    ")\n",
    "df_rbfenna = (\n",
    "    pd.DataFrame(plotting_dict[\"rbfenn-a-optimal\"])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"RBFENN-A-optimal\"}, axis=1)\n",
    ")\n",
    "df_rbfennd = (\n",
    "    pd.DataFrame(plotting_dict[\"rbfenn-d-optimal\"])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"RBFENN-D-optimal\"}, axis=1)\n",
    ")\n",
    "# a d optimal\n",
    "df_combined = (\n",
    "    pd.DataFrame(plotting_dict[\"combined\"])\n",
    "    .applymap(lambda x: x[1])\n",
    "    .T.rename(prot_dict_name)\n",
    "    .drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "    .rename({engine: \"Combined\"}, axis=1)\n",
    ")\n",
    "df_err = reduce(\n",
    "    lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "    [\n",
    "        df_lomap,\n",
    "        df_rbfenn,\n",
    "        df_flare,\n",
    "        df_combined,\n",
    "    ],  # df_lomap, df_rbfenn, df_flare, df_combined\n",
    ")\n",
    "\n",
    "# df_err.insert(0, \"Kuhn et al.\", [0.14, 0.14, 0.15], True) # dG\n",
    "# df_err.insert(0, \"Kuhn et al.\", [0.28, 0.28, 0.27], True)  # ktau\n",
    "\n",
    "# df_low = df - df_err.map(lambda x: x[0])\n",
    "# df_high = df_err.map(lambda x: x[1]) - df\n",
    "# df_err = np.stack([df_low.T.values, df_high.T.values], axis=1)\n",
    "\n",
    "df.plot(\n",
    "    kind=\"bar\",\n",
    "    colormap=\"plasma\",\n",
    "    # color=[\n",
    "    #     \"mediumblue\", \"dodgerblue\", \"lightsteelblue\",\n",
    "    #     \"darkviolet\", \"orchid\", \"thistle\"\n",
    "    # ],\n",
    "    #     # \"mediumslateblue\",\n",
    "    #     \"darkturquoise\",\n",
    "    #     \"paleturquoise\",\n",
    "    #     \"cadetblue\",\n",
    "    #     \"indigo\",\n",
    "    # ],  # [\"mediumslateblue\",\"indigo\"],\n",
    "    yerr=df_err,\n",
    "    xlabel=\"Protein System\",\n",
    "    ylabel=f\"{stats_name} (kcal/mol)\",\n",
    "    ax=ax,\n",
    "    width=0.9\n",
    "    # fontsize=8\n",
    ")\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "# kuhn, lomap, rbfenn\n",
    "# normalised lig pert ratio [1.4,1.7,1.3,1.4,1.4,1.4,1.8,1.3,1.5,2.6,2.5,2.6]\n",
    "# number of perts [23, 70, 54, 24, 48, 48, 30, 45, 51, 44, 84, 88]\n",
    "#\n",
    "# for p, v in zip(ax.patches, [f\"{v:.1f}\" for v in flatten_comprehension([normalised_dict[val] for val in no_perts_dict])]):\n",
    "#     ax.annotate(str(v), (p.get_x() + 0.03, 0.2), fontsize=7.5)\n",
    "plt.legend(fontsize=8, loc=\"lower right\")  # , bbox_to_anchor=(0.15, 1.4))\n",
    "plt.xlabel(\"Protein System\", fontsize=10)\n",
    "plt.ylabel(f\"{stats_name}\", fontsize=10)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=10, rotation=0)\n",
    "plt.title(f\"{eng_dict_name[engine]}\")\n",
    "# ax.set_ylim(top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other plot format - rbfenn and lomap next to each other on same graph\n",
    "# ie graphs based on protein system\n",
    "\n",
    "ana_obj = network_dict[\"lomap\"][\"tyk2\"][\"plain\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 5), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "\n",
    "proteins = [\"tyk2\", \"mcl1\"]\n",
    "for prot, pos in zip(proteins, [axes[0], axes[1]]):  # , axes[2]\n",
    "    df_lomap = (\n",
    "        pd.DataFrame(plotting_dict[\"lomap\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"LOMAP\"}, axis=1)\n",
    "    )\n",
    "    df_rbfenn = (\n",
    "        pd.DataFrame(plotting_dict[\"rbfenn\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"RBFENN\"}, axis=1)\n",
    "    )  # .rename({eng: f\"{eng}_2\" for eng in ana_obj.engines}, axis=0)\n",
    "    df_lomapa = (\n",
    "        pd.DataFrame(plotting_dict[\"lomap-a-optimal\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"LOMAP-A-optimal\"}, axis=1)\n",
    "    )\n",
    "    df_lomapd = (\n",
    "        pd.DataFrame(plotting_dict[\"lomap-d-optimal\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"LOMAP-D-optimal\"}, axis=1)\n",
    "    )\n",
    "    df_rbfenna = (\n",
    "        pd.DataFrame(plotting_dict[\"rbfenn-a-optimal\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"RBFENN-A-optimal\"}, axis=1)\n",
    "    )\n",
    "    df_rbfennd = (\n",
    "        pd.DataFrame(plotting_dict[\"rbfenn-d-optimal\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"RBFENN-D-optimal\"}, axis=1)\n",
    "    )\n",
    "    # df = df_lomap.merge(\n",
    "    #     df_rbfenn, left_index=True, right_index=True\n",
    "    # ).T  # pd.concat if renamed to 2\n",
    "    # TODO some way diff colour for lomap or rbfenn\n",
    "    df = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        [df_lomap, df_lomapa, df_lomapd],  # df_lomap, df_rbfenn, df_flare, df_combined\n",
    "    ).T\n",
    "    df_lomap = (\n",
    "        pd.DataFrame(plotting_dict[\"lomap\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"LOMAP\"}, axis=1)\n",
    "    )\n",
    "    df_rbfenn = (\n",
    "        pd.DataFrame(plotting_dict[\"rbfenn\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"RBFENN\"}, axis=1)\n",
    "    )  # .rename({eng: f\"{eng}_2\" for eng in ana_obj.engines}, axis=0)\n",
    "\n",
    "    df_lomapa = (\n",
    "        pd.DataFrame(plotting_dict[\"lomap-a-optimal\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"LOMAP-A-optimal\"}, axis=1)\n",
    "    )\n",
    "    df_lomapd = (\n",
    "        pd.DataFrame(plotting_dict[\"lomap-d-optimal\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"LOMAP-D-optimal\"}, axis=1)\n",
    "    )\n",
    "    df_rbfenna = (\n",
    "        pd.DataFrame(plotting_dict[\"rbfenn-a-optimal\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"RBFENN-A-optimal\"}, axis=1)\n",
    "    )\n",
    "    df_rbfennd = (\n",
    "        pd.DataFrame(plotting_dict[\"rbfenn-d-optimal\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .drop(labels=[eng for eng in proteins if eng != prot], axis=1)\n",
    "        .rename({prot: \"RBFENN-D-optimal\"}, axis=1)\n",
    "    )\n",
    "    # df_err = df_lomap.merge(df_rbfenn, left_index=True, right_index=True).T\n",
    "    # df_err.applymap(lambda x: (None, None) if x[0] is None else x)\n",
    "    df_err = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        [df_lomap, df_lomapa, df_lomapd],  # df_lomap, df_rbfenn, df_flare, df_combined\n",
    "    ).T\n",
    "    # df_lower = df_err.applymap(lambda x: x[0])\n",
    "    # df_upper = df_err.applymap(lambda x: x[1])\n",
    "    # df_err = (df_upper - df_lower) / 2\n",
    "\n",
    "    # engine colours\n",
    "    re_col_dict = {\n",
    "        \"AMBER\": [\"orange\", \"moccasin\", \"oldlace\"],\n",
    "        \"SOMD\": [\"darkturquoise\", \"paleturquoise\", \"azure\"],\n",
    "        \"GROMACS\": [\"orchid\", \"plum\", \"pink\"],\n",
    "    }\n",
    "    df.plot(\n",
    "        kind=\"bar\",\n",
    "        color=re_col_dict,\n",
    "        yerr=df_err,\n",
    "        title=prot_dict_name[prot],\n",
    "        ax=pos,\n",
    "        xlabel=\"Network Method\",\n",
    "        ylabel=f\"{stats_name}\",\n",
    "        legend=True,\n",
    "    )\n",
    "    pos.tick_params(axis=\"x\", rotation=20)\n",
    "    # key = pipeline.analysis.set_colours()\n",
    "    # key.pop(\"experimental\")\n",
    "    # pos.legend(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the ddG MAE and SEM between the networks\n",
    "\n",
    "# SEM differences collect first\n",
    "sem_dict = {}\n",
    "sem_dict_name = {}\n",
    "sem_dict_eng = {}\n",
    "\n",
    "for network in network_dict:\n",
    "    sem_dict[network] = {}\n",
    "    sem_dict_eng[network] = {}\n",
    "    sem_list_name = []\n",
    "\n",
    "    for prot in [\"tyk2\", \"mcl1\"]:\n",
    "        sem_dict[network][prot] = {}\n",
    "\n",
    "        ana_obj = network_dict[network][prot][\"plain\"]\n",
    "\n",
    "        for eng in ana_obj.engines:\n",
    "            sem_dict[network][prot][eng] = {}\n",
    "\n",
    "            sem_list = []\n",
    "            sems = [val[1] for val in ana_obj.calc_pert_dict[eng].values()]\n",
    "            sem_list.append(sems)\n",
    "            sem_list_name.append(sems)\n",
    "\n",
    "            sem_list = reduce(lambda xs, ys: xs + ys, sem_list)\n",
    "            sem_list = [x for x in sem_list if str(x) != \"nan\"]\n",
    "\n",
    "            # if not check_normal_dist(sem_list):\n",
    "            #     print(f\"{prot} {name} not normally dist\")\n",
    "\n",
    "            mean = np.mean(sem_list)\n",
    "            lower_ci, upper_ci = _stats.norm.interval(\n",
    "                confidence=0.95, loc=np.mean(sem_list), scale=_stats.sem(sem_list)\n",
    "            )\n",
    "            print(prot, network, eng, mean, lower_ci, upper_ci)\n",
    "            sem_dict[network][prot][eng] = (\n",
    "                mean,\n",
    "                _stats.tstd(sem_list),\n",
    "                (lower_ci, upper_ci),\n",
    "                sem_list,\n",
    "            )\n",
    "\n",
    "    # for all the network\n",
    "    sem_list_name = reduce(lambda xs, ys: xs + ys, sem_list_name)\n",
    "    sem_list_name = [x for x in sem_list_name if str(x) != \"nan\"]\n",
    "    mean = np.mean(sem_list_name)\n",
    "    lower_ci, upper_ci = _stats.norm.interval(\n",
    "        confidence=0.95, loc=np.mean(sem_list_name), scale=_stats.sem(sem_list_name)\n",
    "    )\n",
    "    print(network, mean, lower_ci, upper_ci)\n",
    "    sem_dict_name[network] = (\n",
    "        mean,\n",
    "        _stats.tstd(sem_list_name),\n",
    "        (lower_ci, upper_ci),\n",
    "        sem_list_name,\n",
    "    )\n",
    "\n",
    "    # for per engine\n",
    "    for eng in ana_obj.engines:\n",
    "        sem_list_eng = []\n",
    "        for prot in [\"tyk2\", \"mcl1\"]:\n",
    "            sem_list_eng.append(sem_dict[network][prot][eng][3])\n",
    "\n",
    "        sem_list_eng = reduce(lambda xs, ys: xs + ys, sem_list_eng)\n",
    "        sem_list_eng = [x for x in sem_list_eng if str(x) != \"nan\"]\n",
    "        mean = np.mean(sem_list_eng)\n",
    "        lower_ci, upper_ci = _stats.norm.interval(\n",
    "            confidence=0.95, loc=np.mean(sem_list_eng), scale=_stats.sem(sem_list_eng)\n",
    "        )\n",
    "        print(network, mean, lower_ci, upper_ci)\n",
    "        sem_dict_eng[network][eng] = (\n",
    "            mean,\n",
    "            _stats.tstd(sem_list_name),\n",
    "            (lower_ci, upper_ci),\n",
    "            sem_list_eng,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same format as above but w the SEM\n",
    "\n",
    "df = pd.DataFrame(sem_dict_eng).applymap(lambda x: x[0]).T\n",
    "df_err = pd.DataFrame(sem_dict_eng).applymap(lambda x: x[2]).T  # confidene intervals\n",
    "df_lower = df_err.applymap(lambda x: x[0])\n",
    "df_upper = df_err.applymap(lambda x: x[1])\n",
    "df_err = (df_upper - df_lower) / 2\n",
    "\n",
    "col_dict = {\n",
    "    \"AMBER\": [\"orange\", \"moccasin\"],\n",
    "    \"SOMD\": [\"darkturquoise\", \"paleturquoise\"],\n",
    "    \"GROMACS\": [\"orchid\", \"plum\"],\n",
    "}\n",
    "df.plot(\n",
    "    kind=\"bar\",\n",
    "    color=col_dict,\n",
    "    yerr=df_err,\n",
    "    xlabel=\"Network score method\",\n",
    "    ylabel=f\"ddG SEM (kcal/mol)\",\n",
    "    legend=True,\n",
    ")\n",
    "plt.legend(title=False)\n",
    "# key = pipeline.analysis.set_colours()\n",
    "# key.pop(\"experimental\")\n",
    "# pos.legend(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cinnabar stats into a dict\n",
    "net_ana_method_dict = {\"method\": [], \"engine\": [], \"protein\": [], \"value\": []}\n",
    "network = \"lomap\"\n",
    "\n",
    "for eng in [\"AMBER\", \"SOMD\", \"GROMACS\"]:\n",
    "    for prot in ana_obj_dict.keys():\n",
    "        print(prot)\n",
    "        dg_list = []\n",
    "\n",
    "        ana_obj = network_dict[network][prot][\"plain\"]\n",
    "\n",
    "        for key in ana_obj.cinnabar_calc_val_dict[eng].keys():\n",
    "            value = abs(\n",
    "                abs(\n",
    "                    ana_obj.cinnabar_calc_val_dict[eng][key][0]\n",
    "                    - ana_obj.cinnabar_exper_val_dict[eng][key][0]\n",
    "                )\n",
    "            )\n",
    "            dg_list.append(value)\n",
    "            if value > 5:\n",
    "                print(prot, eng, key, value)\n",
    "\n",
    "        net_ana_method_dict[\"method\"].append(\n",
    "            [\"cinnabar\" for l in range(0, len(dg_list))]\n",
    "        )\n",
    "        net_ana_method_dict[\"engine\"].append(\n",
    "            [eng_dict_name[eng] for l in range(0, len(dg_list))]\n",
    "        )\n",
    "        net_ana_method_dict[\"protein\"].append([prot_dict_name[prot] for val in dg_list])\n",
    "        net_ana_method_dict[\"value\"].append([val for val in dg_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also want to compare fwf and cinnabar\n",
    "fwf_path = (\n",
    "    \"/home/anna/Documents/september_2022_workshops/freenrgworkflows/networkanalysis\"\n",
    ")\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    for prot in ana_obj_dict.keys():\n",
    "        print(eng, prot)\n",
    "        dg_list = []\n",
    "\n",
    "        ana_obj = network_dict[network][prot][\"plain\"]\n",
    "\n",
    "        # add path for fwf\n",
    "        ana_obj._add_fwf_path(fwf_path)\n",
    "        ana_obj._get_exp_fwf()\n",
    "\n",
    "        try:\n",
    "            fwf_dict = ana_obj._get_ana_fwf(engine=eng, use_repeat_files=True)\n",
    "        except:\n",
    "            print(f\"{prot} {eng} did not fwf w repeat files, trying w out\")\n",
    "            # try:\n",
    "            #     fwf_dict = ana_obj._get_ana_fwf(engine=eng, use_repeat_files=False)\n",
    "            # except:\n",
    "            #     print(\"non repeat files also failed\")\n",
    "\n",
    "        try:\n",
    "            di2 = {}\n",
    "            for di in ana_obj._fwf_computed_DGs[eng]:\n",
    "                di2[[k for k in di.keys()][0]] = di[[k for k in di.keys()][0]]\n",
    "            # experimental computed normally outside of fwf and normalised\n",
    "            for key in di2.keys():\n",
    "                value = abs(di2[key] - ana_obj.normalised_exper_val_dict[key][0])\n",
    "                dg_list.append(value)\n",
    "                if value > 5:\n",
    "                    print(prot, eng, key, value)\n",
    "        except:\n",
    "            print(\"did not fwf at all\")\n",
    "\n",
    "        net_ana_method_dict[\"method\"].append([\"fen\" for l in range(0, len(dg_list))])\n",
    "        net_ana_method_dict[\"engine\"].append(\n",
    "            [eng_dict_name[eng] for l in range(0, len(dg_list))]\n",
    "        )\n",
    "        net_ana_method_dict[\"protein\"].append([prot_dict_name[prot] for val in dg_list])\n",
    "        net_ana_method_dict[\"value\"].append([val for val in dg_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    sleep(5)\n",
    "    ana_obj = network_dict[\"lomap\"][prot][\"plain\"]\n",
    "    ana_obj.check_html_exists(ana_obj.engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all first\n",
    "# for prot in ana_obj_dict.keys():\n",
    "#     print(prot)\n",
    "ana_obj = network_dict[\"lomap\"][\"syk\"][\"plain\"]\n",
    "\n",
    "for eng in [\"AMBER\"]:\n",
    "    try:\n",
    "        ana_obj.analyse_mbarnet(\n",
    "            compute_missing=False,\n",
    "            write_xml=False,\n",
    "            run_xml_py=False,\n",
    "            use_experimental=True,\n",
    "            overwrite=False,\n",
    "            engines=[eng],\n",
    "            normalise=True,\n",
    "        )\n",
    "        print(ana_obj._mbarnet_computed_DGs[eng])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"failed for {prot} {eng}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbarnet\n",
    "\n",
    "# compute all first\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    ana_obj = network_dict[\"lomap\"][prot][\"plain\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        try:\n",
    "            ana_obj.analyse_mbarnet(\n",
    "                compute_missing=False,\n",
    "                write_xml=False,\n",
    "                run_xml_py=False,\n",
    "                use_experimental=True,\n",
    "                overwrite=False,\n",
    "                engines=[eng],\n",
    "                normalise=True,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"failed for {prot} {eng}\")\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    for prot in ana_obj_dict.keys():\n",
    "        dg_list = []\n",
    "        print(prot, eng)\n",
    "\n",
    "        ana_obj = network_dict[\"lomap\"][prot][\"plain\"]\n",
    "\n",
    "        try:\n",
    "            for key in ana_obj._mbarnet_computed_DGs[eng].keys():\n",
    "                value = abs(\n",
    "                    ana_obj._mbarnet_computed_DGs[eng][key][0]\n",
    "                    - ana_obj.normalised_exper_val_dict[key][0]\n",
    "                )\n",
    "                dg_list.append(value)\n",
    "                if value > 5:\n",
    "                    print(prot, eng, key, value)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        net_ana_method_dict[\"method\"].append(\n",
    "            [\"MBARNet\" for l in range(0, len(dg_list))]\n",
    "        )\n",
    "        net_ana_method_dict[\"engine\"].append(\n",
    "            [eng_dict_name[eng] for l in range(0, len(dg_list))]\n",
    "        )\n",
    "        net_ana_method_dict[\"protein\"].append([prot_dict_name[prot] for val in dg_list])\n",
    "        net_ana_method_dict[\"value\"].append([val for val in dg_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "\n",
    "df_dict[\"cinnabar\"] = {}\n",
    "for prot in ana_obj_dict.keys():\n",
    "    print(prot)\n",
    "    df_dict[\"cinnabar\"][prot] = {}\n",
    "    ana_obj = network_dict[network][prot][\"plain\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        try:\n",
    "            df, df_err, df_ci = ana_obj.calc_mae_engines(\n",
    "                engines=[eng], pert_val=\"val\", recalculate=False\n",
    "            )\n",
    "            df_dict[\"cinnabar\"][prot][eng] = (\n",
    "                df[eng][\"experimental\"],\n",
    "                df_err[eng][\"experimental\"],\n",
    "            )\n",
    "            # print(df[eng][\"experimental\"], df_err[eng][\"experimental\"])\n",
    "        except:\n",
    "            df_dict[\"cinnabar\"][prot][eng] = (0, 0)\n",
    "\n",
    "df_dict[\"fen\"] = {}\n",
    "for prot in ana_obj_dict.keys():\n",
    "    df_dict[\"fen\"][prot] = {}\n",
    "    ana_obj = network_dict[network][prot][\"plain\"]\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        try:\n",
    "            df, df_err, df_ci = ana_obj._get_stats_fwf(engines=[eng], statistic=\"MUE\")\n",
    "            df_dict[\"fen\"][prot][eng] = (\n",
    "                df[eng][\"experimental\"],\n",
    "                df_err[eng][\"experimental\"],\n",
    "            )\n",
    "            # print(df[eng][\"experimental\"], df_err[eng][\"experimental\"])\n",
    "        except:\n",
    "            print(\"ooft\")\n",
    "            df_dict[\"fen\"][prot][eng] = (0, 0)\n",
    "\n",
    "df_dict[\"mbarnet\"] = {}\n",
    "for prot in ana_obj_dict.keys():\n",
    "    df_dict[\"mbarnet\"][prot] = {}\n",
    "    print(prot)\n",
    "    ana_obj = network_dict[network][prot][\"plain\"]\n",
    "    for eng in ana_obj.engines:\n",
    "        try:\n",
    "            print(\n",
    "                prot,\n",
    "                eng,\n",
    "                len(ana_obj._perturbations_dict[eng]),\n",
    "                len(ana_obj._mbarnet_computed_DGs[eng]),\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        try:\n",
    "            df, df_err, df_ci = ana_obj._get_stats_mbarnet(\n",
    "                engines=[eng], statistic=\"MUE\"\n",
    "            )\n",
    "            df_dict[\"mbarnet\"][prot][eng] = (\n",
    "                df[eng][\"experimental\"],\n",
    "                df_err[eng][\"experimental\"],\n",
    "            )\n",
    "            # print(df[eng][\"experimental\"], df_err[eng][\"experimental\"])\n",
    "        except Exception as e:\n",
    "            print(\"oop\")\n",
    "            print(e)\n",
    "            df_dict[\"mbarnet\"][prot][eng] = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare stats\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "for engine, pos in zip(ana_obj.engines, [axes[0], axes[1], axes[2]]):\n",
    "    df_cinnabar = (\n",
    "        pd.DataFrame(df_dict[\"cinnabar\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"cinnabar\"}, axis=1)\n",
    "    )\n",
    "    df_fen = (\n",
    "        pd.DataFrame(df_dict[\"fen\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"fen\"}, axis=1)\n",
    "    )\n",
    "    df_mbarnet = (\n",
    "        pd.DataFrame(df_dict[\"mbarnet\"])\n",
    "        .applymap(lambda x: x[0])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"mbarnet\"}, axis=1)\n",
    "    )\n",
    "    df = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        [df_cinnabar, df_fen, df_mbarnet],\n",
    "    )\n",
    "\n",
    "    df_cinnabar = (\n",
    "        pd.DataFrame(df_dict[\"cinnabar\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"cinnabar\"}, axis=1)\n",
    "    )\n",
    "    df_fen = (\n",
    "        pd.DataFrame(df_dict[\"fen\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"fen\"}, axis=1)\n",
    "    )\n",
    "    df_mbarnet = (\n",
    "        pd.DataFrame(df_dict[\"mbarnet\"])\n",
    "        .applymap(lambda x: x[1])\n",
    "        .T.drop(labels=[eng for eng in ana_obj.engines if eng != engine], axis=1)\n",
    "        .rename({engine: \"mbarnet\"}, axis=1)\n",
    "    )\n",
    "    df_err = reduce(\n",
    "        lambda left, right: pd.merge(left, right, left_index=True, right_index=True),\n",
    "        [df_cinnabar, df_fen, df_mbarnet],\n",
    "    )\n",
    "\n",
    "    # df_lower = df_err.applymap(lambda x: x[0])\n",
    "    # df_upper = df_err.applymap(lambda x: x[1])\n",
    "    # df_err = (df_upper - df_lower)/2\n",
    "\n",
    "    df.plot(\n",
    "        kind=\"bar\",\n",
    "        color=[\"purple\", \"orchid\", \"lavender\"],\n",
    "        yerr=df_err,\n",
    "        title=engine,\n",
    "        ax=pos,\n",
    "        xlabel=\"protein system\",\n",
    "        ylabel=f\"MAE\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting per system per negine\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "plotting_dict = {\n",
    "    \"method\": flatten_comprehension(net_ana_method_dict[\"method\"]),\n",
    "    \"MD engine\": flatten_comprehension(net_ana_method_dict[\"engine\"]),\n",
    "    \"MAE dG (kcal/mol)\": flatten_comprehension(net_ana_method_dict[\"value\"]),\n",
    "    \"Protein\": flatten_comprehension(net_ana_method_dict[\"protein\"]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(plotting_dict)\n",
    "df.drop(df.loc[df[\"method\"] == \"fen\"].index, inplace=True)\n",
    "df.drop(df.loc[df[\"method\"] == \"mbarnet\"].index, inplace=True)\n",
    "\n",
    "sns.barplot(\n",
    "    df,\n",
    "    x=\"Protein\",\n",
    "    y=\"MAE dG (kcal/mol)\",\n",
    "    hue=\"MD engine\",\n",
    "    palette=[\"darkorange\", \"turquoise\", \"orchid\"],\n",
    "    ax=axes,\n",
    ").set_title(\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_dict = {\n",
    "    \"method\": flatten_comprehension(net_ana_method_dict[\"method\"]),\n",
    "    \"MD engine\": flatten_comprehension(net_ana_method_dict[\"engine\"]),\n",
    "    \"MAE dG (kcal/mol)\": flatten_comprehension(net_ana_method_dict[\"value\"]),\n",
    "    \"Protein\": flatten_comprehension(net_ana_method_dict[\"protein\"]),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.25, 3.25), dpi=500)\n",
    "df = pd.DataFrame(plotting_dict)\n",
    "sns.boxplot(\n",
    "    df,\n",
    "    x=\"MD engine\",\n",
    "    y=\"MAE dG (kcal/mol)\",\n",
    "    hue=\"method\",\n",
    "    palette=[\"purple\", \"orchid\", \"lavender\"],\n",
    "    ax=ax,\n",
    ")\n",
    "# modify individual font size of elements\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlabel(\"MD Engine\", fontsize=10)\n",
    "plt.ylabel(\"MAE ÎG (kcal/mol)\", fontsize=10)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=10)\n",
    "ax.set_ylim(top=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting per system per negine\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "plotting_dict = {\n",
    "    \"method\": flatten_comprehension(net_ana_method_dict[\"method\"]),\n",
    "    \"MD engine\": flatten_comprehension(net_ana_method_dict[\"engine\"]),\n",
    "    \"MAE dG (kcal/mol)\": flatten_comprehension(net_ana_method_dict[\"value\"]),\n",
    "    \"Protein\": flatten_comprehension(net_ana_method_dict[\"protein\"]),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(plotting_dict)\n",
    "df.drop(df.loc[df[\"method\"] == \"fen\"].index, inplace=True)\n",
    "df.drop(df.loc[df[\"method\"] == \"mbarnet\"].index, inplace=True)\n",
    "\n",
    "sns.barplot(\n",
    "    df,\n",
    "    x=\"Protein\",\n",
    "    y=\"MAE dG (kcal/mol)\",\n",
    "    hue=\"MD engine\",\n",
    "    palette=[\"darkorange\", \"turquoise\", \"orchid\"],\n",
    "    ax=axes,\n",
    ").set_title(\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting per system\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(20, 20), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "for engine, pos in zip(ana_obj.engines, [axes[0], axes[1], axes[2]]):\n",
    "    print(engine)\n",
    "    plotting_dict = {\n",
    "        \"method\": flatten_comprehension(net_ana_method_dict[\"method\"]),\n",
    "        \"MD engine\": flatten_comprehension(net_ana_method_dict[\"engine\"]),\n",
    "        \"MAE dG (kcal/mol)\": flatten_comprehension(net_ana_method_dict[\"value\"]),\n",
    "        \"Protein\": flatten_comprehension(net_ana_method_dict[\"protein\"]),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(plotting_dict)\n",
    "    for eng in [eng for eng in ana_obj.engines if eng != engine]:\n",
    "        df.drop(df.loc[df[\"MD engine\"] == eng_dict_name[eng]].index, inplace=True)\n",
    "\n",
    "    sns.boxplot(\n",
    "        df,\n",
    "        x=\"Protein\",\n",
    "        y=\"MAE dG (kcal/mol)\",\n",
    "        hue=\"method\",\n",
    "        palette=[\"purple\", \"orchid\", \"lavender\"],\n",
    "        ax=pos,\n",
    "    ).set_title(eng_dict_name[engine])\n",
    "    # pos.set_ylim(top=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(25, 5), sharex=True, sharey=True)\n",
    "plt.xlim = ()\n",
    "plt.ylim = ()\n",
    "for prot, pos in zip(\n",
    "    ana_obj_dict.keys(), [axes[0], axes[1], axes[2], axes[3], axes[4], axes[5]]\n",
    "):\n",
    "    plotting_dict = {\n",
    "        \"method\": flatten_comprehension(net_ana_method_dict[\"method\"]),\n",
    "        \"MD engine\": flatten_comprehension(net_ana_method_dict[\"engine\"]),\n",
    "        \"MAE dG (kcal/mol)\": flatten_comprehension(net_ana_method_dict[\"value\"]),\n",
    "        \"Protein\": flatten_comprehension(net_ana_method_dict[\"protein\"]),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(plotting_dict)\n",
    "    for eng in [eng for eng in ana_obj_dict.keys() if eng != prot]:\n",
    "        df.drop(df.loc[df[\"Protein\"] == prot_dict_name[eng]].index, inplace=True)\n",
    "\n",
    "    sns.boxplot(\n",
    "        df,\n",
    "        x=\"MD engine\",\n",
    "        y=\"MAE dG (kcal/mol)\",\n",
    "        hue=\"method\",\n",
    "        palette=[\"purple\", \"orchid\", \"lavender\"],\n",
    "        ax=pos,\n",
    "    ).set_title(prot.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    df,\n",
    "    x=\"Protein\",\n",
    "    y=\"MAE dG (kcal/mol)\",\n",
    "    hue=\"MD engine\",\n",
    "    palette=pipeline.analysis.set_colours().values(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline_annamherz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
